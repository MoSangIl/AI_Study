{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dropout, Dense, Activation\n",
    "\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>723</th>\n",
       "      <td>2020-09-09</td>\n",
       "      <td>58200</td>\n",
       "      <td>59300</td>\n",
       "      <td>57800</td>\n",
       "      <td>58400</td>\n",
       "      <td>58400.0</td>\n",
       "      <td>30597399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>724</th>\n",
       "      <td>2020-09-10</td>\n",
       "      <td>59900</td>\n",
       "      <td>60000</td>\n",
       "      <td>59100</td>\n",
       "      <td>59200</td>\n",
       "      <td>59200.0</td>\n",
       "      <td>29923293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>725</th>\n",
       "      <td>2020-09-11</td>\n",
       "      <td>59300</td>\n",
       "      <td>59400</td>\n",
       "      <td>58200</td>\n",
       "      <td>59000</td>\n",
       "      <td>59000.0</td>\n",
       "      <td>16017098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>726</th>\n",
       "      <td>2020-09-14</td>\n",
       "      <td>60200</td>\n",
       "      <td>60800</td>\n",
       "      <td>59900</td>\n",
       "      <td>60400</td>\n",
       "      <td>60400.0</td>\n",
       "      <td>20648281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>727</th>\n",
       "      <td>2020-09-15</td>\n",
       "      <td>60900</td>\n",
       "      <td>61000</td>\n",
       "      <td>60500</td>\n",
       "      <td>61000</td>\n",
       "      <td>61000.0</td>\n",
       "      <td>17787753</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Date   Open   High    Low  Close  Adj Close    Volume\n",
       "723  2020-09-09  58200  59300  57800  58400    58400.0  30597399\n",
       "724  2020-09-10  59900  60000  59100  59200    59200.0  29923293\n",
       "725  2020-09-11  59300  59400  58200  59000    59000.0  16017098\n",
       "726  2020-09-14  60200  60800  59900  60400    60400.0  20648281\n",
       "727  2020-09-15  60900  61000  60500  61000    61000.0  17787753"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('dataset/SamsumgStock.KS.csv')\n",
    "data.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute Mid Price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50210. 51500. 52210. 52170. 52590. 53340. 53620. 51850. 51860. 51230.\n",
      " 53220. 54050. 54630. 54310. 54310. 54690. 54640. 53840. 53450. 54320.\n",
      " 54410. 54060. 53150. 52730. 54010. 54470. 56840. 57140. 56500. 55920.\n",
      " 56390. 56460. 56410. 56160. 56450. 56330. 55820. 56350. 55590. 55560.\n",
      " 55910. 55340. 54000. 52500. 52870. 51030. 51290. 50680. 50790. 50790.\n",
      " 50500. 51520. 51770. 51880. 51600. 51670. 51000. 50930. 51800. 50080.\n",
      " 49600. 49150. 49010. 50230. 51990. 51410. 51660. 52010. 50850. 49580.\n",
      " 48640. 47620. 48450. 49380. 49540. 50230. 49710. 48320. 48730. 49130.\n",
      " 49760. 50310. 51190. 50210. 51870. 50340. 48550. 47160. 47250. 47030.\n",
      " 46300. 44800. 45680. 47130. 48520. 48830. 47690. 47210. 47010. 47280.\n",
      " 47320. 47880. 47550. 46400. 45620. 46460. 48060. 48780. 49890. 50180.\n",
      " 51010. 51500. 51520. 50830. 50890. 50650. 51420. 51410. 50160. 49660.\n",
      " 49770. 48720. 48940. 49490. 48860. 47710. 47590. 48360. 47990. 48820.\n",
      " 48630. 49250. 49160. 49790. 50230. 50180. 50970. 52260. 51840. 51540.\n",
      " 50970. 49860. 51280. 53040. 53000. 53000. 53000. 52850. 52550. 51850.\n",
      " 51150. 51700. 50500. 49750. 49675. 49950. 49625. 49650. 51200. 51550.\n",
      " 51800. 52500. 51900. 50300. 50325. 50825. 50950. 50900. 51150. 50000.\n",
      " 49825. 49525. 48600. 48175. 46925. 46925. 47225. 47475. 46725. 46600.\n",
      " 46600. 47750. 46875. 46675. 46325. 46100. 46550. 46075. 45250. 45650.\n",
      " 46325. 45925. 45850. 46125. 46400. 45900. 46825. 46900. 47150. 46675.\n",
      " 46275. 46225. 46500. 46725. 46575. 46225. 46450. 46150. 45675. 45950.\n",
      " 46325. 46775. 46750. 45625. 44875. 45125. 44175. 44225. 43850. 44300.\n",
      " 45550. 45950. 45975. 46275. 46625. 46600. 47325. 47725. 47800. 47500.\n",
      " 46925. 46100. 44800. 45275. 45475. 44800. 44375. 45375. 45350. 45300.\n",
      " 45950. 47000. 47050. 46975. 46775. 46300. 46200. 45150. 45025. 44700.\n",
      " 45000. 43875. 43925. 43700. 43750. 44250. 44075. 43800. 43575. 43000.\n",
      " 42675. 41050. 40850. 41250. 42000. 42525. 42550. 43525. 43350. 43375.\n",
      " 43950. 44550. 44375. 44475. 43950. 44150. 44225. 43850. 42550. 42050.\n",
      " 42325. 42250. 42450. 42800. 42975. 43375. 42875. 42900. 42400. 41300.\n",
      " 40775. 41125. 40325. 40450. 40425. 40375. 39450. 39125. 38750. 39100.\n",
      " 38800. 38375. 38675. 38525. 38450. 38550. 38975. 38000. 37225. 38350.\n",
      " 38575. 38950. 39875. 40250. 40275. 40475. 41075. 41775. 42175. 42325.\n",
      " 42350. 41800. 42725. 44250. 45050. 44925. 45600. 46600. 46600. 46650.\n",
      " 45175. 44625. 45450. 46350. 46825. 46250. 46350. 45800. 46800. 46700.\n",
      " 46800. 47300. 46975. 47000. 45800. 45450. 44625. 44000. 44175. 44300.\n",
      " 44050. 44550. 44075. 43925. 43975. 43800. 43725. 43650. 45150. 46625.\n",
      " 45225. 45300. 44925. 44750. 44550. 45150. 45725. 46275. 46625. 47075.\n",
      " 46700. 46575. 46375. 46475. 46450. 47250. 47100. 47300. 46375. 45625.\n",
      " 45500. 45250. 44900. 44550. 44400. 45625. 45825. 45775. 45675. 44850.\n",
      " 44525. 43350. 42950. 42775. 42200. 42800. 41875. 41450. 41825. 43150.\n",
      " 43100. 43625. 43100. 42675. 42550. 41700. 42425. 42475. 43200. 43350.\n",
      " 43950. 43900. 44450. 44775. 44675. 43900. 43725. 43725. 44075. 45225.\n",
      " 45175. 45500. 45500. 45500. 45800. 46175. 46850. 46825. 46375. 45775.\n",
      " 45725. 45600. 44575. 45075. 45825. 46350. 46100. 46200. 46575. 46150.\n",
      " 46050. 46775. 46950. 47300. 46700. 46900. 46850. 46525. 46575. 45800.\n",
      " 45175. 44900. 44100. 43150. 43500. 43075. 43200. 43775. 43225. 43875.\n",
      " 43600. 43925. 44075. 44475. 44275. 43925. 43375. 43900. 44075. 43625.\n",
      " 44025. 44250. 43375. 43625. 45275. 46175. 46650. 46875. 47100. 46750.\n",
      " 46950. 47250. 48525. 49350. 49150. 49250. 49075. 49075. 48350. 48575.\n",
      " 48875. 48000. 48000. 48175. 48300. 48600. 49125. 50075. 50050. 50650.\n",
      " 50350. 50275. 50100. 51100. 51150. 51500. 50850. 51100. 51250. 50500.\n",
      " 50850. 50800. 51850. 52400. 53100. 52900. 52650. 51800. 52100. 52250.\n",
      " 53150. 53500. 53100. 52700. 51350. 51250. 52150. 52350. 51950. 51700.\n",
      " 50800. 50850. 49900. 49425. 49950. 50425. 51050. 51150. 51800. 53000.\n",
      " 54350. 54600. 56050. 56600. 56400. 56050. 55750. 55250. 54900. 56200.\n",
      " 56150. 55500. 55750. 55100. 56000. 56650. 58000. 59000. 59550. 60450.\n",
      " 59250. 59850. 61500. 62250. 61800. 61500. 61250. 58850. 59250. 57800.\n",
      " 57400. 56300. 57900. 59550. 60400. 60450. 59450. 60200. 60200. 61050.\n",
      " 61050. 61600. 60300. 59900. 60450. 59150. 57450. 57100. 56500. 56200.\n",
      " 54850. 54550. 56000. 56100. 57350. 56700. 56500. 54300. 53200. 52100.\n",
      " 49225. 49850. 48175. 46975. 44475. 44525. 42975. 45000. 48375. 48500.\n",
      " 48275. 47450. 47825. 46850. 46100. 47075. 48025. 49600. 49175. 49250.\n",
      " 48950. 48600. 48750. 48950. 51150. 50700. 49200. 49175. 49900. 49375.\n",
      " 49550. 49700. 50050. 48800. 48850. 49000. 49075. 48775. 48025. 47875.\n",
      " 47875. 48075. 48350. 50100. 50000. 50125. 49200. 48675. 49025. 49400.\n",
      " 50550. 50200. 50900. 51150. 53350. 55800. 54950. 55600. 55450. 55400.\n",
      " 54150. 52150. 50950. 51350. 52100. 51950. 52250. 52200. 51950. 52750.\n",
      " 52450. 53050. 52600. 53350. 53000. 52500. 53150. 54400. 54650. 53400.\n",
      " 53200. 52750. 53450. 53500. 54650. 54300. 54400. 54400. 55100. 55100.\n",
      " 54250. 54050. 55000. 57600. 59500. 59550. 58650. 57300. 57550. 56900.\n",
      " 57750. 57750. 57900. 58650. 58350. 58800. 58050. 58950. 58500. 56450.\n",
      " 56350. 56000. 56450. 56100. 55950. 55850. 55050. 54450. 54600. 56100.\n",
      " 55450. 56550. 57950. 58550. 59550. 58800. 60350. 60750.]\n",
      "62250.0 37225.0\n"
     ]
    }
   ],
   "source": [
    "high_prices = data['High'].values\n",
    "low_prices = data['Low'].values\n",
    "mid_prices = (high_prices + low_prices) / 2\n",
    "len(mid_prices)\n",
    "print(mid_prices)\n",
    "print(max(mid_prices), min(mid_prices))\n",
    "max_price = max(mid_prices)\n",
    "min_price = min(mid_prices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Windows\n",
    "\n",
    "Window: 50  \n",
    "최근 50일 데이터를 보고 다음을 예측한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_len = 100\n",
    "output_len = 5\n",
    "sequence_length = seq_len + output_len\n",
    "\n",
    "result = []\n",
    "\n",
    "for index in range(len(mid_prices)):\n",
    "    if  len(mid_prices) <= (index * output_len) + sequence_length:\n",
    "        break\n",
    "    result.append(mid_prices[(index * output_len) : (index * output_len) + sequence_length])\n",
    "\n",
    "\n",
    "# for index in range(len(mid_prices) - sequence_length + 5):\n",
    "#     result.append(mid_prices[index: index + sequence_length]) # slicing 60개"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([50210., 51500., 52210., 52170., 52590., 53340., 53620., 51850.,\n",
      "       51860., 51230., 53220., 54050., 54630., 54310., 54310., 54690.,\n",
      "       54640., 53840., 53450., 54320., 54410., 54060., 53150., 52730.,\n",
      "       54010., 54470., 56840., 57140., 56500., 55920., 56390., 56460.,\n",
      "       56410., 56160., 56450., 56330., 55820., 56350., 55590., 55560.,\n",
      "       55910., 55340., 54000., 52500., 52870., 51030., 51290., 50680.,\n",
      "       50790., 50790., 50500., 51520., 51770., 51880., 51600., 51670.,\n",
      "       51000., 50930., 51800., 50080., 49600., 49150., 49010., 50230.,\n",
      "       51990., 51410., 51660., 52010., 50850., 49580., 48640., 47620.,\n",
      "       48450., 49380., 49540., 50230., 49710., 48320., 48730., 49130.,\n",
      "       49760., 50310., 51190., 50210., 51870., 50340., 48550., 47160.,\n",
      "       47250., 47030., 46300., 44800., 45680., 47130., 48520., 48830.,\n",
      "       47690., 47210., 47010., 47280., 47320., 47880., 47550., 46400.,\n",
      "       45620.]), array([53340., 53620., 51850., 51860., 51230., 53220., 54050., 54630.,\n",
      "       54310., 54310., 54690., 54640., 53840., 53450., 54320., 54410.,\n",
      "       54060., 53150., 52730., 54010., 54470., 56840., 57140., 56500.,\n",
      "       55920., 56390., 56460., 56410., 56160., 56450., 56330., 55820.,\n",
      "       56350., 55590., 55560., 55910., 55340., 54000., 52500., 52870.,\n",
      "       51030., 51290., 50680., 50790., 50790., 50500., 51520., 51770.,\n",
      "       51880., 51600., 51670., 51000., 50930., 51800., 50080., 49600.,\n",
      "       49150., 49010., 50230., 51990., 51410., 51660., 52010., 50850.,\n",
      "       49580., 48640., 47620., 48450., 49380., 49540., 50230., 49710.,\n",
      "       48320., 48730., 49130., 49760., 50310., 51190., 50210., 51870.,\n",
      "       50340., 48550., 47160., 47250., 47030., 46300., 44800., 45680.,\n",
      "       47130., 48520., 48830., 47690., 47210., 47010., 47280., 47320.,\n",
      "       47880., 47550., 46400., 45620., 46460., 48060., 48780., 49890.,\n",
      "       50180.]), array([53220., 54050., 54630., 54310., 54310., 54690., 54640., 53840.,\n",
      "       53450., 54320., 54410., 54060., 53150., 52730., 54010., 54470.,\n",
      "       56840., 57140., 56500., 55920., 56390., 56460., 56410., 56160.,\n",
      "       56450., 56330., 55820., 56350., 55590., 55560., 55910., 55340.,\n",
      "       54000., 52500., 52870., 51030., 51290., 50680., 50790., 50790.,\n",
      "       50500., 51520., 51770., 51880., 51600., 51670., 51000., 50930.,\n",
      "       51800., 50080., 49600., 49150., 49010., 50230., 51990., 51410.,\n",
      "       51660., 52010., 50850., 49580., 48640., 47620., 48450., 49380.,\n",
      "       49540., 50230., 49710., 48320., 48730., 49130., 49760., 50310.,\n",
      "       51190., 50210., 51870., 50340., 48550., 47160., 47250., 47030.,\n",
      "       46300., 44800., 45680., 47130., 48520., 48830., 47690., 47210.,\n",
      "       47010., 47280., 47320., 47880., 47550., 46400., 45620., 46460.,\n",
      "       48060., 48780., 49890., 50180., 51010., 51500., 51520., 50830.,\n",
      "       50890.]), array([54690., 54640., 53840., 53450., 54320., 54410., 54060., 53150.,\n",
      "       52730., 54010., 54470., 56840., 57140., 56500., 55920., 56390.,\n",
      "       56460., 56410., 56160., 56450., 56330., 55820., 56350., 55590.,\n",
      "       55560., 55910., 55340., 54000., 52500., 52870., 51030., 51290.,\n",
      "       50680., 50790., 50790., 50500., 51520., 51770., 51880., 51600.,\n",
      "       51670., 51000., 50930., 51800., 50080., 49600., 49150., 49010.,\n",
      "       50230., 51990., 51410., 51660., 52010., 50850., 49580., 48640.,\n",
      "       47620., 48450., 49380., 49540., 50230., 49710., 48320., 48730.,\n",
      "       49130., 49760., 50310., 51190., 50210., 51870., 50340., 48550.,\n",
      "       47160., 47250., 47030., 46300., 44800., 45680., 47130., 48520.,\n",
      "       48830., 47690., 47210., 47010., 47280., 47320., 47880., 47550.,\n",
      "       46400., 45620., 46460., 48060., 48780., 49890., 50180., 51010.,\n",
      "       51500., 51520., 50830., 50890., 50650., 51420., 51410., 50160.,\n",
      "       49660.]), array([54410., 54060., 53150., 52730., 54010., 54470., 56840., 57140.,\n",
      "       56500., 55920., 56390., 56460., 56410., 56160., 56450., 56330.,\n",
      "       55820., 56350., 55590., 55560., 55910., 55340., 54000., 52500.,\n",
      "       52870., 51030., 51290., 50680., 50790., 50790., 50500., 51520.,\n",
      "       51770., 51880., 51600., 51670., 51000., 50930., 51800., 50080.,\n",
      "       49600., 49150., 49010., 50230., 51990., 51410., 51660., 52010.,\n",
      "       50850., 49580., 48640., 47620., 48450., 49380., 49540., 50230.,\n",
      "       49710., 48320., 48730., 49130., 49760., 50310., 51190., 50210.,\n",
      "       51870., 50340., 48550., 47160., 47250., 47030., 46300., 44800.,\n",
      "       45680., 47130., 48520., 48830., 47690., 47210., 47010., 47280.,\n",
      "       47320., 47880., 47550., 46400., 45620., 46460., 48060., 48780.,\n",
      "       49890., 50180., 51010., 51500., 51520., 50830., 50890., 50650.,\n",
      "       51420., 51410., 50160., 49660., 49770., 48720., 48940., 49490.,\n",
      "       48860.]), array([54470., 56840., 57140., 56500., 55920., 56390., 56460., 56410.,\n",
      "       56160., 56450., 56330., 55820., 56350., 55590., 55560., 55910.,\n",
      "       55340., 54000., 52500., 52870., 51030., 51290., 50680., 50790.,\n",
      "       50790., 50500., 51520., 51770., 51880., 51600., 51670., 51000.,\n",
      "       50930., 51800., 50080., 49600., 49150., 49010., 50230., 51990.,\n",
      "       51410., 51660., 52010., 50850., 49580., 48640., 47620., 48450.,\n",
      "       49380., 49540., 50230., 49710., 48320., 48730., 49130., 49760.,\n",
      "       50310., 51190., 50210., 51870., 50340., 48550., 47160., 47250.,\n",
      "       47030., 46300., 44800., 45680., 47130., 48520., 48830., 47690.,\n",
      "       47210., 47010., 47280., 47320., 47880., 47550., 46400., 45620.,\n",
      "       46460., 48060., 48780., 49890., 50180., 51010., 51500., 51520.,\n",
      "       50830., 50890., 50650., 51420., 51410., 50160., 49660., 49770.,\n",
      "       48720., 48940., 49490., 48860., 47710., 47590., 48360., 47990.,\n",
      "       48820.]), array([56390., 56460., 56410., 56160., 56450., 56330., 55820., 56350.,\n",
      "       55590., 55560., 55910., 55340., 54000., 52500., 52870., 51030.,\n",
      "       51290., 50680., 50790., 50790., 50500., 51520., 51770., 51880.,\n",
      "       51600., 51670., 51000., 50930., 51800., 50080., 49600., 49150.,\n",
      "       49010., 50230., 51990., 51410., 51660., 52010., 50850., 49580.,\n",
      "       48640., 47620., 48450., 49380., 49540., 50230., 49710., 48320.,\n",
      "       48730., 49130., 49760., 50310., 51190., 50210., 51870., 50340.,\n",
      "       48550., 47160., 47250., 47030., 46300., 44800., 45680., 47130.,\n",
      "       48520., 48830., 47690., 47210., 47010., 47280., 47320., 47880.,\n",
      "       47550., 46400., 45620., 46460., 48060., 48780., 49890., 50180.,\n",
      "       51010., 51500., 51520., 50830., 50890., 50650., 51420., 51410.,\n",
      "       50160., 49660., 49770., 48720., 48940., 49490., 48860., 47710.,\n",
      "       47590., 48360., 47990., 48820., 48630., 49250., 49160., 49790.,\n",
      "       50230.]), array([56330., 55820., 56350., 55590., 55560., 55910., 55340., 54000.,\n",
      "       52500., 52870., 51030., 51290., 50680., 50790., 50790., 50500.,\n",
      "       51520., 51770., 51880., 51600., 51670., 51000., 50930., 51800.,\n",
      "       50080., 49600., 49150., 49010., 50230., 51990., 51410., 51660.,\n",
      "       52010., 50850., 49580., 48640., 47620., 48450., 49380., 49540.,\n",
      "       50230., 49710., 48320., 48730., 49130., 49760., 50310., 51190.,\n",
      "       50210., 51870., 50340., 48550., 47160., 47250., 47030., 46300.,\n",
      "       44800., 45680., 47130., 48520., 48830., 47690., 47210., 47010.,\n",
      "       47280., 47320., 47880., 47550., 46400., 45620., 46460., 48060.,\n",
      "       48780., 49890., 50180., 51010., 51500., 51520., 50830., 50890.,\n",
      "       50650., 51420., 51410., 50160., 49660., 49770., 48720., 48940.,\n",
      "       49490., 48860., 47710., 47590., 48360., 47990., 48820., 48630.,\n",
      "       49250., 49160., 49790., 50230., 50180., 50970., 52260., 51840.,\n",
      "       51540.]), array([55910., 55340., 54000., 52500., 52870., 51030., 51290., 50680.,\n",
      "       50790., 50790., 50500., 51520., 51770., 51880., 51600., 51670.,\n",
      "       51000., 50930., 51800., 50080., 49600., 49150., 49010., 50230.,\n",
      "       51990., 51410., 51660., 52010., 50850., 49580., 48640., 47620.,\n",
      "       48450., 49380., 49540., 50230., 49710., 48320., 48730., 49130.,\n",
      "       49760., 50310., 51190., 50210., 51870., 50340., 48550., 47160.,\n",
      "       47250., 47030., 46300., 44800., 45680., 47130., 48520., 48830.,\n",
      "       47690., 47210., 47010., 47280., 47320., 47880., 47550., 46400.,\n",
      "       45620., 46460., 48060., 48780., 49890., 50180., 51010., 51500.,\n",
      "       51520., 50830., 50890., 50650., 51420., 51410., 50160., 49660.,\n",
      "       49770., 48720., 48940., 49490., 48860., 47710., 47590., 48360.,\n",
      "       47990., 48820., 48630., 49250., 49160., 49790., 50230., 50180.,\n",
      "       50970., 52260., 51840., 51540., 50970., 49860., 51280., 53040.,\n",
      "       53000.]), array([51030., 51290., 50680., 50790., 50790., 50500., 51520., 51770.,\n",
      "       51880., 51600., 51670., 51000., 50930., 51800., 50080., 49600.,\n",
      "       49150., 49010., 50230., 51990., 51410., 51660., 52010., 50850.,\n",
      "       49580., 48640., 47620., 48450., 49380., 49540., 50230., 49710.,\n",
      "       48320., 48730., 49130., 49760., 50310., 51190., 50210., 51870.,\n",
      "       50340., 48550., 47160., 47250., 47030., 46300., 44800., 45680.,\n",
      "       47130., 48520., 48830., 47690., 47210., 47010., 47280., 47320.,\n",
      "       47880., 47550., 46400., 45620., 46460., 48060., 48780., 49890.,\n",
      "       50180., 51010., 51500., 51520., 50830., 50890., 50650., 51420.,\n",
      "       51410., 50160., 49660., 49770., 48720., 48940., 49490., 48860.,\n",
      "       47710., 47590., 48360., 47990., 48820., 48630., 49250., 49160.,\n",
      "       49790., 50230., 50180., 50970., 52260., 51840., 51540., 50970.,\n",
      "       49860., 51280., 53040., 53000., 53000., 53000., 52850., 52550.,\n",
      "       51850.]), array([50500., 51520., 51770., 51880., 51600., 51670., 51000., 50930.,\n",
      "       51800., 50080., 49600., 49150., 49010., 50230., 51990., 51410.,\n",
      "       51660., 52010., 50850., 49580., 48640., 47620., 48450., 49380.,\n",
      "       49540., 50230., 49710., 48320., 48730., 49130., 49760., 50310.,\n",
      "       51190., 50210., 51870., 50340., 48550., 47160., 47250., 47030.,\n",
      "       46300., 44800., 45680., 47130., 48520., 48830., 47690., 47210.,\n",
      "       47010., 47280., 47320., 47880., 47550., 46400., 45620., 46460.,\n",
      "       48060., 48780., 49890., 50180., 51010., 51500., 51520., 50830.,\n",
      "       50890., 50650., 51420., 51410., 50160., 49660., 49770., 48720.,\n",
      "       48940., 49490., 48860., 47710., 47590., 48360., 47990., 48820.,\n",
      "       48630., 49250., 49160., 49790., 50230., 50180., 50970., 52260.,\n",
      "       51840., 51540., 50970., 49860., 51280., 53040., 53000., 53000.,\n",
      "       53000., 52850., 52550., 51850., 51150., 51700., 50500., 49750.,\n",
      "       49675.]), array([51670., 51000., 50930., 51800., 50080., 49600., 49150., 49010.,\n",
      "       50230., 51990., 51410., 51660., 52010., 50850., 49580., 48640.,\n",
      "       47620., 48450., 49380., 49540., 50230., 49710., 48320., 48730.,\n",
      "       49130., 49760., 50310., 51190., 50210., 51870., 50340., 48550.,\n",
      "       47160., 47250., 47030., 46300., 44800., 45680., 47130., 48520.,\n",
      "       48830., 47690., 47210., 47010., 47280., 47320., 47880., 47550.,\n",
      "       46400., 45620., 46460., 48060., 48780., 49890., 50180., 51010.,\n",
      "       51500., 51520., 50830., 50890., 50650., 51420., 51410., 50160.,\n",
      "       49660., 49770., 48720., 48940., 49490., 48860., 47710., 47590.,\n",
      "       48360., 47990., 48820., 48630., 49250., 49160., 49790., 50230.,\n",
      "       50180., 50970., 52260., 51840., 51540., 50970., 49860., 51280.,\n",
      "       53040., 53000., 53000., 53000., 52850., 52550., 51850., 51150.,\n",
      "       51700., 50500., 49750., 49675., 49950., 49625., 49650., 51200.,\n",
      "       51550.]), array([49600., 49150., 49010., 50230., 51990., 51410., 51660., 52010.,\n",
      "       50850., 49580., 48640., 47620., 48450., 49380., 49540., 50230.,\n",
      "       49710., 48320., 48730., 49130., 49760., 50310., 51190., 50210.,\n",
      "       51870., 50340., 48550., 47160., 47250., 47030., 46300., 44800.,\n",
      "       45680., 47130., 48520., 48830., 47690., 47210., 47010., 47280.,\n",
      "       47320., 47880., 47550., 46400., 45620., 46460., 48060., 48780.,\n",
      "       49890., 50180., 51010., 51500., 51520., 50830., 50890., 50650.,\n",
      "       51420., 51410., 50160., 49660., 49770., 48720., 48940., 49490.,\n",
      "       48860., 47710., 47590., 48360., 47990., 48820., 48630., 49250.,\n",
      "       49160., 49790., 50230., 50180., 50970., 52260., 51840., 51540.,\n",
      "       50970., 49860., 51280., 53040., 53000., 53000., 53000., 52850.,\n",
      "       52550., 51850., 51150., 51700., 50500., 49750., 49675., 49950.,\n",
      "       49625., 49650., 51200., 51550., 51800., 52500., 51900., 50300.,\n",
      "       50325.]), array([51410., 51660., 52010., 50850., 49580., 48640., 47620., 48450.,\n",
      "       49380., 49540., 50230., 49710., 48320., 48730., 49130., 49760.,\n",
      "       50310., 51190., 50210., 51870., 50340., 48550., 47160., 47250.,\n",
      "       47030., 46300., 44800., 45680., 47130., 48520., 48830., 47690.,\n",
      "       47210., 47010., 47280., 47320., 47880., 47550., 46400., 45620.,\n",
      "       46460., 48060., 48780., 49890., 50180., 51010., 51500., 51520.,\n",
      "       50830., 50890., 50650., 51420., 51410., 50160., 49660., 49770.,\n",
      "       48720., 48940., 49490., 48860., 47710., 47590., 48360., 47990.,\n",
      "       48820., 48630., 49250., 49160., 49790., 50230., 50180., 50970.,\n",
      "       52260., 51840., 51540., 50970., 49860., 51280., 53040., 53000.,\n",
      "       53000., 53000., 52850., 52550., 51850., 51150., 51700., 50500.,\n",
      "       49750., 49675., 49950., 49625., 49650., 51200., 51550., 51800.,\n",
      "       52500., 51900., 50300., 50325., 50825., 50950., 50900., 51150.,\n",
      "       50000.]), array([48640., 47620., 48450., 49380., 49540., 50230., 49710., 48320.,\n",
      "       48730., 49130., 49760., 50310., 51190., 50210., 51870., 50340.,\n",
      "       48550., 47160., 47250., 47030., 46300., 44800., 45680., 47130.,\n",
      "       48520., 48830., 47690., 47210., 47010., 47280., 47320., 47880.,\n",
      "       47550., 46400., 45620., 46460., 48060., 48780., 49890., 50180.,\n",
      "       51010., 51500., 51520., 50830., 50890., 50650., 51420., 51410.,\n",
      "       50160., 49660., 49770., 48720., 48940., 49490., 48860., 47710.,\n",
      "       47590., 48360., 47990., 48820., 48630., 49250., 49160., 49790.,\n",
      "       50230., 50180., 50970., 52260., 51840., 51540., 50970., 49860.,\n",
      "       51280., 53040., 53000., 53000., 53000., 52850., 52550., 51850.,\n",
      "       51150., 51700., 50500., 49750., 49675., 49950., 49625., 49650.,\n",
      "       51200., 51550., 51800., 52500., 51900., 50300., 50325., 50825.,\n",
      "       50950., 50900., 51150., 50000., 49825., 49525., 48600., 48175.,\n",
      "       46925.]), array([50230., 49710., 48320., 48730., 49130., 49760., 50310., 51190.,\n",
      "       50210., 51870., 50340., 48550., 47160., 47250., 47030., 46300.,\n",
      "       44800., 45680., 47130., 48520., 48830., 47690., 47210., 47010.,\n",
      "       47280., 47320., 47880., 47550., 46400., 45620., 46460., 48060.,\n",
      "       48780., 49890., 50180., 51010., 51500., 51520., 50830., 50890.,\n",
      "       50650., 51420., 51410., 50160., 49660., 49770., 48720., 48940.,\n",
      "       49490., 48860., 47710., 47590., 48360., 47990., 48820., 48630.,\n",
      "       49250., 49160., 49790., 50230., 50180., 50970., 52260., 51840.,\n",
      "       51540., 50970., 49860., 51280., 53040., 53000., 53000., 53000.,\n",
      "       52850., 52550., 51850., 51150., 51700., 50500., 49750., 49675.,\n",
      "       49950., 49625., 49650., 51200., 51550., 51800., 52500., 51900.,\n",
      "       50300., 50325., 50825., 50950., 50900., 51150., 50000., 49825.,\n",
      "       49525., 48600., 48175., 46925., 46925., 47225., 47475., 46725.,\n",
      "       46600.]), array([49760., 50310., 51190., 50210., 51870., 50340., 48550., 47160.,\n",
      "       47250., 47030., 46300., 44800., 45680., 47130., 48520., 48830.,\n",
      "       47690., 47210., 47010., 47280., 47320., 47880., 47550., 46400.,\n",
      "       45620., 46460., 48060., 48780., 49890., 50180., 51010., 51500.,\n",
      "       51520., 50830., 50890., 50650., 51420., 51410., 50160., 49660.,\n",
      "       49770., 48720., 48940., 49490., 48860., 47710., 47590., 48360.,\n",
      "       47990., 48820., 48630., 49250., 49160., 49790., 50230., 50180.,\n",
      "       50970., 52260., 51840., 51540., 50970., 49860., 51280., 53040.,\n",
      "       53000., 53000., 53000., 52850., 52550., 51850., 51150., 51700.,\n",
      "       50500., 49750., 49675., 49950., 49625., 49650., 51200., 51550.,\n",
      "       51800., 52500., 51900., 50300., 50325., 50825., 50950., 50900.,\n",
      "       51150., 50000., 49825., 49525., 48600., 48175., 46925., 46925.,\n",
      "       47225., 47475., 46725., 46600., 46600., 47750., 46875., 46675.,\n",
      "       46325.]), array([50340., 48550., 47160., 47250., 47030., 46300., 44800., 45680.,\n",
      "       47130., 48520., 48830., 47690., 47210., 47010., 47280., 47320.,\n",
      "       47880., 47550., 46400., 45620., 46460., 48060., 48780., 49890.,\n",
      "       50180., 51010., 51500., 51520., 50830., 50890., 50650., 51420.,\n",
      "       51410., 50160., 49660., 49770., 48720., 48940., 49490., 48860.,\n",
      "       47710., 47590., 48360., 47990., 48820., 48630., 49250., 49160.,\n",
      "       49790., 50230., 50180., 50970., 52260., 51840., 51540., 50970.,\n",
      "       49860., 51280., 53040., 53000., 53000., 53000., 52850., 52550.,\n",
      "       51850., 51150., 51700., 50500., 49750., 49675., 49950., 49625.,\n",
      "       49650., 51200., 51550., 51800., 52500., 51900., 50300., 50325.,\n",
      "       50825., 50950., 50900., 51150., 50000., 49825., 49525., 48600.,\n",
      "       48175., 46925., 46925., 47225., 47475., 46725., 46600., 46600.,\n",
      "       47750., 46875., 46675., 46325., 46100., 46550., 46075., 45250.,\n",
      "       45650.]), array([46300., 44800., 45680., 47130., 48520., 48830., 47690., 47210.,\n",
      "       47010., 47280., 47320., 47880., 47550., 46400., 45620., 46460.,\n",
      "       48060., 48780., 49890., 50180., 51010., 51500., 51520., 50830.,\n",
      "       50890., 50650., 51420., 51410., 50160., 49660., 49770., 48720.,\n",
      "       48940., 49490., 48860., 47710., 47590., 48360., 47990., 48820.,\n",
      "       48630., 49250., 49160., 49790., 50230., 50180., 50970., 52260.,\n",
      "       51840., 51540., 50970., 49860., 51280., 53040., 53000., 53000.,\n",
      "       53000., 52850., 52550., 51850., 51150., 51700., 50500., 49750.,\n",
      "       49675., 49950., 49625., 49650., 51200., 51550., 51800., 52500.,\n",
      "       51900., 50300., 50325., 50825., 50950., 50900., 51150., 50000.,\n",
      "       49825., 49525., 48600., 48175., 46925., 46925., 47225., 47475.,\n",
      "       46725., 46600., 46600., 47750., 46875., 46675., 46325., 46100.,\n",
      "       46550., 46075., 45250., 45650., 46325., 45925., 45850., 46125.,\n",
      "       46400.]), array([48830., 47690., 47210., 47010., 47280., 47320., 47880., 47550.,\n",
      "       46400., 45620., 46460., 48060., 48780., 49890., 50180., 51010.,\n",
      "       51500., 51520., 50830., 50890., 50650., 51420., 51410., 50160.,\n",
      "       49660., 49770., 48720., 48940., 49490., 48860., 47710., 47590.,\n",
      "       48360., 47990., 48820., 48630., 49250., 49160., 49790., 50230.,\n",
      "       50180., 50970., 52260., 51840., 51540., 50970., 49860., 51280.,\n",
      "       53040., 53000., 53000., 53000., 52850., 52550., 51850., 51150.,\n",
      "       51700., 50500., 49750., 49675., 49950., 49625., 49650., 51200.,\n",
      "       51550., 51800., 52500., 51900., 50300., 50325., 50825., 50950.,\n",
      "       50900., 51150., 50000., 49825., 49525., 48600., 48175., 46925.,\n",
      "       46925., 47225., 47475., 46725., 46600., 46600., 47750., 46875.,\n",
      "       46675., 46325., 46100., 46550., 46075., 45250., 45650., 46325.,\n",
      "       45925., 45850., 46125., 46400., 45900., 46825., 46900., 47150.,\n",
      "       46675.]), array([47320., 47880., 47550., 46400., 45620., 46460., 48060., 48780.,\n",
      "       49890., 50180., 51010., 51500., 51520., 50830., 50890., 50650.,\n",
      "       51420., 51410., 50160., 49660., 49770., 48720., 48940., 49490.,\n",
      "       48860., 47710., 47590., 48360., 47990., 48820., 48630., 49250.,\n",
      "       49160., 49790., 50230., 50180., 50970., 52260., 51840., 51540.,\n",
      "       50970., 49860., 51280., 53040., 53000., 53000., 53000., 52850.,\n",
      "       52550., 51850., 51150., 51700., 50500., 49750., 49675., 49950.,\n",
      "       49625., 49650., 51200., 51550., 51800., 52500., 51900., 50300.,\n",
      "       50325., 50825., 50950., 50900., 51150., 50000., 49825., 49525.,\n",
      "       48600., 48175., 46925., 46925., 47225., 47475., 46725., 46600.,\n",
      "       46600., 47750., 46875., 46675., 46325., 46100., 46550., 46075.,\n",
      "       45250., 45650., 46325., 45925., 45850., 46125., 46400., 45900.,\n",
      "       46825., 46900., 47150., 46675., 46275., 46225., 46500., 46725.,\n",
      "       46575.]), array([46460., 48060., 48780., 49890., 50180., 51010., 51500., 51520.,\n",
      "       50830., 50890., 50650., 51420., 51410., 50160., 49660., 49770.,\n",
      "       48720., 48940., 49490., 48860., 47710., 47590., 48360., 47990.,\n",
      "       48820., 48630., 49250., 49160., 49790., 50230., 50180., 50970.,\n",
      "       52260., 51840., 51540., 50970., 49860., 51280., 53040., 53000.,\n",
      "       53000., 53000., 52850., 52550., 51850., 51150., 51700., 50500.,\n",
      "       49750., 49675., 49950., 49625., 49650., 51200., 51550., 51800.,\n",
      "       52500., 51900., 50300., 50325., 50825., 50950., 50900., 51150.,\n",
      "       50000., 49825., 49525., 48600., 48175., 46925., 46925., 47225.,\n",
      "       47475., 46725., 46600., 46600., 47750., 46875., 46675., 46325.,\n",
      "       46100., 46550., 46075., 45250., 45650., 46325., 45925., 45850.,\n",
      "       46125., 46400., 45900., 46825., 46900., 47150., 46675., 46275.,\n",
      "       46225., 46500., 46725., 46575., 46225., 46450., 46150., 45675.,\n",
      "       45950.]), array([51010., 51500., 51520., 50830., 50890., 50650., 51420., 51410.,\n",
      "       50160., 49660., 49770., 48720., 48940., 49490., 48860., 47710.,\n",
      "       47590., 48360., 47990., 48820., 48630., 49250., 49160., 49790.,\n",
      "       50230., 50180., 50970., 52260., 51840., 51540., 50970., 49860.,\n",
      "       51280., 53040., 53000., 53000., 53000., 52850., 52550., 51850.,\n",
      "       51150., 51700., 50500., 49750., 49675., 49950., 49625., 49650.,\n",
      "       51200., 51550., 51800., 52500., 51900., 50300., 50325., 50825.,\n",
      "       50950., 50900., 51150., 50000., 49825., 49525., 48600., 48175.,\n",
      "       46925., 46925., 47225., 47475., 46725., 46600., 46600., 47750.,\n",
      "       46875., 46675., 46325., 46100., 46550., 46075., 45250., 45650.,\n",
      "       46325., 45925., 45850., 46125., 46400., 45900., 46825., 46900.,\n",
      "       47150., 46675., 46275., 46225., 46500., 46725., 46575., 46225.,\n",
      "       46450., 46150., 45675., 45950., 46325., 46775., 46750., 45625.,\n",
      "       44875.]), array([50650., 51420., 51410., 50160., 49660., 49770., 48720., 48940.,\n",
      "       49490., 48860., 47710., 47590., 48360., 47990., 48820., 48630.,\n",
      "       49250., 49160., 49790., 50230., 50180., 50970., 52260., 51840.,\n",
      "       51540., 50970., 49860., 51280., 53040., 53000., 53000., 53000.,\n",
      "       52850., 52550., 51850., 51150., 51700., 50500., 49750., 49675.,\n",
      "       49950., 49625., 49650., 51200., 51550., 51800., 52500., 51900.,\n",
      "       50300., 50325., 50825., 50950., 50900., 51150., 50000., 49825.,\n",
      "       49525., 48600., 48175., 46925., 46925., 47225., 47475., 46725.,\n",
      "       46600., 46600., 47750., 46875., 46675., 46325., 46100., 46550.,\n",
      "       46075., 45250., 45650., 46325., 45925., 45850., 46125., 46400.,\n",
      "       45900., 46825., 46900., 47150., 46675., 46275., 46225., 46500.,\n",
      "       46725., 46575., 46225., 46450., 46150., 45675., 45950., 46325.,\n",
      "       46775., 46750., 45625., 44875., 45125., 44175., 44225., 43850.,\n",
      "       44300.]), array([49770., 48720., 48940., 49490., 48860., 47710., 47590., 48360.,\n",
      "       47990., 48820., 48630., 49250., 49160., 49790., 50230., 50180.,\n",
      "       50970., 52260., 51840., 51540., 50970., 49860., 51280., 53040.,\n",
      "       53000., 53000., 53000., 52850., 52550., 51850., 51150., 51700.,\n",
      "       50500., 49750., 49675., 49950., 49625., 49650., 51200., 51550.,\n",
      "       51800., 52500., 51900., 50300., 50325., 50825., 50950., 50900.,\n",
      "       51150., 50000., 49825., 49525., 48600., 48175., 46925., 46925.,\n",
      "       47225., 47475., 46725., 46600., 46600., 47750., 46875., 46675.,\n",
      "       46325., 46100., 46550., 46075., 45250., 45650., 46325., 45925.,\n",
      "       45850., 46125., 46400., 45900., 46825., 46900., 47150., 46675.,\n",
      "       46275., 46225., 46500., 46725., 46575., 46225., 46450., 46150.,\n",
      "       45675., 45950., 46325., 46775., 46750., 45625., 44875., 45125.,\n",
      "       44175., 44225., 43850., 44300., 45550., 45950., 45975., 46275.,\n",
      "       46625.]), array([47710., 47590., 48360., 47990., 48820., 48630., 49250., 49160.,\n",
      "       49790., 50230., 50180., 50970., 52260., 51840., 51540., 50970.,\n",
      "       49860., 51280., 53040., 53000., 53000., 53000., 52850., 52550.,\n",
      "       51850., 51150., 51700., 50500., 49750., 49675., 49950., 49625.,\n",
      "       49650., 51200., 51550., 51800., 52500., 51900., 50300., 50325.,\n",
      "       50825., 50950., 50900., 51150., 50000., 49825., 49525., 48600.,\n",
      "       48175., 46925., 46925., 47225., 47475., 46725., 46600., 46600.,\n",
      "       47750., 46875., 46675., 46325., 46100., 46550., 46075., 45250.,\n",
      "       45650., 46325., 45925., 45850., 46125., 46400., 45900., 46825.,\n",
      "       46900., 47150., 46675., 46275., 46225., 46500., 46725., 46575.,\n",
      "       46225., 46450., 46150., 45675., 45950., 46325., 46775., 46750.,\n",
      "       45625., 44875., 45125., 44175., 44225., 43850., 44300., 45550.,\n",
      "       45950., 45975., 46275., 46625., 46600., 47325., 47725., 47800.,\n",
      "       47500.]), array([48630., 49250., 49160., 49790., 50230., 50180., 50970., 52260.,\n",
      "       51840., 51540., 50970., 49860., 51280., 53040., 53000., 53000.,\n",
      "       53000., 52850., 52550., 51850., 51150., 51700., 50500., 49750.,\n",
      "       49675., 49950., 49625., 49650., 51200., 51550., 51800., 52500.,\n",
      "       51900., 50300., 50325., 50825., 50950., 50900., 51150., 50000.,\n",
      "       49825., 49525., 48600., 48175., 46925., 46925., 47225., 47475.,\n",
      "       46725., 46600., 46600., 47750., 46875., 46675., 46325., 46100.,\n",
      "       46550., 46075., 45250., 45650., 46325., 45925., 45850., 46125.,\n",
      "       46400., 45900., 46825., 46900., 47150., 46675., 46275., 46225.,\n",
      "       46500., 46725., 46575., 46225., 46450., 46150., 45675., 45950.,\n",
      "       46325., 46775., 46750., 45625., 44875., 45125., 44175., 44225.,\n",
      "       43850., 44300., 45550., 45950., 45975., 46275., 46625., 46600.,\n",
      "       47325., 47725., 47800., 47500., 46925., 46100., 44800., 45275.,\n",
      "       45475.]), array([50180., 50970., 52260., 51840., 51540., 50970., 49860., 51280.,\n",
      "       53040., 53000., 53000., 53000., 52850., 52550., 51850., 51150.,\n",
      "       51700., 50500., 49750., 49675., 49950., 49625., 49650., 51200.,\n",
      "       51550., 51800., 52500., 51900., 50300., 50325., 50825., 50950.,\n",
      "       50900., 51150., 50000., 49825., 49525., 48600., 48175., 46925.,\n",
      "       46925., 47225., 47475., 46725., 46600., 46600., 47750., 46875.,\n",
      "       46675., 46325., 46100., 46550., 46075., 45250., 45650., 46325.,\n",
      "       45925., 45850., 46125., 46400., 45900., 46825., 46900., 47150.,\n",
      "       46675., 46275., 46225., 46500., 46725., 46575., 46225., 46450.,\n",
      "       46150., 45675., 45950., 46325., 46775., 46750., 45625., 44875.,\n",
      "       45125., 44175., 44225., 43850., 44300., 45550., 45950., 45975.,\n",
      "       46275., 46625., 46600., 47325., 47725., 47800., 47500., 46925.,\n",
      "       46100., 44800., 45275., 45475., 44800., 44375., 45375., 45350.,\n",
      "       45300.]), array([50970., 49860., 51280., 53040., 53000., 53000., 53000., 52850.,\n",
      "       52550., 51850., 51150., 51700., 50500., 49750., 49675., 49950.,\n",
      "       49625., 49650., 51200., 51550., 51800., 52500., 51900., 50300.,\n",
      "       50325., 50825., 50950., 50900., 51150., 50000., 49825., 49525.,\n",
      "       48600., 48175., 46925., 46925., 47225., 47475., 46725., 46600.,\n",
      "       46600., 47750., 46875., 46675., 46325., 46100., 46550., 46075.,\n",
      "       45250., 45650., 46325., 45925., 45850., 46125., 46400., 45900.,\n",
      "       46825., 46900., 47150., 46675., 46275., 46225., 46500., 46725.,\n",
      "       46575., 46225., 46450., 46150., 45675., 45950., 46325., 46775.,\n",
      "       46750., 45625., 44875., 45125., 44175., 44225., 43850., 44300.,\n",
      "       45550., 45950., 45975., 46275., 46625., 46600., 47325., 47725.,\n",
      "       47800., 47500., 46925., 46100., 44800., 45275., 45475., 44800.,\n",
      "       44375., 45375., 45350., 45300., 45950., 47000., 47050., 46975.,\n",
      "       46775.]), array([53000., 53000., 52850., 52550., 51850., 51150., 51700., 50500.,\n",
      "       49750., 49675., 49950., 49625., 49650., 51200., 51550., 51800.,\n",
      "       52500., 51900., 50300., 50325., 50825., 50950., 50900., 51150.,\n",
      "       50000., 49825., 49525., 48600., 48175., 46925., 46925., 47225.,\n",
      "       47475., 46725., 46600., 46600., 47750., 46875., 46675., 46325.,\n",
      "       46100., 46550., 46075., 45250., 45650., 46325., 45925., 45850.,\n",
      "       46125., 46400., 45900., 46825., 46900., 47150., 46675., 46275.,\n",
      "       46225., 46500., 46725., 46575., 46225., 46450., 46150., 45675.,\n",
      "       45950., 46325., 46775., 46750., 45625., 44875., 45125., 44175.,\n",
      "       44225., 43850., 44300., 45550., 45950., 45975., 46275., 46625.,\n",
      "       46600., 47325., 47725., 47800., 47500., 46925., 46100., 44800.,\n",
      "       45275., 45475., 44800., 44375., 45375., 45350., 45300., 45950.,\n",
      "       47000., 47050., 46975., 46775., 46300., 46200., 45150., 45025.,\n",
      "       44700.]), array([51150., 51700., 50500., 49750., 49675., 49950., 49625., 49650.,\n",
      "       51200., 51550., 51800., 52500., 51900., 50300., 50325., 50825.,\n",
      "       50950., 50900., 51150., 50000., 49825., 49525., 48600., 48175.,\n",
      "       46925., 46925., 47225., 47475., 46725., 46600., 46600., 47750.,\n",
      "       46875., 46675., 46325., 46100., 46550., 46075., 45250., 45650.,\n",
      "       46325., 45925., 45850., 46125., 46400., 45900., 46825., 46900.,\n",
      "       47150., 46675., 46275., 46225., 46500., 46725., 46575., 46225.,\n",
      "       46450., 46150., 45675., 45950., 46325., 46775., 46750., 45625.,\n",
      "       44875., 45125., 44175., 44225., 43850., 44300., 45550., 45950.,\n",
      "       45975., 46275., 46625., 46600., 47325., 47725., 47800., 47500.,\n",
      "       46925., 46100., 44800., 45275., 45475., 44800., 44375., 45375.,\n",
      "       45350., 45300., 45950., 47000., 47050., 46975., 46775., 46300.,\n",
      "       46200., 45150., 45025., 44700., 45000., 43875., 43925., 43700.,\n",
      "       43750.]), array([49950., 49625., 49650., 51200., 51550., 51800., 52500., 51900.,\n",
      "       50300., 50325., 50825., 50950., 50900., 51150., 50000., 49825.,\n",
      "       49525., 48600., 48175., 46925., 46925., 47225., 47475., 46725.,\n",
      "       46600., 46600., 47750., 46875., 46675., 46325., 46100., 46550.,\n",
      "       46075., 45250., 45650., 46325., 45925., 45850., 46125., 46400.,\n",
      "       45900., 46825., 46900., 47150., 46675., 46275., 46225., 46500.,\n",
      "       46725., 46575., 46225., 46450., 46150., 45675., 45950., 46325.,\n",
      "       46775., 46750., 45625., 44875., 45125., 44175., 44225., 43850.,\n",
      "       44300., 45550., 45950., 45975., 46275., 46625., 46600., 47325.,\n",
      "       47725., 47800., 47500., 46925., 46100., 44800., 45275., 45475.,\n",
      "       44800., 44375., 45375., 45350., 45300., 45950., 47000., 47050.,\n",
      "       46975., 46775., 46300., 46200., 45150., 45025., 44700., 45000.,\n",
      "       43875., 43925., 43700., 43750., 44250., 44075., 43800., 43575.,\n",
      "       43000.]), array([51800., 52500., 51900., 50300., 50325., 50825., 50950., 50900.,\n",
      "       51150., 50000., 49825., 49525., 48600., 48175., 46925., 46925.,\n",
      "       47225., 47475., 46725., 46600., 46600., 47750., 46875., 46675.,\n",
      "       46325., 46100., 46550., 46075., 45250., 45650., 46325., 45925.,\n",
      "       45850., 46125., 46400., 45900., 46825., 46900., 47150., 46675.,\n",
      "       46275., 46225., 46500., 46725., 46575., 46225., 46450., 46150.,\n",
      "       45675., 45950., 46325., 46775., 46750., 45625., 44875., 45125.,\n",
      "       44175., 44225., 43850., 44300., 45550., 45950., 45975., 46275.,\n",
      "       46625., 46600., 47325., 47725., 47800., 47500., 46925., 46100.,\n",
      "       44800., 45275., 45475., 44800., 44375., 45375., 45350., 45300.,\n",
      "       45950., 47000., 47050., 46975., 46775., 46300., 46200., 45150.,\n",
      "       45025., 44700., 45000., 43875., 43925., 43700., 43750., 44250.,\n",
      "       44075., 43800., 43575., 43000., 42675., 41050., 40850., 41250.,\n",
      "       42000.]), array([50825., 50950., 50900., 51150., 50000., 49825., 49525., 48600.,\n",
      "       48175., 46925., 46925., 47225., 47475., 46725., 46600., 46600.,\n",
      "       47750., 46875., 46675., 46325., 46100., 46550., 46075., 45250.,\n",
      "       45650., 46325., 45925., 45850., 46125., 46400., 45900., 46825.,\n",
      "       46900., 47150., 46675., 46275., 46225., 46500., 46725., 46575.,\n",
      "       46225., 46450., 46150., 45675., 45950., 46325., 46775., 46750.,\n",
      "       45625., 44875., 45125., 44175., 44225., 43850., 44300., 45550.,\n",
      "       45950., 45975., 46275., 46625., 46600., 47325., 47725., 47800.,\n",
      "       47500., 46925., 46100., 44800., 45275., 45475., 44800., 44375.,\n",
      "       45375., 45350., 45300., 45950., 47000., 47050., 46975., 46775.,\n",
      "       46300., 46200., 45150., 45025., 44700., 45000., 43875., 43925.,\n",
      "       43700., 43750., 44250., 44075., 43800., 43575., 43000., 42675.,\n",
      "       41050., 40850., 41250., 42000., 42525., 42550., 43525., 43350.,\n",
      "       43375.]), array([49825., 49525., 48600., 48175., 46925., 46925., 47225., 47475.,\n",
      "       46725., 46600., 46600., 47750., 46875., 46675., 46325., 46100.,\n",
      "       46550., 46075., 45250., 45650., 46325., 45925., 45850., 46125.,\n",
      "       46400., 45900., 46825., 46900., 47150., 46675., 46275., 46225.,\n",
      "       46500., 46725., 46575., 46225., 46450., 46150., 45675., 45950.,\n",
      "       46325., 46775., 46750., 45625., 44875., 45125., 44175., 44225.,\n",
      "       43850., 44300., 45550., 45950., 45975., 46275., 46625., 46600.,\n",
      "       47325., 47725., 47800., 47500., 46925., 46100., 44800., 45275.,\n",
      "       45475., 44800., 44375., 45375., 45350., 45300., 45950., 47000.,\n",
      "       47050., 46975., 46775., 46300., 46200., 45150., 45025., 44700.,\n",
      "       45000., 43875., 43925., 43700., 43750., 44250., 44075., 43800.,\n",
      "       43575., 43000., 42675., 41050., 40850., 41250., 42000., 42525.,\n",
      "       42550., 43525., 43350., 43375., 43950., 44550., 44375., 44475.,\n",
      "       43950.]), array([46925., 47225., 47475., 46725., 46600., 46600., 47750., 46875.,\n",
      "       46675., 46325., 46100., 46550., 46075., 45250., 45650., 46325.,\n",
      "       45925., 45850., 46125., 46400., 45900., 46825., 46900., 47150.,\n",
      "       46675., 46275., 46225., 46500., 46725., 46575., 46225., 46450.,\n",
      "       46150., 45675., 45950., 46325., 46775., 46750., 45625., 44875.,\n",
      "       45125., 44175., 44225., 43850., 44300., 45550., 45950., 45975.,\n",
      "       46275., 46625., 46600., 47325., 47725., 47800., 47500., 46925.,\n",
      "       46100., 44800., 45275., 45475., 44800., 44375., 45375., 45350.,\n",
      "       45300., 45950., 47000., 47050., 46975., 46775., 46300., 46200.,\n",
      "       45150., 45025., 44700., 45000., 43875., 43925., 43700., 43750.,\n",
      "       44250., 44075., 43800., 43575., 43000., 42675., 41050., 40850.,\n",
      "       41250., 42000., 42525., 42550., 43525., 43350., 43375., 43950.,\n",
      "       44550., 44375., 44475., 43950., 44150., 44225., 43850., 42550.,\n",
      "       42050.]), array([46600., 47750., 46875., 46675., 46325., 46100., 46550., 46075.,\n",
      "       45250., 45650., 46325., 45925., 45850., 46125., 46400., 45900.,\n",
      "       46825., 46900., 47150., 46675., 46275., 46225., 46500., 46725.,\n",
      "       46575., 46225., 46450., 46150., 45675., 45950., 46325., 46775.,\n",
      "       46750., 45625., 44875., 45125., 44175., 44225., 43850., 44300.,\n",
      "       45550., 45950., 45975., 46275., 46625., 46600., 47325., 47725.,\n",
      "       47800., 47500., 46925., 46100., 44800., 45275., 45475., 44800.,\n",
      "       44375., 45375., 45350., 45300., 45950., 47000., 47050., 46975.,\n",
      "       46775., 46300., 46200., 45150., 45025., 44700., 45000., 43875.,\n",
      "       43925., 43700., 43750., 44250., 44075., 43800., 43575., 43000.,\n",
      "       42675., 41050., 40850., 41250., 42000., 42525., 42550., 43525.,\n",
      "       43350., 43375., 43950., 44550., 44375., 44475., 43950., 44150.,\n",
      "       44225., 43850., 42550., 42050., 42325., 42250., 42450., 42800.,\n",
      "       42975.]), array([46100., 46550., 46075., 45250., 45650., 46325., 45925., 45850.,\n",
      "       46125., 46400., 45900., 46825., 46900., 47150., 46675., 46275.,\n",
      "       46225., 46500., 46725., 46575., 46225., 46450., 46150., 45675.,\n",
      "       45950., 46325., 46775., 46750., 45625., 44875., 45125., 44175.,\n",
      "       44225., 43850., 44300., 45550., 45950., 45975., 46275., 46625.,\n",
      "       46600., 47325., 47725., 47800., 47500., 46925., 46100., 44800.,\n",
      "       45275., 45475., 44800., 44375., 45375., 45350., 45300., 45950.,\n",
      "       47000., 47050., 46975., 46775., 46300., 46200., 45150., 45025.,\n",
      "       44700., 45000., 43875., 43925., 43700., 43750., 44250., 44075.,\n",
      "       43800., 43575., 43000., 42675., 41050., 40850., 41250., 42000.,\n",
      "       42525., 42550., 43525., 43350., 43375., 43950., 44550., 44375.,\n",
      "       44475., 43950., 44150., 44225., 43850., 42550., 42050., 42325.,\n",
      "       42250., 42450., 42800., 42975., 43375., 42875., 42900., 42400.,\n",
      "       41300.]), array([46325., 45925., 45850., 46125., 46400., 45900., 46825., 46900.,\n",
      "       47150., 46675., 46275., 46225., 46500., 46725., 46575., 46225.,\n",
      "       46450., 46150., 45675., 45950., 46325., 46775., 46750., 45625.,\n",
      "       44875., 45125., 44175., 44225., 43850., 44300., 45550., 45950.,\n",
      "       45975., 46275., 46625., 46600., 47325., 47725., 47800., 47500.,\n",
      "       46925., 46100., 44800., 45275., 45475., 44800., 44375., 45375.,\n",
      "       45350., 45300., 45950., 47000., 47050., 46975., 46775., 46300.,\n",
      "       46200., 45150., 45025., 44700., 45000., 43875., 43925., 43700.,\n",
      "       43750., 44250., 44075., 43800., 43575., 43000., 42675., 41050.,\n",
      "       40850., 41250., 42000., 42525., 42550., 43525., 43350., 43375.,\n",
      "       43950., 44550., 44375., 44475., 43950., 44150., 44225., 43850.,\n",
      "       42550., 42050., 42325., 42250., 42450., 42800., 42975., 43375.,\n",
      "       42875., 42900., 42400., 41300., 40775., 41125., 40325., 40450.,\n",
      "       40425.]), array([45900., 46825., 46900., 47150., 46675., 46275., 46225., 46500.,\n",
      "       46725., 46575., 46225., 46450., 46150., 45675., 45950., 46325.,\n",
      "       46775., 46750., 45625., 44875., 45125., 44175., 44225., 43850.,\n",
      "       44300., 45550., 45950., 45975., 46275., 46625., 46600., 47325.,\n",
      "       47725., 47800., 47500., 46925., 46100., 44800., 45275., 45475.,\n",
      "       44800., 44375., 45375., 45350., 45300., 45950., 47000., 47050.,\n",
      "       46975., 46775., 46300., 46200., 45150., 45025., 44700., 45000.,\n",
      "       43875., 43925., 43700., 43750., 44250., 44075., 43800., 43575.,\n",
      "       43000., 42675., 41050., 40850., 41250., 42000., 42525., 42550.,\n",
      "       43525., 43350., 43375., 43950., 44550., 44375., 44475., 43950.,\n",
      "       44150., 44225., 43850., 42550., 42050., 42325., 42250., 42450.,\n",
      "       42800., 42975., 43375., 42875., 42900., 42400., 41300., 40775.,\n",
      "       41125., 40325., 40450., 40425., 40375., 39450., 39125., 38750.,\n",
      "       39100.]), array([46275., 46225., 46500., 46725., 46575., 46225., 46450., 46150.,\n",
      "       45675., 45950., 46325., 46775., 46750., 45625., 44875., 45125.,\n",
      "       44175., 44225., 43850., 44300., 45550., 45950., 45975., 46275.,\n",
      "       46625., 46600., 47325., 47725., 47800., 47500., 46925., 46100.,\n",
      "       44800., 45275., 45475., 44800., 44375., 45375., 45350., 45300.,\n",
      "       45950., 47000., 47050., 46975., 46775., 46300., 46200., 45150.,\n",
      "       45025., 44700., 45000., 43875., 43925., 43700., 43750., 44250.,\n",
      "       44075., 43800., 43575., 43000., 42675., 41050., 40850., 41250.,\n",
      "       42000., 42525., 42550., 43525., 43350., 43375., 43950., 44550.,\n",
      "       44375., 44475., 43950., 44150., 44225., 43850., 42550., 42050.,\n",
      "       42325., 42250., 42450., 42800., 42975., 43375., 42875., 42900.,\n",
      "       42400., 41300., 40775., 41125., 40325., 40450., 40425., 40375.,\n",
      "       39450., 39125., 38750., 39100., 38800., 38375., 38675., 38525.,\n",
      "       38450.]), array([46225., 46450., 46150., 45675., 45950., 46325., 46775., 46750.,\n",
      "       45625., 44875., 45125., 44175., 44225., 43850., 44300., 45550.,\n",
      "       45950., 45975., 46275., 46625., 46600., 47325., 47725., 47800.,\n",
      "       47500., 46925., 46100., 44800., 45275., 45475., 44800., 44375.,\n",
      "       45375., 45350., 45300., 45950., 47000., 47050., 46975., 46775.,\n",
      "       46300., 46200., 45150., 45025., 44700., 45000., 43875., 43925.,\n",
      "       43700., 43750., 44250., 44075., 43800., 43575., 43000., 42675.,\n",
      "       41050., 40850., 41250., 42000., 42525., 42550., 43525., 43350.,\n",
      "       43375., 43950., 44550., 44375., 44475., 43950., 44150., 44225.,\n",
      "       43850., 42550., 42050., 42325., 42250., 42450., 42800., 42975.,\n",
      "       43375., 42875., 42900., 42400., 41300., 40775., 41125., 40325.,\n",
      "       40450., 40425., 40375., 39450., 39125., 38750., 39100., 38800.,\n",
      "       38375., 38675., 38525., 38450., 38550., 38975., 38000., 37225.,\n",
      "       38350.]), array([46325., 46775., 46750., 45625., 44875., 45125., 44175., 44225.,\n",
      "       43850., 44300., 45550., 45950., 45975., 46275., 46625., 46600.,\n",
      "       47325., 47725., 47800., 47500., 46925., 46100., 44800., 45275.,\n",
      "       45475., 44800., 44375., 45375., 45350., 45300., 45950., 47000.,\n",
      "       47050., 46975., 46775., 46300., 46200., 45150., 45025., 44700.,\n",
      "       45000., 43875., 43925., 43700., 43750., 44250., 44075., 43800.,\n",
      "       43575., 43000., 42675., 41050., 40850., 41250., 42000., 42525.,\n",
      "       42550., 43525., 43350., 43375., 43950., 44550., 44375., 44475.,\n",
      "       43950., 44150., 44225., 43850., 42550., 42050., 42325., 42250.,\n",
      "       42450., 42800., 42975., 43375., 42875., 42900., 42400., 41300.,\n",
      "       40775., 41125., 40325., 40450., 40425., 40375., 39450., 39125.,\n",
      "       38750., 39100., 38800., 38375., 38675., 38525., 38450., 38550.,\n",
      "       38975., 38000., 37225., 38350., 38575., 38950., 39875., 40250.,\n",
      "       40275.]), array([45125., 44175., 44225., 43850., 44300., 45550., 45950., 45975.,\n",
      "       46275., 46625., 46600., 47325., 47725., 47800., 47500., 46925.,\n",
      "       46100., 44800., 45275., 45475., 44800., 44375., 45375., 45350.,\n",
      "       45300., 45950., 47000., 47050., 46975., 46775., 46300., 46200.,\n",
      "       45150., 45025., 44700., 45000., 43875., 43925., 43700., 43750.,\n",
      "       44250., 44075., 43800., 43575., 43000., 42675., 41050., 40850.,\n",
      "       41250., 42000., 42525., 42550., 43525., 43350., 43375., 43950.,\n",
      "       44550., 44375., 44475., 43950., 44150., 44225., 43850., 42550.,\n",
      "       42050., 42325., 42250., 42450., 42800., 42975., 43375., 42875.,\n",
      "       42900., 42400., 41300., 40775., 41125., 40325., 40450., 40425.,\n",
      "       40375., 39450., 39125., 38750., 39100., 38800., 38375., 38675.,\n",
      "       38525., 38450., 38550., 38975., 38000., 37225., 38350., 38575.,\n",
      "       38950., 39875., 40250., 40275., 40475., 41075., 41775., 42175.,\n",
      "       42325.]), array([45550., 45950., 45975., 46275., 46625., 46600., 47325., 47725.,\n",
      "       47800., 47500., 46925., 46100., 44800., 45275., 45475., 44800.,\n",
      "       44375., 45375., 45350., 45300., 45950., 47000., 47050., 46975.,\n",
      "       46775., 46300., 46200., 45150., 45025., 44700., 45000., 43875.,\n",
      "       43925., 43700., 43750., 44250., 44075., 43800., 43575., 43000.,\n",
      "       42675., 41050., 40850., 41250., 42000., 42525., 42550., 43525.,\n",
      "       43350., 43375., 43950., 44550., 44375., 44475., 43950., 44150.,\n",
      "       44225., 43850., 42550., 42050., 42325., 42250., 42450., 42800.,\n",
      "       42975., 43375., 42875., 42900., 42400., 41300., 40775., 41125.,\n",
      "       40325., 40450., 40425., 40375., 39450., 39125., 38750., 39100.,\n",
      "       38800., 38375., 38675., 38525., 38450., 38550., 38975., 38000.,\n",
      "       37225., 38350., 38575., 38950., 39875., 40250., 40275., 40475.,\n",
      "       41075., 41775., 42175., 42325., 42350., 41800., 42725., 44250.,\n",
      "       45050.]), array([46600., 47325., 47725., 47800., 47500., 46925., 46100., 44800.,\n",
      "       45275., 45475., 44800., 44375., 45375., 45350., 45300., 45950.,\n",
      "       47000., 47050., 46975., 46775., 46300., 46200., 45150., 45025.,\n",
      "       44700., 45000., 43875., 43925., 43700., 43750., 44250., 44075.,\n",
      "       43800., 43575., 43000., 42675., 41050., 40850., 41250., 42000.,\n",
      "       42525., 42550., 43525., 43350., 43375., 43950., 44550., 44375.,\n",
      "       44475., 43950., 44150., 44225., 43850., 42550., 42050., 42325.,\n",
      "       42250., 42450., 42800., 42975., 43375., 42875., 42900., 42400.,\n",
      "       41300., 40775., 41125., 40325., 40450., 40425., 40375., 39450.,\n",
      "       39125., 38750., 39100., 38800., 38375., 38675., 38525., 38450.,\n",
      "       38550., 38975., 38000., 37225., 38350., 38575., 38950., 39875.,\n",
      "       40250., 40275., 40475., 41075., 41775., 42175., 42325., 42350.,\n",
      "       41800., 42725., 44250., 45050., 44925., 45600., 46600., 46600.,\n",
      "       46650.]), array([46925., 46100., 44800., 45275., 45475., 44800., 44375., 45375.,\n",
      "       45350., 45300., 45950., 47000., 47050., 46975., 46775., 46300.,\n",
      "       46200., 45150., 45025., 44700., 45000., 43875., 43925., 43700.,\n",
      "       43750., 44250., 44075., 43800., 43575., 43000., 42675., 41050.,\n",
      "       40850., 41250., 42000., 42525., 42550., 43525., 43350., 43375.,\n",
      "       43950., 44550., 44375., 44475., 43950., 44150., 44225., 43850.,\n",
      "       42550., 42050., 42325., 42250., 42450., 42800., 42975., 43375.,\n",
      "       42875., 42900., 42400., 41300., 40775., 41125., 40325., 40450.,\n",
      "       40425., 40375., 39450., 39125., 38750., 39100., 38800., 38375.,\n",
      "       38675., 38525., 38450., 38550., 38975., 38000., 37225., 38350.,\n",
      "       38575., 38950., 39875., 40250., 40275., 40475., 41075., 41775.,\n",
      "       42175., 42325., 42350., 41800., 42725., 44250., 45050., 44925.,\n",
      "       45600., 46600., 46600., 46650., 45175., 44625., 45450., 46350.,\n",
      "       46825.]), array([44800., 44375., 45375., 45350., 45300., 45950., 47000., 47050.,\n",
      "       46975., 46775., 46300., 46200., 45150., 45025., 44700., 45000.,\n",
      "       43875., 43925., 43700., 43750., 44250., 44075., 43800., 43575.,\n",
      "       43000., 42675., 41050., 40850., 41250., 42000., 42525., 42550.,\n",
      "       43525., 43350., 43375., 43950., 44550., 44375., 44475., 43950.,\n",
      "       44150., 44225., 43850., 42550., 42050., 42325., 42250., 42450.,\n",
      "       42800., 42975., 43375., 42875., 42900., 42400., 41300., 40775.,\n",
      "       41125., 40325., 40450., 40425., 40375., 39450., 39125., 38750.,\n",
      "       39100., 38800., 38375., 38675., 38525., 38450., 38550., 38975.,\n",
      "       38000., 37225., 38350., 38575., 38950., 39875., 40250., 40275.,\n",
      "       40475., 41075., 41775., 42175., 42325., 42350., 41800., 42725.,\n",
      "       44250., 45050., 44925., 45600., 46600., 46600., 46650., 45175.,\n",
      "       44625., 45450., 46350., 46825., 46250., 46350., 45800., 46800.,\n",
      "       46700.]), array([45950., 47000., 47050., 46975., 46775., 46300., 46200., 45150.,\n",
      "       45025., 44700., 45000., 43875., 43925., 43700., 43750., 44250.,\n",
      "       44075., 43800., 43575., 43000., 42675., 41050., 40850., 41250.,\n",
      "       42000., 42525., 42550., 43525., 43350., 43375., 43950., 44550.,\n",
      "       44375., 44475., 43950., 44150., 44225., 43850., 42550., 42050.,\n",
      "       42325., 42250., 42450., 42800., 42975., 43375., 42875., 42900.,\n",
      "       42400., 41300., 40775., 41125., 40325., 40450., 40425., 40375.,\n",
      "       39450., 39125., 38750., 39100., 38800., 38375., 38675., 38525.,\n",
      "       38450., 38550., 38975., 38000., 37225., 38350., 38575., 38950.,\n",
      "       39875., 40250., 40275., 40475., 41075., 41775., 42175., 42325.,\n",
      "       42350., 41800., 42725., 44250., 45050., 44925., 45600., 46600.,\n",
      "       46600., 46650., 45175., 44625., 45450., 46350., 46825., 46250.,\n",
      "       46350., 45800., 46800., 46700., 46800., 47300., 46975., 47000.,\n",
      "       45800.]), array([46300., 46200., 45150., 45025., 44700., 45000., 43875., 43925.,\n",
      "       43700., 43750., 44250., 44075., 43800., 43575., 43000., 42675.,\n",
      "       41050., 40850., 41250., 42000., 42525., 42550., 43525., 43350.,\n",
      "       43375., 43950., 44550., 44375., 44475., 43950., 44150., 44225.,\n",
      "       43850., 42550., 42050., 42325., 42250., 42450., 42800., 42975.,\n",
      "       43375., 42875., 42900., 42400., 41300., 40775., 41125., 40325.,\n",
      "       40450., 40425., 40375., 39450., 39125., 38750., 39100., 38800.,\n",
      "       38375., 38675., 38525., 38450., 38550., 38975., 38000., 37225.,\n",
      "       38350., 38575., 38950., 39875., 40250., 40275., 40475., 41075.,\n",
      "       41775., 42175., 42325., 42350., 41800., 42725., 44250., 45050.,\n",
      "       44925., 45600., 46600., 46600., 46650., 45175., 44625., 45450.,\n",
      "       46350., 46825., 46250., 46350., 45800., 46800., 46700., 46800.,\n",
      "       47300., 46975., 47000., 45800., 45450., 44625., 44000., 44175.,\n",
      "       44300.]), array([45000., 43875., 43925., 43700., 43750., 44250., 44075., 43800.,\n",
      "       43575., 43000., 42675., 41050., 40850., 41250., 42000., 42525.,\n",
      "       42550., 43525., 43350., 43375., 43950., 44550., 44375., 44475.,\n",
      "       43950., 44150., 44225., 43850., 42550., 42050., 42325., 42250.,\n",
      "       42450., 42800., 42975., 43375., 42875., 42900., 42400., 41300.,\n",
      "       40775., 41125., 40325., 40450., 40425., 40375., 39450., 39125.,\n",
      "       38750., 39100., 38800., 38375., 38675., 38525., 38450., 38550.,\n",
      "       38975., 38000., 37225., 38350., 38575., 38950., 39875., 40250.,\n",
      "       40275., 40475., 41075., 41775., 42175., 42325., 42350., 41800.,\n",
      "       42725., 44250., 45050., 44925., 45600., 46600., 46600., 46650.,\n",
      "       45175., 44625., 45450., 46350., 46825., 46250., 46350., 45800.,\n",
      "       46800., 46700., 46800., 47300., 46975., 47000., 45800., 45450.,\n",
      "       44625., 44000., 44175., 44300., 44050., 44550., 44075., 43925.,\n",
      "       43975.]), array([44250., 44075., 43800., 43575., 43000., 42675., 41050., 40850.,\n",
      "       41250., 42000., 42525., 42550., 43525., 43350., 43375., 43950.,\n",
      "       44550., 44375., 44475., 43950., 44150., 44225., 43850., 42550.,\n",
      "       42050., 42325., 42250., 42450., 42800., 42975., 43375., 42875.,\n",
      "       42900., 42400., 41300., 40775., 41125., 40325., 40450., 40425.,\n",
      "       40375., 39450., 39125., 38750., 39100., 38800., 38375., 38675.,\n",
      "       38525., 38450., 38550., 38975., 38000., 37225., 38350., 38575.,\n",
      "       38950., 39875., 40250., 40275., 40475., 41075., 41775., 42175.,\n",
      "       42325., 42350., 41800., 42725., 44250., 45050., 44925., 45600.,\n",
      "       46600., 46600., 46650., 45175., 44625., 45450., 46350., 46825.,\n",
      "       46250., 46350., 45800., 46800., 46700., 46800., 47300., 46975.,\n",
      "       47000., 45800., 45450., 44625., 44000., 44175., 44300., 44050.,\n",
      "       44550., 44075., 43925., 43975., 43800., 43725., 43650., 45150.,\n",
      "       46625.]), array([42675., 41050., 40850., 41250., 42000., 42525., 42550., 43525.,\n",
      "       43350., 43375., 43950., 44550., 44375., 44475., 43950., 44150.,\n",
      "       44225., 43850., 42550., 42050., 42325., 42250., 42450., 42800.,\n",
      "       42975., 43375., 42875., 42900., 42400., 41300., 40775., 41125.,\n",
      "       40325., 40450., 40425., 40375., 39450., 39125., 38750., 39100.,\n",
      "       38800., 38375., 38675., 38525., 38450., 38550., 38975., 38000.,\n",
      "       37225., 38350., 38575., 38950., 39875., 40250., 40275., 40475.,\n",
      "       41075., 41775., 42175., 42325., 42350., 41800., 42725., 44250.,\n",
      "       45050., 44925., 45600., 46600., 46600., 46650., 45175., 44625.,\n",
      "       45450., 46350., 46825., 46250., 46350., 45800., 46800., 46700.,\n",
      "       46800., 47300., 46975., 47000., 45800., 45450., 44625., 44000.,\n",
      "       44175., 44300., 44050., 44550., 44075., 43925., 43975., 43800.,\n",
      "       43725., 43650., 45150., 46625., 45225., 45300., 44925., 44750.,\n",
      "       44550.]), array([42525., 42550., 43525., 43350., 43375., 43950., 44550., 44375.,\n",
      "       44475., 43950., 44150., 44225., 43850., 42550., 42050., 42325.,\n",
      "       42250., 42450., 42800., 42975., 43375., 42875., 42900., 42400.,\n",
      "       41300., 40775., 41125., 40325., 40450., 40425., 40375., 39450.,\n",
      "       39125., 38750., 39100., 38800., 38375., 38675., 38525., 38450.,\n",
      "       38550., 38975., 38000., 37225., 38350., 38575., 38950., 39875.,\n",
      "       40250., 40275., 40475., 41075., 41775., 42175., 42325., 42350.,\n",
      "       41800., 42725., 44250., 45050., 44925., 45600., 46600., 46600.,\n",
      "       46650., 45175., 44625., 45450., 46350., 46825., 46250., 46350.,\n",
      "       45800., 46800., 46700., 46800., 47300., 46975., 47000., 45800.,\n",
      "       45450., 44625., 44000., 44175., 44300., 44050., 44550., 44075.,\n",
      "       43925., 43975., 43800., 43725., 43650., 45150., 46625., 45225.,\n",
      "       45300., 44925., 44750., 44550., 45150., 45725., 46275., 46625.,\n",
      "       47075.]), array([43950., 44550., 44375., 44475., 43950., 44150., 44225., 43850.,\n",
      "       42550., 42050., 42325., 42250., 42450., 42800., 42975., 43375.,\n",
      "       42875., 42900., 42400., 41300., 40775., 41125., 40325., 40450.,\n",
      "       40425., 40375., 39450., 39125., 38750., 39100., 38800., 38375.,\n",
      "       38675., 38525., 38450., 38550., 38975., 38000., 37225., 38350.,\n",
      "       38575., 38950., 39875., 40250., 40275., 40475., 41075., 41775.,\n",
      "       42175., 42325., 42350., 41800., 42725., 44250., 45050., 44925.,\n",
      "       45600., 46600., 46600., 46650., 45175., 44625., 45450., 46350.,\n",
      "       46825., 46250., 46350., 45800., 46800., 46700., 46800., 47300.,\n",
      "       46975., 47000., 45800., 45450., 44625., 44000., 44175., 44300.,\n",
      "       44050., 44550., 44075., 43925., 43975., 43800., 43725., 43650.,\n",
      "       45150., 46625., 45225., 45300., 44925., 44750., 44550., 45150.,\n",
      "       45725., 46275., 46625., 47075., 46700., 46575., 46375., 46475.,\n",
      "       46450.]), array([44150., 44225., 43850., 42550., 42050., 42325., 42250., 42450.,\n",
      "       42800., 42975., 43375., 42875., 42900., 42400., 41300., 40775.,\n",
      "       41125., 40325., 40450., 40425., 40375., 39450., 39125., 38750.,\n",
      "       39100., 38800., 38375., 38675., 38525., 38450., 38550., 38975.,\n",
      "       38000., 37225., 38350., 38575., 38950., 39875., 40250., 40275.,\n",
      "       40475., 41075., 41775., 42175., 42325., 42350., 41800., 42725.,\n",
      "       44250., 45050., 44925., 45600., 46600., 46600., 46650., 45175.,\n",
      "       44625., 45450., 46350., 46825., 46250., 46350., 45800., 46800.,\n",
      "       46700., 46800., 47300., 46975., 47000., 45800., 45450., 44625.,\n",
      "       44000., 44175., 44300., 44050., 44550., 44075., 43925., 43975.,\n",
      "       43800., 43725., 43650., 45150., 46625., 45225., 45300., 44925.,\n",
      "       44750., 44550., 45150., 45725., 46275., 46625., 47075., 46700.,\n",
      "       46575., 46375., 46475., 46450., 47250., 47100., 47300., 46375.,\n",
      "       45625.]), array([42325., 42250., 42450., 42800., 42975., 43375., 42875., 42900.,\n",
      "       42400., 41300., 40775., 41125., 40325., 40450., 40425., 40375.,\n",
      "       39450., 39125., 38750., 39100., 38800., 38375., 38675., 38525.,\n",
      "       38450., 38550., 38975., 38000., 37225., 38350., 38575., 38950.,\n",
      "       39875., 40250., 40275., 40475., 41075., 41775., 42175., 42325.,\n",
      "       42350., 41800., 42725., 44250., 45050., 44925., 45600., 46600.,\n",
      "       46600., 46650., 45175., 44625., 45450., 46350., 46825., 46250.,\n",
      "       46350., 45800., 46800., 46700., 46800., 47300., 46975., 47000.,\n",
      "       45800., 45450., 44625., 44000., 44175., 44300., 44050., 44550.,\n",
      "       44075., 43925., 43975., 43800., 43725., 43650., 45150., 46625.,\n",
      "       45225., 45300., 44925., 44750., 44550., 45150., 45725., 46275.,\n",
      "       46625., 47075., 46700., 46575., 46375., 46475., 46450., 47250.,\n",
      "       47100., 47300., 46375., 45625., 45500., 45250., 44900., 44550.,\n",
      "       44400.]), array([43375., 42875., 42900., 42400., 41300., 40775., 41125., 40325.,\n",
      "       40450., 40425., 40375., 39450., 39125., 38750., 39100., 38800.,\n",
      "       38375., 38675., 38525., 38450., 38550., 38975., 38000., 37225.,\n",
      "       38350., 38575., 38950., 39875., 40250., 40275., 40475., 41075.,\n",
      "       41775., 42175., 42325., 42350., 41800., 42725., 44250., 45050.,\n",
      "       44925., 45600., 46600., 46600., 46650., 45175., 44625., 45450.,\n",
      "       46350., 46825., 46250., 46350., 45800., 46800., 46700., 46800.,\n",
      "       47300., 46975., 47000., 45800., 45450., 44625., 44000., 44175.,\n",
      "       44300., 44050., 44550., 44075., 43925., 43975., 43800., 43725.,\n",
      "       43650., 45150., 46625., 45225., 45300., 44925., 44750., 44550.,\n",
      "       45150., 45725., 46275., 46625., 47075., 46700., 46575., 46375.,\n",
      "       46475., 46450., 47250., 47100., 47300., 46375., 45625., 45500.,\n",
      "       45250., 44900., 44550., 44400., 45625., 45825., 45775., 45675.,\n",
      "       44850.]), array([40775., 41125., 40325., 40450., 40425., 40375., 39450., 39125.,\n",
      "       38750., 39100., 38800., 38375., 38675., 38525., 38450., 38550.,\n",
      "       38975., 38000., 37225., 38350., 38575., 38950., 39875., 40250.,\n",
      "       40275., 40475., 41075., 41775., 42175., 42325., 42350., 41800.,\n",
      "       42725., 44250., 45050., 44925., 45600., 46600., 46600., 46650.,\n",
      "       45175., 44625., 45450., 46350., 46825., 46250., 46350., 45800.,\n",
      "       46800., 46700., 46800., 47300., 46975., 47000., 45800., 45450.,\n",
      "       44625., 44000., 44175., 44300., 44050., 44550., 44075., 43925.,\n",
      "       43975., 43800., 43725., 43650., 45150., 46625., 45225., 45300.,\n",
      "       44925., 44750., 44550., 45150., 45725., 46275., 46625., 47075.,\n",
      "       46700., 46575., 46375., 46475., 46450., 47250., 47100., 47300.,\n",
      "       46375., 45625., 45500., 45250., 44900., 44550., 44400., 45625.,\n",
      "       45825., 45775., 45675., 44850., 44525., 43350., 42950., 42775.,\n",
      "       42200.]), array([40375., 39450., 39125., 38750., 39100., 38800., 38375., 38675.,\n",
      "       38525., 38450., 38550., 38975., 38000., 37225., 38350., 38575.,\n",
      "       38950., 39875., 40250., 40275., 40475., 41075., 41775., 42175.,\n",
      "       42325., 42350., 41800., 42725., 44250., 45050., 44925., 45600.,\n",
      "       46600., 46600., 46650., 45175., 44625., 45450., 46350., 46825.,\n",
      "       46250., 46350., 45800., 46800., 46700., 46800., 47300., 46975.,\n",
      "       47000., 45800., 45450., 44625., 44000., 44175., 44300., 44050.,\n",
      "       44550., 44075., 43925., 43975., 43800., 43725., 43650., 45150.,\n",
      "       46625., 45225., 45300., 44925., 44750., 44550., 45150., 45725.,\n",
      "       46275., 46625., 47075., 46700., 46575., 46375., 46475., 46450.,\n",
      "       47250., 47100., 47300., 46375., 45625., 45500., 45250., 44900.,\n",
      "       44550., 44400., 45625., 45825., 45775., 45675., 44850., 44525.,\n",
      "       43350., 42950., 42775., 42200., 42800., 41875., 41450., 41825.,\n",
      "       43150.]), array([38800., 38375., 38675., 38525., 38450., 38550., 38975., 38000.,\n",
      "       37225., 38350., 38575., 38950., 39875., 40250., 40275., 40475.,\n",
      "       41075., 41775., 42175., 42325., 42350., 41800., 42725., 44250.,\n",
      "       45050., 44925., 45600., 46600., 46600., 46650., 45175., 44625.,\n",
      "       45450., 46350., 46825., 46250., 46350., 45800., 46800., 46700.,\n",
      "       46800., 47300., 46975., 47000., 45800., 45450., 44625., 44000.,\n",
      "       44175., 44300., 44050., 44550., 44075., 43925., 43975., 43800.,\n",
      "       43725., 43650., 45150., 46625., 45225., 45300., 44925., 44750.,\n",
      "       44550., 45150., 45725., 46275., 46625., 47075., 46700., 46575.,\n",
      "       46375., 46475., 46450., 47250., 47100., 47300., 46375., 45625.,\n",
      "       45500., 45250., 44900., 44550., 44400., 45625., 45825., 45775.,\n",
      "       45675., 44850., 44525., 43350., 42950., 42775., 42200., 42800.,\n",
      "       41875., 41450., 41825., 43150., 43100., 43625., 43100., 42675.,\n",
      "       42550.]), array([38550., 38975., 38000., 37225., 38350., 38575., 38950., 39875.,\n",
      "       40250., 40275., 40475., 41075., 41775., 42175., 42325., 42350.,\n",
      "       41800., 42725., 44250., 45050., 44925., 45600., 46600., 46600.,\n",
      "       46650., 45175., 44625., 45450., 46350., 46825., 46250., 46350.,\n",
      "       45800., 46800., 46700., 46800., 47300., 46975., 47000., 45800.,\n",
      "       45450., 44625., 44000., 44175., 44300., 44050., 44550., 44075.,\n",
      "       43925., 43975., 43800., 43725., 43650., 45150., 46625., 45225.,\n",
      "       45300., 44925., 44750., 44550., 45150., 45725., 46275., 46625.,\n",
      "       47075., 46700., 46575., 46375., 46475., 46450., 47250., 47100.,\n",
      "       47300., 46375., 45625., 45500., 45250., 44900., 44550., 44400.,\n",
      "       45625., 45825., 45775., 45675., 44850., 44525., 43350., 42950.,\n",
      "       42775., 42200., 42800., 41875., 41450., 41825., 43150., 43100.,\n",
      "       43625., 43100., 42675., 42550., 41700., 42425., 42475., 43200.,\n",
      "       43350.]), array([38575., 38950., 39875., 40250., 40275., 40475., 41075., 41775.,\n",
      "       42175., 42325., 42350., 41800., 42725., 44250., 45050., 44925.,\n",
      "       45600., 46600., 46600., 46650., 45175., 44625., 45450., 46350.,\n",
      "       46825., 46250., 46350., 45800., 46800., 46700., 46800., 47300.,\n",
      "       46975., 47000., 45800., 45450., 44625., 44000., 44175., 44300.,\n",
      "       44050., 44550., 44075., 43925., 43975., 43800., 43725., 43650.,\n",
      "       45150., 46625., 45225., 45300., 44925., 44750., 44550., 45150.,\n",
      "       45725., 46275., 46625., 47075., 46700., 46575., 46375., 46475.,\n",
      "       46450., 47250., 47100., 47300., 46375., 45625., 45500., 45250.,\n",
      "       44900., 44550., 44400., 45625., 45825., 45775., 45675., 44850.,\n",
      "       44525., 43350., 42950., 42775., 42200., 42800., 41875., 41450.,\n",
      "       41825., 43150., 43100., 43625., 43100., 42675., 42550., 41700.,\n",
      "       42425., 42475., 43200., 43350., 43950., 43900., 44450., 44775.,\n",
      "       44675.]), array([40475., 41075., 41775., 42175., 42325., 42350., 41800., 42725.,\n",
      "       44250., 45050., 44925., 45600., 46600., 46600., 46650., 45175.,\n",
      "       44625., 45450., 46350., 46825., 46250., 46350., 45800., 46800.,\n",
      "       46700., 46800., 47300., 46975., 47000., 45800., 45450., 44625.,\n",
      "       44000., 44175., 44300., 44050., 44550., 44075., 43925., 43975.,\n",
      "       43800., 43725., 43650., 45150., 46625., 45225., 45300., 44925.,\n",
      "       44750., 44550., 45150., 45725., 46275., 46625., 47075., 46700.,\n",
      "       46575., 46375., 46475., 46450., 47250., 47100., 47300., 46375.,\n",
      "       45625., 45500., 45250., 44900., 44550., 44400., 45625., 45825.,\n",
      "       45775., 45675., 44850., 44525., 43350., 42950., 42775., 42200.,\n",
      "       42800., 41875., 41450., 41825., 43150., 43100., 43625., 43100.,\n",
      "       42675., 42550., 41700., 42425., 42475., 43200., 43350., 43950.,\n",
      "       43900., 44450., 44775., 44675., 43900., 43725., 43725., 44075.,\n",
      "       45225.]), array([42350., 41800., 42725., 44250., 45050., 44925., 45600., 46600.,\n",
      "       46600., 46650., 45175., 44625., 45450., 46350., 46825., 46250.,\n",
      "       46350., 45800., 46800., 46700., 46800., 47300., 46975., 47000.,\n",
      "       45800., 45450., 44625., 44000., 44175., 44300., 44050., 44550.,\n",
      "       44075., 43925., 43975., 43800., 43725., 43650., 45150., 46625.,\n",
      "       45225., 45300., 44925., 44750., 44550., 45150., 45725., 46275.,\n",
      "       46625., 47075., 46700., 46575., 46375., 46475., 46450., 47250.,\n",
      "       47100., 47300., 46375., 45625., 45500., 45250., 44900., 44550.,\n",
      "       44400., 45625., 45825., 45775., 45675., 44850., 44525., 43350.,\n",
      "       42950., 42775., 42200., 42800., 41875., 41450., 41825., 43150.,\n",
      "       43100., 43625., 43100., 42675., 42550., 41700., 42425., 42475.,\n",
      "       43200., 43350., 43950., 43900., 44450., 44775., 44675., 43900.,\n",
      "       43725., 43725., 44075., 45225., 45175., 45500., 45500., 45500.,\n",
      "       45800.]), array([44925., 45600., 46600., 46600., 46650., 45175., 44625., 45450.,\n",
      "       46350., 46825., 46250., 46350., 45800., 46800., 46700., 46800.,\n",
      "       47300., 46975., 47000., 45800., 45450., 44625., 44000., 44175.,\n",
      "       44300., 44050., 44550., 44075., 43925., 43975., 43800., 43725.,\n",
      "       43650., 45150., 46625., 45225., 45300., 44925., 44750., 44550.,\n",
      "       45150., 45725., 46275., 46625., 47075., 46700., 46575., 46375.,\n",
      "       46475., 46450., 47250., 47100., 47300., 46375., 45625., 45500.,\n",
      "       45250., 44900., 44550., 44400., 45625., 45825., 45775., 45675.,\n",
      "       44850., 44525., 43350., 42950., 42775., 42200., 42800., 41875.,\n",
      "       41450., 41825., 43150., 43100., 43625., 43100., 42675., 42550.,\n",
      "       41700., 42425., 42475., 43200., 43350., 43950., 43900., 44450.,\n",
      "       44775., 44675., 43900., 43725., 43725., 44075., 45225., 45175.,\n",
      "       45500., 45500., 45500., 45800., 46175., 46850., 46825., 46375.,\n",
      "       45775.]), array([45175., 44625., 45450., 46350., 46825., 46250., 46350., 45800.,\n",
      "       46800., 46700., 46800., 47300., 46975., 47000., 45800., 45450.,\n",
      "       44625., 44000., 44175., 44300., 44050., 44550., 44075., 43925.,\n",
      "       43975., 43800., 43725., 43650., 45150., 46625., 45225., 45300.,\n",
      "       44925., 44750., 44550., 45150., 45725., 46275., 46625., 47075.,\n",
      "       46700., 46575., 46375., 46475., 46450., 47250., 47100., 47300.,\n",
      "       46375., 45625., 45500., 45250., 44900., 44550., 44400., 45625.,\n",
      "       45825., 45775., 45675., 44850., 44525., 43350., 42950., 42775.,\n",
      "       42200., 42800., 41875., 41450., 41825., 43150., 43100., 43625.,\n",
      "       43100., 42675., 42550., 41700., 42425., 42475., 43200., 43350.,\n",
      "       43950., 43900., 44450., 44775., 44675., 43900., 43725., 43725.,\n",
      "       44075., 45225., 45175., 45500., 45500., 45500., 45800., 46175.,\n",
      "       46850., 46825., 46375., 45775., 45725., 45600., 44575., 45075.,\n",
      "       45825.]), array([46250., 46350., 45800., 46800., 46700., 46800., 47300., 46975.,\n",
      "       47000., 45800., 45450., 44625., 44000., 44175., 44300., 44050.,\n",
      "       44550., 44075., 43925., 43975., 43800., 43725., 43650., 45150.,\n",
      "       46625., 45225., 45300., 44925., 44750., 44550., 45150., 45725.,\n",
      "       46275., 46625., 47075., 46700., 46575., 46375., 46475., 46450.,\n",
      "       47250., 47100., 47300., 46375., 45625., 45500., 45250., 44900.,\n",
      "       44550., 44400., 45625., 45825., 45775., 45675., 44850., 44525.,\n",
      "       43350., 42950., 42775., 42200., 42800., 41875., 41450., 41825.,\n",
      "       43150., 43100., 43625., 43100., 42675., 42550., 41700., 42425.,\n",
      "       42475., 43200., 43350., 43950., 43900., 44450., 44775., 44675.,\n",
      "       43900., 43725., 43725., 44075., 45225., 45175., 45500., 45500.,\n",
      "       45500., 45800., 46175., 46850., 46825., 46375., 45775., 45725.,\n",
      "       45600., 44575., 45075., 45825., 46350., 46100., 46200., 46575.,\n",
      "       46150.]), array([46800., 47300., 46975., 47000., 45800., 45450., 44625., 44000.,\n",
      "       44175., 44300., 44050., 44550., 44075., 43925., 43975., 43800.,\n",
      "       43725., 43650., 45150., 46625., 45225., 45300., 44925., 44750.,\n",
      "       44550., 45150., 45725., 46275., 46625., 47075., 46700., 46575.,\n",
      "       46375., 46475., 46450., 47250., 47100., 47300., 46375., 45625.,\n",
      "       45500., 45250., 44900., 44550., 44400., 45625., 45825., 45775.,\n",
      "       45675., 44850., 44525., 43350., 42950., 42775., 42200., 42800.,\n",
      "       41875., 41450., 41825., 43150., 43100., 43625., 43100., 42675.,\n",
      "       42550., 41700., 42425., 42475., 43200., 43350., 43950., 43900.,\n",
      "       44450., 44775., 44675., 43900., 43725., 43725., 44075., 45225.,\n",
      "       45175., 45500., 45500., 45500., 45800., 46175., 46850., 46825.,\n",
      "       46375., 45775., 45725., 45600., 44575., 45075., 45825., 46350.,\n",
      "       46100., 46200., 46575., 46150., 46050., 46775., 46950., 47300.,\n",
      "       46700.]), array([45450., 44625., 44000., 44175., 44300., 44050., 44550., 44075.,\n",
      "       43925., 43975., 43800., 43725., 43650., 45150., 46625., 45225.,\n",
      "       45300., 44925., 44750., 44550., 45150., 45725., 46275., 46625.,\n",
      "       47075., 46700., 46575., 46375., 46475., 46450., 47250., 47100.,\n",
      "       47300., 46375., 45625., 45500., 45250., 44900., 44550., 44400.,\n",
      "       45625., 45825., 45775., 45675., 44850., 44525., 43350., 42950.,\n",
      "       42775., 42200., 42800., 41875., 41450., 41825., 43150., 43100.,\n",
      "       43625., 43100., 42675., 42550., 41700., 42425., 42475., 43200.,\n",
      "       43350., 43950., 43900., 44450., 44775., 44675., 43900., 43725.,\n",
      "       43725., 44075., 45225., 45175., 45500., 45500., 45500., 45800.,\n",
      "       46175., 46850., 46825., 46375., 45775., 45725., 45600., 44575.,\n",
      "       45075., 45825., 46350., 46100., 46200., 46575., 46150., 46050.,\n",
      "       46775., 46950., 47300., 46700., 46900., 46850., 46525., 46575.,\n",
      "       45800.]), array([44050., 44550., 44075., 43925., 43975., 43800., 43725., 43650.,\n",
      "       45150., 46625., 45225., 45300., 44925., 44750., 44550., 45150.,\n",
      "       45725., 46275., 46625., 47075., 46700., 46575., 46375., 46475.,\n",
      "       46450., 47250., 47100., 47300., 46375., 45625., 45500., 45250.,\n",
      "       44900., 44550., 44400., 45625., 45825., 45775., 45675., 44850.,\n",
      "       44525., 43350., 42950., 42775., 42200., 42800., 41875., 41450.,\n",
      "       41825., 43150., 43100., 43625., 43100., 42675., 42550., 41700.,\n",
      "       42425., 42475., 43200., 43350., 43950., 43900., 44450., 44775.,\n",
      "       44675., 43900., 43725., 43725., 44075., 45225., 45175., 45500.,\n",
      "       45500., 45500., 45800., 46175., 46850., 46825., 46375., 45775.,\n",
      "       45725., 45600., 44575., 45075., 45825., 46350., 46100., 46200.,\n",
      "       46575., 46150., 46050., 46775., 46950., 47300., 46700., 46900.,\n",
      "       46850., 46525., 46575., 45800., 45175., 44900., 44100., 43150.,\n",
      "       43500.]), array([43800., 43725., 43650., 45150., 46625., 45225., 45300., 44925.,\n",
      "       44750., 44550., 45150., 45725., 46275., 46625., 47075., 46700.,\n",
      "       46575., 46375., 46475., 46450., 47250., 47100., 47300., 46375.,\n",
      "       45625., 45500., 45250., 44900., 44550., 44400., 45625., 45825.,\n",
      "       45775., 45675., 44850., 44525., 43350., 42950., 42775., 42200.,\n",
      "       42800., 41875., 41450., 41825., 43150., 43100., 43625., 43100.,\n",
      "       42675., 42550., 41700., 42425., 42475., 43200., 43350., 43950.,\n",
      "       43900., 44450., 44775., 44675., 43900., 43725., 43725., 44075.,\n",
      "       45225., 45175., 45500., 45500., 45500., 45800., 46175., 46850.,\n",
      "       46825., 46375., 45775., 45725., 45600., 44575., 45075., 45825.,\n",
      "       46350., 46100., 46200., 46575., 46150., 46050., 46775., 46950.,\n",
      "       47300., 46700., 46900., 46850., 46525., 46575., 45800., 45175.,\n",
      "       44900., 44100., 43150., 43500., 43075., 43200., 43775., 43225.,\n",
      "       43875.]), array([45225., 45300., 44925., 44750., 44550., 45150., 45725., 46275.,\n",
      "       46625., 47075., 46700., 46575., 46375., 46475., 46450., 47250.,\n",
      "       47100., 47300., 46375., 45625., 45500., 45250., 44900., 44550.,\n",
      "       44400., 45625., 45825., 45775., 45675., 44850., 44525., 43350.,\n",
      "       42950., 42775., 42200., 42800., 41875., 41450., 41825., 43150.,\n",
      "       43100., 43625., 43100., 42675., 42550., 41700., 42425., 42475.,\n",
      "       43200., 43350., 43950., 43900., 44450., 44775., 44675., 43900.,\n",
      "       43725., 43725., 44075., 45225., 45175., 45500., 45500., 45500.,\n",
      "       45800., 46175., 46850., 46825., 46375., 45775., 45725., 45600.,\n",
      "       44575., 45075., 45825., 46350., 46100., 46200., 46575., 46150.,\n",
      "       46050., 46775., 46950., 47300., 46700., 46900., 46850., 46525.,\n",
      "       46575., 45800., 45175., 44900., 44100., 43150., 43500., 43075.,\n",
      "       43200., 43775., 43225., 43875., 43600., 43925., 44075., 44475.,\n",
      "       44275.]), array([45150., 45725., 46275., 46625., 47075., 46700., 46575., 46375.,\n",
      "       46475., 46450., 47250., 47100., 47300., 46375., 45625., 45500.,\n",
      "       45250., 44900., 44550., 44400., 45625., 45825., 45775., 45675.,\n",
      "       44850., 44525., 43350., 42950., 42775., 42200., 42800., 41875.,\n",
      "       41450., 41825., 43150., 43100., 43625., 43100., 42675., 42550.,\n",
      "       41700., 42425., 42475., 43200., 43350., 43950., 43900., 44450.,\n",
      "       44775., 44675., 43900., 43725., 43725., 44075., 45225., 45175.,\n",
      "       45500., 45500., 45500., 45800., 46175., 46850., 46825., 46375.,\n",
      "       45775., 45725., 45600., 44575., 45075., 45825., 46350., 46100.,\n",
      "       46200., 46575., 46150., 46050., 46775., 46950., 47300., 46700.,\n",
      "       46900., 46850., 46525., 46575., 45800., 45175., 44900., 44100.,\n",
      "       43150., 43500., 43075., 43200., 43775., 43225., 43875., 43600.,\n",
      "       43925., 44075., 44475., 44275., 43925., 43375., 43900., 44075.,\n",
      "       43625.]), array([46700., 46575., 46375., 46475., 46450., 47250., 47100., 47300.,\n",
      "       46375., 45625., 45500., 45250., 44900., 44550., 44400., 45625.,\n",
      "       45825., 45775., 45675., 44850., 44525., 43350., 42950., 42775.,\n",
      "       42200., 42800., 41875., 41450., 41825., 43150., 43100., 43625.,\n",
      "       43100., 42675., 42550., 41700., 42425., 42475., 43200., 43350.,\n",
      "       43950., 43900., 44450., 44775., 44675., 43900., 43725., 43725.,\n",
      "       44075., 45225., 45175., 45500., 45500., 45500., 45800., 46175.,\n",
      "       46850., 46825., 46375., 45775., 45725., 45600., 44575., 45075.,\n",
      "       45825., 46350., 46100., 46200., 46575., 46150., 46050., 46775.,\n",
      "       46950., 47300., 46700., 46900., 46850., 46525., 46575., 45800.,\n",
      "       45175., 44900., 44100., 43150., 43500., 43075., 43200., 43775.,\n",
      "       43225., 43875., 43600., 43925., 44075., 44475., 44275., 43925.,\n",
      "       43375., 43900., 44075., 43625., 44025., 44250., 43375., 43625.,\n",
      "       45275.]), array([47250., 47100., 47300., 46375., 45625., 45500., 45250., 44900.,\n",
      "       44550., 44400., 45625., 45825., 45775., 45675., 44850., 44525.,\n",
      "       43350., 42950., 42775., 42200., 42800., 41875., 41450., 41825.,\n",
      "       43150., 43100., 43625., 43100., 42675., 42550., 41700., 42425.,\n",
      "       42475., 43200., 43350., 43950., 43900., 44450., 44775., 44675.,\n",
      "       43900., 43725., 43725., 44075., 45225., 45175., 45500., 45500.,\n",
      "       45500., 45800., 46175., 46850., 46825., 46375., 45775., 45725.,\n",
      "       45600., 44575., 45075., 45825., 46350., 46100., 46200., 46575.,\n",
      "       46150., 46050., 46775., 46950., 47300., 46700., 46900., 46850.,\n",
      "       46525., 46575., 45800., 45175., 44900., 44100., 43150., 43500.,\n",
      "       43075., 43200., 43775., 43225., 43875., 43600., 43925., 44075.,\n",
      "       44475., 44275., 43925., 43375., 43900., 44075., 43625., 44025.,\n",
      "       44250., 43375., 43625., 45275., 46175., 46650., 46875., 47100.,\n",
      "       46750.]), array([45500., 45250., 44900., 44550., 44400., 45625., 45825., 45775.,\n",
      "       45675., 44850., 44525., 43350., 42950., 42775., 42200., 42800.,\n",
      "       41875., 41450., 41825., 43150., 43100., 43625., 43100., 42675.,\n",
      "       42550., 41700., 42425., 42475., 43200., 43350., 43950., 43900.,\n",
      "       44450., 44775., 44675., 43900., 43725., 43725., 44075., 45225.,\n",
      "       45175., 45500., 45500., 45500., 45800., 46175., 46850., 46825.,\n",
      "       46375., 45775., 45725., 45600., 44575., 45075., 45825., 46350.,\n",
      "       46100., 46200., 46575., 46150., 46050., 46775., 46950., 47300.,\n",
      "       46700., 46900., 46850., 46525., 46575., 45800., 45175., 44900.,\n",
      "       44100., 43150., 43500., 43075., 43200., 43775., 43225., 43875.,\n",
      "       43600., 43925., 44075., 44475., 44275., 43925., 43375., 43900.,\n",
      "       44075., 43625., 44025., 44250., 43375., 43625., 45275., 46175.,\n",
      "       46650., 46875., 47100., 46750., 46950., 47250., 48525., 49350.,\n",
      "       49150.]), array([45625., 45825., 45775., 45675., 44850., 44525., 43350., 42950.,\n",
      "       42775., 42200., 42800., 41875., 41450., 41825., 43150., 43100.,\n",
      "       43625., 43100., 42675., 42550., 41700., 42425., 42475., 43200.,\n",
      "       43350., 43950., 43900., 44450., 44775., 44675., 43900., 43725.,\n",
      "       43725., 44075., 45225., 45175., 45500., 45500., 45500., 45800.,\n",
      "       46175., 46850., 46825., 46375., 45775., 45725., 45600., 44575.,\n",
      "       45075., 45825., 46350., 46100., 46200., 46575., 46150., 46050.,\n",
      "       46775., 46950., 47300., 46700., 46900., 46850., 46525., 46575.,\n",
      "       45800., 45175., 44900., 44100., 43150., 43500., 43075., 43200.,\n",
      "       43775., 43225., 43875., 43600., 43925., 44075., 44475., 44275.,\n",
      "       43925., 43375., 43900., 44075., 43625., 44025., 44250., 43375.,\n",
      "       43625., 45275., 46175., 46650., 46875., 47100., 46750., 46950.,\n",
      "       47250., 48525., 49350., 49150., 49250., 49075., 49075., 48350.,\n",
      "       48575.]), array([44525., 43350., 42950., 42775., 42200., 42800., 41875., 41450.,\n",
      "       41825., 43150., 43100., 43625., 43100., 42675., 42550., 41700.,\n",
      "       42425., 42475., 43200., 43350., 43950., 43900., 44450., 44775.,\n",
      "       44675., 43900., 43725., 43725., 44075., 45225., 45175., 45500.,\n",
      "       45500., 45500., 45800., 46175., 46850., 46825., 46375., 45775.,\n",
      "       45725., 45600., 44575., 45075., 45825., 46350., 46100., 46200.,\n",
      "       46575., 46150., 46050., 46775., 46950., 47300., 46700., 46900.,\n",
      "       46850., 46525., 46575., 45800., 45175., 44900., 44100., 43150.,\n",
      "       43500., 43075., 43200., 43775., 43225., 43875., 43600., 43925.,\n",
      "       44075., 44475., 44275., 43925., 43375., 43900., 44075., 43625.,\n",
      "       44025., 44250., 43375., 43625., 45275., 46175., 46650., 46875.,\n",
      "       47100., 46750., 46950., 47250., 48525., 49350., 49150., 49250.,\n",
      "       49075., 49075., 48350., 48575., 48875., 48000., 48000., 48175.,\n",
      "       48300.]), array([42800., 41875., 41450., 41825., 43150., 43100., 43625., 43100.,\n",
      "       42675., 42550., 41700., 42425., 42475., 43200., 43350., 43950.,\n",
      "       43900., 44450., 44775., 44675., 43900., 43725., 43725., 44075.,\n",
      "       45225., 45175., 45500., 45500., 45500., 45800., 46175., 46850.,\n",
      "       46825., 46375., 45775., 45725., 45600., 44575., 45075., 45825.,\n",
      "       46350., 46100., 46200., 46575., 46150., 46050., 46775., 46950.,\n",
      "       47300., 46700., 46900., 46850., 46525., 46575., 45800., 45175.,\n",
      "       44900., 44100., 43150., 43500., 43075., 43200., 43775., 43225.,\n",
      "       43875., 43600., 43925., 44075., 44475., 44275., 43925., 43375.,\n",
      "       43900., 44075., 43625., 44025., 44250., 43375., 43625., 45275.,\n",
      "       46175., 46650., 46875., 47100., 46750., 46950., 47250., 48525.,\n",
      "       49350., 49150., 49250., 49075., 49075., 48350., 48575., 48875.,\n",
      "       48000., 48000., 48175., 48300., 48600., 49125., 50075., 50050.,\n",
      "       50650.]), array([43100., 43625., 43100., 42675., 42550., 41700., 42425., 42475.,\n",
      "       43200., 43350., 43950., 43900., 44450., 44775., 44675., 43900.,\n",
      "       43725., 43725., 44075., 45225., 45175., 45500., 45500., 45500.,\n",
      "       45800., 46175., 46850., 46825., 46375., 45775., 45725., 45600.,\n",
      "       44575., 45075., 45825., 46350., 46100., 46200., 46575., 46150.,\n",
      "       46050., 46775., 46950., 47300., 46700., 46900., 46850., 46525.,\n",
      "       46575., 45800., 45175., 44900., 44100., 43150., 43500., 43075.,\n",
      "       43200., 43775., 43225., 43875., 43600., 43925., 44075., 44475.,\n",
      "       44275., 43925., 43375., 43900., 44075., 43625., 44025., 44250.,\n",
      "       43375., 43625., 45275., 46175., 46650., 46875., 47100., 46750.,\n",
      "       46950., 47250., 48525., 49350., 49150., 49250., 49075., 49075.,\n",
      "       48350., 48575., 48875., 48000., 48000., 48175., 48300., 48600.,\n",
      "       49125., 50075., 50050., 50650., 50350., 50275., 50100., 51100.,\n",
      "       51150.]), array([41700., 42425., 42475., 43200., 43350., 43950., 43900., 44450.,\n",
      "       44775., 44675., 43900., 43725., 43725., 44075., 45225., 45175.,\n",
      "       45500., 45500., 45500., 45800., 46175., 46850., 46825., 46375.,\n",
      "       45775., 45725., 45600., 44575., 45075., 45825., 46350., 46100.,\n",
      "       46200., 46575., 46150., 46050., 46775., 46950., 47300., 46700.,\n",
      "       46900., 46850., 46525., 46575., 45800., 45175., 44900., 44100.,\n",
      "       43150., 43500., 43075., 43200., 43775., 43225., 43875., 43600.,\n",
      "       43925., 44075., 44475., 44275., 43925., 43375., 43900., 44075.,\n",
      "       43625., 44025., 44250., 43375., 43625., 45275., 46175., 46650.,\n",
      "       46875., 47100., 46750., 46950., 47250., 48525., 49350., 49150.,\n",
      "       49250., 49075., 49075., 48350., 48575., 48875., 48000., 48000.,\n",
      "       48175., 48300., 48600., 49125., 50075., 50050., 50650., 50350.,\n",
      "       50275., 50100., 51100., 51150., 51500., 50850., 51100., 51250.,\n",
      "       50500.]), array([43950., 43900., 44450., 44775., 44675., 43900., 43725., 43725.,\n",
      "       44075., 45225., 45175., 45500., 45500., 45500., 45800., 46175.,\n",
      "       46850., 46825., 46375., 45775., 45725., 45600., 44575., 45075.,\n",
      "       45825., 46350., 46100., 46200., 46575., 46150., 46050., 46775.,\n",
      "       46950., 47300., 46700., 46900., 46850., 46525., 46575., 45800.,\n",
      "       45175., 44900., 44100., 43150., 43500., 43075., 43200., 43775.,\n",
      "       43225., 43875., 43600., 43925., 44075., 44475., 44275., 43925.,\n",
      "       43375., 43900., 44075., 43625., 44025., 44250., 43375., 43625.,\n",
      "       45275., 46175., 46650., 46875., 47100., 46750., 46950., 47250.,\n",
      "       48525., 49350., 49150., 49250., 49075., 49075., 48350., 48575.,\n",
      "       48875., 48000., 48000., 48175., 48300., 48600., 49125., 50075.,\n",
      "       50050., 50650., 50350., 50275., 50100., 51100., 51150., 51500.,\n",
      "       50850., 51100., 51250., 50500., 50850., 50800., 51850., 52400.,\n",
      "       53100.]), array([43900., 43725., 43725., 44075., 45225., 45175., 45500., 45500.,\n",
      "       45500., 45800., 46175., 46850., 46825., 46375., 45775., 45725.,\n",
      "       45600., 44575., 45075., 45825., 46350., 46100., 46200., 46575.,\n",
      "       46150., 46050., 46775., 46950., 47300., 46700., 46900., 46850.,\n",
      "       46525., 46575., 45800., 45175., 44900., 44100., 43150., 43500.,\n",
      "       43075., 43200., 43775., 43225., 43875., 43600., 43925., 44075.,\n",
      "       44475., 44275., 43925., 43375., 43900., 44075., 43625., 44025.,\n",
      "       44250., 43375., 43625., 45275., 46175., 46650., 46875., 47100.,\n",
      "       46750., 46950., 47250., 48525., 49350., 49150., 49250., 49075.,\n",
      "       49075., 48350., 48575., 48875., 48000., 48000., 48175., 48300.,\n",
      "       48600., 49125., 50075., 50050., 50650., 50350., 50275., 50100.,\n",
      "       51100., 51150., 51500., 50850., 51100., 51250., 50500., 50850.,\n",
      "       50800., 51850., 52400., 53100., 52900., 52650., 51800., 52100.,\n",
      "       52250.]), array([45175., 45500., 45500., 45500., 45800., 46175., 46850., 46825.,\n",
      "       46375., 45775., 45725., 45600., 44575., 45075., 45825., 46350.,\n",
      "       46100., 46200., 46575., 46150., 46050., 46775., 46950., 47300.,\n",
      "       46700., 46900., 46850., 46525., 46575., 45800., 45175., 44900.,\n",
      "       44100., 43150., 43500., 43075., 43200., 43775., 43225., 43875.,\n",
      "       43600., 43925., 44075., 44475., 44275., 43925., 43375., 43900.,\n",
      "       44075., 43625., 44025., 44250., 43375., 43625., 45275., 46175.,\n",
      "       46650., 46875., 47100., 46750., 46950., 47250., 48525., 49350.,\n",
      "       49150., 49250., 49075., 49075., 48350., 48575., 48875., 48000.,\n",
      "       48000., 48175., 48300., 48600., 49125., 50075., 50050., 50650.,\n",
      "       50350., 50275., 50100., 51100., 51150., 51500., 50850., 51100.,\n",
      "       51250., 50500., 50850., 50800., 51850., 52400., 53100., 52900.,\n",
      "       52650., 51800., 52100., 52250., 53150., 53500., 53100., 52700.,\n",
      "       51350.]), array([46175., 46850., 46825., 46375., 45775., 45725., 45600., 44575.,\n",
      "       45075., 45825., 46350., 46100., 46200., 46575., 46150., 46050.,\n",
      "       46775., 46950., 47300., 46700., 46900., 46850., 46525., 46575.,\n",
      "       45800., 45175., 44900., 44100., 43150., 43500., 43075., 43200.,\n",
      "       43775., 43225., 43875., 43600., 43925., 44075., 44475., 44275.,\n",
      "       43925., 43375., 43900., 44075., 43625., 44025., 44250., 43375.,\n",
      "       43625., 45275., 46175., 46650., 46875., 47100., 46750., 46950.,\n",
      "       47250., 48525., 49350., 49150., 49250., 49075., 49075., 48350.,\n",
      "       48575., 48875., 48000., 48000., 48175., 48300., 48600., 49125.,\n",
      "       50075., 50050., 50650., 50350., 50275., 50100., 51100., 51150.,\n",
      "       51500., 50850., 51100., 51250., 50500., 50850., 50800., 51850.,\n",
      "       52400., 53100., 52900., 52650., 51800., 52100., 52250., 53150.,\n",
      "       53500., 53100., 52700., 51350., 51250., 52150., 52350., 51950.,\n",
      "       51700.]), array([45725., 45600., 44575., 45075., 45825., 46350., 46100., 46200.,\n",
      "       46575., 46150., 46050., 46775., 46950., 47300., 46700., 46900.,\n",
      "       46850., 46525., 46575., 45800., 45175., 44900., 44100., 43150.,\n",
      "       43500., 43075., 43200., 43775., 43225., 43875., 43600., 43925.,\n",
      "       44075., 44475., 44275., 43925., 43375., 43900., 44075., 43625.,\n",
      "       44025., 44250., 43375., 43625., 45275., 46175., 46650., 46875.,\n",
      "       47100., 46750., 46950., 47250., 48525., 49350., 49150., 49250.,\n",
      "       49075., 49075., 48350., 48575., 48875., 48000., 48000., 48175.,\n",
      "       48300., 48600., 49125., 50075., 50050., 50650., 50350., 50275.,\n",
      "       50100., 51100., 51150., 51500., 50850., 51100., 51250., 50500.,\n",
      "       50850., 50800., 51850., 52400., 53100., 52900., 52650., 51800.,\n",
      "       52100., 52250., 53150., 53500., 53100., 52700., 51350., 51250.,\n",
      "       52150., 52350., 51950., 51700., 50800., 50850., 49900., 49425.,\n",
      "       49950.]), array([46350., 46100., 46200., 46575., 46150., 46050., 46775., 46950.,\n",
      "       47300., 46700., 46900., 46850., 46525., 46575., 45800., 45175.,\n",
      "       44900., 44100., 43150., 43500., 43075., 43200., 43775., 43225.,\n",
      "       43875., 43600., 43925., 44075., 44475., 44275., 43925., 43375.,\n",
      "       43900., 44075., 43625., 44025., 44250., 43375., 43625., 45275.,\n",
      "       46175., 46650., 46875., 47100., 46750., 46950., 47250., 48525.,\n",
      "       49350., 49150., 49250., 49075., 49075., 48350., 48575., 48875.,\n",
      "       48000., 48000., 48175., 48300., 48600., 49125., 50075., 50050.,\n",
      "       50650., 50350., 50275., 50100., 51100., 51150., 51500., 50850.,\n",
      "       51100., 51250., 50500., 50850., 50800., 51850., 52400., 53100.,\n",
      "       52900., 52650., 51800., 52100., 52250., 53150., 53500., 53100.,\n",
      "       52700., 51350., 51250., 52150., 52350., 51950., 51700., 50800.,\n",
      "       50850., 49900., 49425., 49950., 50425., 51050., 51150., 51800.,\n",
      "       53000.]), array([46050., 46775., 46950., 47300., 46700., 46900., 46850., 46525.,\n",
      "       46575., 45800., 45175., 44900., 44100., 43150., 43500., 43075.,\n",
      "       43200., 43775., 43225., 43875., 43600., 43925., 44075., 44475.,\n",
      "       44275., 43925., 43375., 43900., 44075., 43625., 44025., 44250.,\n",
      "       43375., 43625., 45275., 46175., 46650., 46875., 47100., 46750.,\n",
      "       46950., 47250., 48525., 49350., 49150., 49250., 49075., 49075.,\n",
      "       48350., 48575., 48875., 48000., 48000., 48175., 48300., 48600.,\n",
      "       49125., 50075., 50050., 50650., 50350., 50275., 50100., 51100.,\n",
      "       51150., 51500., 50850., 51100., 51250., 50500., 50850., 50800.,\n",
      "       51850., 52400., 53100., 52900., 52650., 51800., 52100., 52250.,\n",
      "       53150., 53500., 53100., 52700., 51350., 51250., 52150., 52350.,\n",
      "       51950., 51700., 50800., 50850., 49900., 49425., 49950., 50425.,\n",
      "       51050., 51150., 51800., 53000., 54350., 54600., 56050., 56600.,\n",
      "       56400.]), array([46900., 46850., 46525., 46575., 45800., 45175., 44900., 44100.,\n",
      "       43150., 43500., 43075., 43200., 43775., 43225., 43875., 43600.,\n",
      "       43925., 44075., 44475., 44275., 43925., 43375., 43900., 44075.,\n",
      "       43625., 44025., 44250., 43375., 43625., 45275., 46175., 46650.,\n",
      "       46875., 47100., 46750., 46950., 47250., 48525., 49350., 49150.,\n",
      "       49250., 49075., 49075., 48350., 48575., 48875., 48000., 48000.,\n",
      "       48175., 48300., 48600., 49125., 50075., 50050., 50650., 50350.,\n",
      "       50275., 50100., 51100., 51150., 51500., 50850., 51100., 51250.,\n",
      "       50500., 50850., 50800., 51850., 52400., 53100., 52900., 52650.,\n",
      "       51800., 52100., 52250., 53150., 53500., 53100., 52700., 51350.,\n",
      "       51250., 52150., 52350., 51950., 51700., 50800., 50850., 49900.,\n",
      "       49425., 49950., 50425., 51050., 51150., 51800., 53000., 54350.,\n",
      "       54600., 56050., 56600., 56400., 56050., 55750., 55250., 54900.,\n",
      "       56200.]), array([45175., 44900., 44100., 43150., 43500., 43075., 43200., 43775.,\n",
      "       43225., 43875., 43600., 43925., 44075., 44475., 44275., 43925.,\n",
      "       43375., 43900., 44075., 43625., 44025., 44250., 43375., 43625.,\n",
      "       45275., 46175., 46650., 46875., 47100., 46750., 46950., 47250.,\n",
      "       48525., 49350., 49150., 49250., 49075., 49075., 48350., 48575.,\n",
      "       48875., 48000., 48000., 48175., 48300., 48600., 49125., 50075.,\n",
      "       50050., 50650., 50350., 50275., 50100., 51100., 51150., 51500.,\n",
      "       50850., 51100., 51250., 50500., 50850., 50800., 51850., 52400.,\n",
      "       53100., 52900., 52650., 51800., 52100., 52250., 53150., 53500.,\n",
      "       53100., 52700., 51350., 51250., 52150., 52350., 51950., 51700.,\n",
      "       50800., 50850., 49900., 49425., 49950., 50425., 51050., 51150.,\n",
      "       51800., 53000., 54350., 54600., 56050., 56600., 56400., 56050.,\n",
      "       55750., 55250., 54900., 56200., 56150., 55500., 55750., 55100.,\n",
      "       56000.]), array([43075., 43200., 43775., 43225., 43875., 43600., 43925., 44075.,\n",
      "       44475., 44275., 43925., 43375., 43900., 44075., 43625., 44025.,\n",
      "       44250., 43375., 43625., 45275., 46175., 46650., 46875., 47100.,\n",
      "       46750., 46950., 47250., 48525., 49350., 49150., 49250., 49075.,\n",
      "       49075., 48350., 48575., 48875., 48000., 48000., 48175., 48300.,\n",
      "       48600., 49125., 50075., 50050., 50650., 50350., 50275., 50100.,\n",
      "       51100., 51150., 51500., 50850., 51100., 51250., 50500., 50850.,\n",
      "       50800., 51850., 52400., 53100., 52900., 52650., 51800., 52100.,\n",
      "       52250., 53150., 53500., 53100., 52700., 51350., 51250., 52150.,\n",
      "       52350., 51950., 51700., 50800., 50850., 49900., 49425., 49950.,\n",
      "       50425., 51050., 51150., 51800., 53000., 54350., 54600., 56050.,\n",
      "       56600., 56400., 56050., 55750., 55250., 54900., 56200., 56150.,\n",
      "       55500., 55750., 55100., 56000., 56650., 58000., 59000., 59550.,\n",
      "       60450.]), array([43600., 43925., 44075., 44475., 44275., 43925., 43375., 43900.,\n",
      "       44075., 43625., 44025., 44250., 43375., 43625., 45275., 46175.,\n",
      "       46650., 46875., 47100., 46750., 46950., 47250., 48525., 49350.,\n",
      "       49150., 49250., 49075., 49075., 48350., 48575., 48875., 48000.,\n",
      "       48000., 48175., 48300., 48600., 49125., 50075., 50050., 50650.,\n",
      "       50350., 50275., 50100., 51100., 51150., 51500., 50850., 51100.,\n",
      "       51250., 50500., 50850., 50800., 51850., 52400., 53100., 52900.,\n",
      "       52650., 51800., 52100., 52250., 53150., 53500., 53100., 52700.,\n",
      "       51350., 51250., 52150., 52350., 51950., 51700., 50800., 50850.,\n",
      "       49900., 49425., 49950., 50425., 51050., 51150., 51800., 53000.,\n",
      "       54350., 54600., 56050., 56600., 56400., 56050., 55750., 55250.,\n",
      "       54900., 56200., 56150., 55500., 55750., 55100., 56000., 56650.,\n",
      "       58000., 59000., 59550., 60450., 59250., 59850., 61500., 62250.,\n",
      "       61800.]), array([43925., 43375., 43900., 44075., 43625., 44025., 44250., 43375.,\n",
      "       43625., 45275., 46175., 46650., 46875., 47100., 46750., 46950.,\n",
      "       47250., 48525., 49350., 49150., 49250., 49075., 49075., 48350.,\n",
      "       48575., 48875., 48000., 48000., 48175., 48300., 48600., 49125.,\n",
      "       50075., 50050., 50650., 50350., 50275., 50100., 51100., 51150.,\n",
      "       51500., 50850., 51100., 51250., 50500., 50850., 50800., 51850.,\n",
      "       52400., 53100., 52900., 52650., 51800., 52100., 52250., 53150.,\n",
      "       53500., 53100., 52700., 51350., 51250., 52150., 52350., 51950.,\n",
      "       51700., 50800., 50850., 49900., 49425., 49950., 50425., 51050.,\n",
      "       51150., 51800., 53000., 54350., 54600., 56050., 56600., 56400.,\n",
      "       56050., 55750., 55250., 54900., 56200., 56150., 55500., 55750.,\n",
      "       55100., 56000., 56650., 58000., 59000., 59550., 60450., 59250.,\n",
      "       59850., 61500., 62250., 61800., 61500., 61250., 58850., 59250.,\n",
      "       57800.]), array([44025., 44250., 43375., 43625., 45275., 46175., 46650., 46875.,\n",
      "       47100., 46750., 46950., 47250., 48525., 49350., 49150., 49250.,\n",
      "       49075., 49075., 48350., 48575., 48875., 48000., 48000., 48175.,\n",
      "       48300., 48600., 49125., 50075., 50050., 50650., 50350., 50275.,\n",
      "       50100., 51100., 51150., 51500., 50850., 51100., 51250., 50500.,\n",
      "       50850., 50800., 51850., 52400., 53100., 52900., 52650., 51800.,\n",
      "       52100., 52250., 53150., 53500., 53100., 52700., 51350., 51250.,\n",
      "       52150., 52350., 51950., 51700., 50800., 50850., 49900., 49425.,\n",
      "       49950., 50425., 51050., 51150., 51800., 53000., 54350., 54600.,\n",
      "       56050., 56600., 56400., 56050., 55750., 55250., 54900., 56200.,\n",
      "       56150., 55500., 55750., 55100., 56000., 56650., 58000., 59000.,\n",
      "       59550., 60450., 59250., 59850., 61500., 62250., 61800., 61500.,\n",
      "       61250., 58850., 59250., 57800., 57400., 56300., 57900., 59550.,\n",
      "       60400.]), array([46175., 46650., 46875., 47100., 46750., 46950., 47250., 48525.,\n",
      "       49350., 49150., 49250., 49075., 49075., 48350., 48575., 48875.,\n",
      "       48000., 48000., 48175., 48300., 48600., 49125., 50075., 50050.,\n",
      "       50650., 50350., 50275., 50100., 51100., 51150., 51500., 50850.,\n",
      "       51100., 51250., 50500., 50850., 50800., 51850., 52400., 53100.,\n",
      "       52900., 52650., 51800., 52100., 52250., 53150., 53500., 53100.,\n",
      "       52700., 51350., 51250., 52150., 52350., 51950., 51700., 50800.,\n",
      "       50850., 49900., 49425., 49950., 50425., 51050., 51150., 51800.,\n",
      "       53000., 54350., 54600., 56050., 56600., 56400., 56050., 55750.,\n",
      "       55250., 54900., 56200., 56150., 55500., 55750., 55100., 56000.,\n",
      "       56650., 58000., 59000., 59550., 60450., 59250., 59850., 61500.,\n",
      "       62250., 61800., 61500., 61250., 58850., 59250., 57800., 57400.,\n",
      "       56300., 57900., 59550., 60400., 60450., 59450., 60200., 60200.,\n",
      "       61050.]), array([46950., 47250., 48525., 49350., 49150., 49250., 49075., 49075.,\n",
      "       48350., 48575., 48875., 48000., 48000., 48175., 48300., 48600.,\n",
      "       49125., 50075., 50050., 50650., 50350., 50275., 50100., 51100.,\n",
      "       51150., 51500., 50850., 51100., 51250., 50500., 50850., 50800.,\n",
      "       51850., 52400., 53100., 52900., 52650., 51800., 52100., 52250.,\n",
      "       53150., 53500., 53100., 52700., 51350., 51250., 52150., 52350.,\n",
      "       51950., 51700., 50800., 50850., 49900., 49425., 49950., 50425.,\n",
      "       51050., 51150., 51800., 53000., 54350., 54600., 56050., 56600.,\n",
      "       56400., 56050., 55750., 55250., 54900., 56200., 56150., 55500.,\n",
      "       55750., 55100., 56000., 56650., 58000., 59000., 59550., 60450.,\n",
      "       59250., 59850., 61500., 62250., 61800., 61500., 61250., 58850.,\n",
      "       59250., 57800., 57400., 56300., 57900., 59550., 60400., 60450.,\n",
      "       59450., 60200., 60200., 61050., 61050., 61600., 60300., 59900.,\n",
      "       60450.]), array([49250., 49075., 49075., 48350., 48575., 48875., 48000., 48000.,\n",
      "       48175., 48300., 48600., 49125., 50075., 50050., 50650., 50350.,\n",
      "       50275., 50100., 51100., 51150., 51500., 50850., 51100., 51250.,\n",
      "       50500., 50850., 50800., 51850., 52400., 53100., 52900., 52650.,\n",
      "       51800., 52100., 52250., 53150., 53500., 53100., 52700., 51350.,\n",
      "       51250., 52150., 52350., 51950., 51700., 50800., 50850., 49900.,\n",
      "       49425., 49950., 50425., 51050., 51150., 51800., 53000., 54350.,\n",
      "       54600., 56050., 56600., 56400., 56050., 55750., 55250., 54900.,\n",
      "       56200., 56150., 55500., 55750., 55100., 56000., 56650., 58000.,\n",
      "       59000., 59550., 60450., 59250., 59850., 61500., 62250., 61800.,\n",
      "       61500., 61250., 58850., 59250., 57800., 57400., 56300., 57900.,\n",
      "       59550., 60400., 60450., 59450., 60200., 60200., 61050., 61050.,\n",
      "       61600., 60300., 59900., 60450., 59150., 57450., 57100., 56500.,\n",
      "       56200.]), array([48875., 48000., 48000., 48175., 48300., 48600., 49125., 50075.,\n",
      "       50050., 50650., 50350., 50275., 50100., 51100., 51150., 51500.,\n",
      "       50850., 51100., 51250., 50500., 50850., 50800., 51850., 52400.,\n",
      "       53100., 52900., 52650., 51800., 52100., 52250., 53150., 53500.,\n",
      "       53100., 52700., 51350., 51250., 52150., 52350., 51950., 51700.,\n",
      "       50800., 50850., 49900., 49425., 49950., 50425., 51050., 51150.,\n",
      "       51800., 53000., 54350., 54600., 56050., 56600., 56400., 56050.,\n",
      "       55750., 55250., 54900., 56200., 56150., 55500., 55750., 55100.,\n",
      "       56000., 56650., 58000., 59000., 59550., 60450., 59250., 59850.,\n",
      "       61500., 62250., 61800., 61500., 61250., 58850., 59250., 57800.,\n",
      "       57400., 56300., 57900., 59550., 60400., 60450., 59450., 60200.,\n",
      "       60200., 61050., 61050., 61600., 60300., 59900., 60450., 59150.,\n",
      "       57450., 57100., 56500., 56200., 54850., 54550., 56000., 56100.,\n",
      "       57350.]), array([48600., 49125., 50075., 50050., 50650., 50350., 50275., 50100.,\n",
      "       51100., 51150., 51500., 50850., 51100., 51250., 50500., 50850.,\n",
      "       50800., 51850., 52400., 53100., 52900., 52650., 51800., 52100.,\n",
      "       52250., 53150., 53500., 53100., 52700., 51350., 51250., 52150.,\n",
      "       52350., 51950., 51700., 50800., 50850., 49900., 49425., 49950.,\n",
      "       50425., 51050., 51150., 51800., 53000., 54350., 54600., 56050.,\n",
      "       56600., 56400., 56050., 55750., 55250., 54900., 56200., 56150.,\n",
      "       55500., 55750., 55100., 56000., 56650., 58000., 59000., 59550.,\n",
      "       60450., 59250., 59850., 61500., 62250., 61800., 61500., 61250.,\n",
      "       58850., 59250., 57800., 57400., 56300., 57900., 59550., 60400.,\n",
      "       60450., 59450., 60200., 60200., 61050., 61050., 61600., 60300.,\n",
      "       59900., 60450., 59150., 57450., 57100., 56500., 56200., 54850.,\n",
      "       54550., 56000., 56100., 57350., 56700., 56500., 54300., 53200.,\n",
      "       52100.]), array([50350., 50275., 50100., 51100., 51150., 51500., 50850., 51100.,\n",
      "       51250., 50500., 50850., 50800., 51850., 52400., 53100., 52900.,\n",
      "       52650., 51800., 52100., 52250., 53150., 53500., 53100., 52700.,\n",
      "       51350., 51250., 52150., 52350., 51950., 51700., 50800., 50850.,\n",
      "       49900., 49425., 49950., 50425., 51050., 51150., 51800., 53000.,\n",
      "       54350., 54600., 56050., 56600., 56400., 56050., 55750., 55250.,\n",
      "       54900., 56200., 56150., 55500., 55750., 55100., 56000., 56650.,\n",
      "       58000., 59000., 59550., 60450., 59250., 59850., 61500., 62250.,\n",
      "       61800., 61500., 61250., 58850., 59250., 57800., 57400., 56300.,\n",
      "       57900., 59550., 60400., 60450., 59450., 60200., 60200., 61050.,\n",
      "       61050., 61600., 60300., 59900., 60450., 59150., 57450., 57100.,\n",
      "       56500., 56200., 54850., 54550., 56000., 56100., 57350., 56700.,\n",
      "       56500., 54300., 53200., 52100., 49225., 49850., 48175., 46975.,\n",
      "       44475.]), array([51500., 50850., 51100., 51250., 50500., 50850., 50800., 51850.,\n",
      "       52400., 53100., 52900., 52650., 51800., 52100., 52250., 53150.,\n",
      "       53500., 53100., 52700., 51350., 51250., 52150., 52350., 51950.,\n",
      "       51700., 50800., 50850., 49900., 49425., 49950., 50425., 51050.,\n",
      "       51150., 51800., 53000., 54350., 54600., 56050., 56600., 56400.,\n",
      "       56050., 55750., 55250., 54900., 56200., 56150., 55500., 55750.,\n",
      "       55100., 56000., 56650., 58000., 59000., 59550., 60450., 59250.,\n",
      "       59850., 61500., 62250., 61800., 61500., 61250., 58850., 59250.,\n",
      "       57800., 57400., 56300., 57900., 59550., 60400., 60450., 59450.,\n",
      "       60200., 60200., 61050., 61050., 61600., 60300., 59900., 60450.,\n",
      "       59150., 57450., 57100., 56500., 56200., 54850., 54550., 56000.,\n",
      "       56100., 57350., 56700., 56500., 54300., 53200., 52100., 49225.,\n",
      "       49850., 48175., 46975., 44475., 44525., 42975., 45000., 48375.,\n",
      "       48500.]), array([50850., 50800., 51850., 52400., 53100., 52900., 52650., 51800.,\n",
      "       52100., 52250., 53150., 53500., 53100., 52700., 51350., 51250.,\n",
      "       52150., 52350., 51950., 51700., 50800., 50850., 49900., 49425.,\n",
      "       49950., 50425., 51050., 51150., 51800., 53000., 54350., 54600.,\n",
      "       56050., 56600., 56400., 56050., 55750., 55250., 54900., 56200.,\n",
      "       56150., 55500., 55750., 55100., 56000., 56650., 58000., 59000.,\n",
      "       59550., 60450., 59250., 59850., 61500., 62250., 61800., 61500.,\n",
      "       61250., 58850., 59250., 57800., 57400., 56300., 57900., 59550.,\n",
      "       60400., 60450., 59450., 60200., 60200., 61050., 61050., 61600.,\n",
      "       60300., 59900., 60450., 59150., 57450., 57100., 56500., 56200.,\n",
      "       54850., 54550., 56000., 56100., 57350., 56700., 56500., 54300.,\n",
      "       53200., 52100., 49225., 49850., 48175., 46975., 44475., 44525.,\n",
      "       42975., 45000., 48375., 48500., 48275., 47450., 47825., 46850.,\n",
      "       46100.]), array([52900., 52650., 51800., 52100., 52250., 53150., 53500., 53100.,\n",
      "       52700., 51350., 51250., 52150., 52350., 51950., 51700., 50800.,\n",
      "       50850., 49900., 49425., 49950., 50425., 51050., 51150., 51800.,\n",
      "       53000., 54350., 54600., 56050., 56600., 56400., 56050., 55750.,\n",
      "       55250., 54900., 56200., 56150., 55500., 55750., 55100., 56000.,\n",
      "       56650., 58000., 59000., 59550., 60450., 59250., 59850., 61500.,\n",
      "       62250., 61800., 61500., 61250., 58850., 59250., 57800., 57400.,\n",
      "       56300., 57900., 59550., 60400., 60450., 59450., 60200., 60200.,\n",
      "       61050., 61050., 61600., 60300., 59900., 60450., 59150., 57450.,\n",
      "       57100., 56500., 56200., 54850., 54550., 56000., 56100., 57350.,\n",
      "       56700., 56500., 54300., 53200., 52100., 49225., 49850., 48175.,\n",
      "       46975., 44475., 44525., 42975., 45000., 48375., 48500., 48275.,\n",
      "       47450., 47825., 46850., 46100., 47075., 48025., 49600., 49175.,\n",
      "       49250.]), array([53150., 53500., 53100., 52700., 51350., 51250., 52150., 52350.,\n",
      "       51950., 51700., 50800., 50850., 49900., 49425., 49950., 50425.,\n",
      "       51050., 51150., 51800., 53000., 54350., 54600., 56050., 56600.,\n",
      "       56400., 56050., 55750., 55250., 54900., 56200., 56150., 55500.,\n",
      "       55750., 55100., 56000., 56650., 58000., 59000., 59550., 60450.,\n",
      "       59250., 59850., 61500., 62250., 61800., 61500., 61250., 58850.,\n",
      "       59250., 57800., 57400., 56300., 57900., 59550., 60400., 60450.,\n",
      "       59450., 60200., 60200., 61050., 61050., 61600., 60300., 59900.,\n",
      "       60450., 59150., 57450., 57100., 56500., 56200., 54850., 54550.,\n",
      "       56000., 56100., 57350., 56700., 56500., 54300., 53200., 52100.,\n",
      "       49225., 49850., 48175., 46975., 44475., 44525., 42975., 45000.,\n",
      "       48375., 48500., 48275., 47450., 47825., 46850., 46100., 47075.,\n",
      "       48025., 49600., 49175., 49250., 48950., 48600., 48750., 48950.,\n",
      "       51150.]), array([51250., 52150., 52350., 51950., 51700., 50800., 50850., 49900.,\n",
      "       49425., 49950., 50425., 51050., 51150., 51800., 53000., 54350.,\n",
      "       54600., 56050., 56600., 56400., 56050., 55750., 55250., 54900.,\n",
      "       56200., 56150., 55500., 55750., 55100., 56000., 56650., 58000.,\n",
      "       59000., 59550., 60450., 59250., 59850., 61500., 62250., 61800.,\n",
      "       61500., 61250., 58850., 59250., 57800., 57400., 56300., 57900.,\n",
      "       59550., 60400., 60450., 59450., 60200., 60200., 61050., 61050.,\n",
      "       61600., 60300., 59900., 60450., 59150., 57450., 57100., 56500.,\n",
      "       56200., 54850., 54550., 56000., 56100., 57350., 56700., 56500.,\n",
      "       54300., 53200., 52100., 49225., 49850., 48175., 46975., 44475.,\n",
      "       44525., 42975., 45000., 48375., 48500., 48275., 47450., 47825.,\n",
      "       46850., 46100., 47075., 48025., 49600., 49175., 49250., 48950.,\n",
      "       48600., 48750., 48950., 51150., 50700., 49200., 49175., 49900.,\n",
      "       49375.]), array([50800., 50850., 49900., 49425., 49950., 50425., 51050., 51150.,\n",
      "       51800., 53000., 54350., 54600., 56050., 56600., 56400., 56050.,\n",
      "       55750., 55250., 54900., 56200., 56150., 55500., 55750., 55100.,\n",
      "       56000., 56650., 58000., 59000., 59550., 60450., 59250., 59850.,\n",
      "       61500., 62250., 61800., 61500., 61250., 58850., 59250., 57800.,\n",
      "       57400., 56300., 57900., 59550., 60400., 60450., 59450., 60200.,\n",
      "       60200., 61050., 61050., 61600., 60300., 59900., 60450., 59150.,\n",
      "       57450., 57100., 56500., 56200., 54850., 54550., 56000., 56100.,\n",
      "       57350., 56700., 56500., 54300., 53200., 52100., 49225., 49850.,\n",
      "       48175., 46975., 44475., 44525., 42975., 45000., 48375., 48500.,\n",
      "       48275., 47450., 47825., 46850., 46100., 47075., 48025., 49600.,\n",
      "       49175., 49250., 48950., 48600., 48750., 48950., 51150., 50700.,\n",
      "       49200., 49175., 49900., 49375., 49550., 49700., 50050., 48800.,\n",
      "       48850.]), array([50425., 51050., 51150., 51800., 53000., 54350., 54600., 56050.,\n",
      "       56600., 56400., 56050., 55750., 55250., 54900., 56200., 56150.,\n",
      "       55500., 55750., 55100., 56000., 56650., 58000., 59000., 59550.,\n",
      "       60450., 59250., 59850., 61500., 62250., 61800., 61500., 61250.,\n",
      "       58850., 59250., 57800., 57400., 56300., 57900., 59550., 60400.,\n",
      "       60450., 59450., 60200., 60200., 61050., 61050., 61600., 60300.,\n",
      "       59900., 60450., 59150., 57450., 57100., 56500., 56200., 54850.,\n",
      "       54550., 56000., 56100., 57350., 56700., 56500., 54300., 53200.,\n",
      "       52100., 49225., 49850., 48175., 46975., 44475., 44525., 42975.,\n",
      "       45000., 48375., 48500., 48275., 47450., 47825., 46850., 46100.,\n",
      "       47075., 48025., 49600., 49175., 49250., 48950., 48600., 48750.,\n",
      "       48950., 51150., 50700., 49200., 49175., 49900., 49375., 49550.,\n",
      "       49700., 50050., 48800., 48850., 49000., 49075., 48775., 48025.,\n",
      "       47875.]), array([54350., 54600., 56050., 56600., 56400., 56050., 55750., 55250.,\n",
      "       54900., 56200., 56150., 55500., 55750., 55100., 56000., 56650.,\n",
      "       58000., 59000., 59550., 60450., 59250., 59850., 61500., 62250.,\n",
      "       61800., 61500., 61250., 58850., 59250., 57800., 57400., 56300.,\n",
      "       57900., 59550., 60400., 60450., 59450., 60200., 60200., 61050.,\n",
      "       61050., 61600., 60300., 59900., 60450., 59150., 57450., 57100.,\n",
      "       56500., 56200., 54850., 54550., 56000., 56100., 57350., 56700.,\n",
      "       56500., 54300., 53200., 52100., 49225., 49850., 48175., 46975.,\n",
      "       44475., 44525., 42975., 45000., 48375., 48500., 48275., 47450.,\n",
      "       47825., 46850., 46100., 47075., 48025., 49600., 49175., 49250.,\n",
      "       48950., 48600., 48750., 48950., 51150., 50700., 49200., 49175.,\n",
      "       49900., 49375., 49550., 49700., 50050., 48800., 48850., 49000.,\n",
      "       49075., 48775., 48025., 47875., 47875., 48075., 48350., 50100.,\n",
      "       50000.]), array([56050., 55750., 55250., 54900., 56200., 56150., 55500., 55750.,\n",
      "       55100., 56000., 56650., 58000., 59000., 59550., 60450., 59250.,\n",
      "       59850., 61500., 62250., 61800., 61500., 61250., 58850., 59250.,\n",
      "       57800., 57400., 56300., 57900., 59550., 60400., 60450., 59450.,\n",
      "       60200., 60200., 61050., 61050., 61600., 60300., 59900., 60450.,\n",
      "       59150., 57450., 57100., 56500., 56200., 54850., 54550., 56000.,\n",
      "       56100., 57350., 56700., 56500., 54300., 53200., 52100., 49225.,\n",
      "       49850., 48175., 46975., 44475., 44525., 42975., 45000., 48375.,\n",
      "       48500., 48275., 47450., 47825., 46850., 46100., 47075., 48025.,\n",
      "       49600., 49175., 49250., 48950., 48600., 48750., 48950., 51150.,\n",
      "       50700., 49200., 49175., 49900., 49375., 49550., 49700., 50050.,\n",
      "       48800., 48850., 49000., 49075., 48775., 48025., 47875., 47875.,\n",
      "       48075., 48350., 50100., 50000., 50125., 49200., 48675., 49025.,\n",
      "       49400.]), array([56150., 55500., 55750., 55100., 56000., 56650., 58000., 59000.,\n",
      "       59550., 60450., 59250., 59850., 61500., 62250., 61800., 61500.,\n",
      "       61250., 58850., 59250., 57800., 57400., 56300., 57900., 59550.,\n",
      "       60400., 60450., 59450., 60200., 60200., 61050., 61050., 61600.,\n",
      "       60300., 59900., 60450., 59150., 57450., 57100., 56500., 56200.,\n",
      "       54850., 54550., 56000., 56100., 57350., 56700., 56500., 54300.,\n",
      "       53200., 52100., 49225., 49850., 48175., 46975., 44475., 44525.,\n",
      "       42975., 45000., 48375., 48500., 48275., 47450., 47825., 46850.,\n",
      "       46100., 47075., 48025., 49600., 49175., 49250., 48950., 48600.,\n",
      "       48750., 48950., 51150., 50700., 49200., 49175., 49900., 49375.,\n",
      "       49550., 49700., 50050., 48800., 48850., 49000., 49075., 48775.,\n",
      "       48025., 47875., 47875., 48075., 48350., 50100., 50000., 50125.,\n",
      "       49200., 48675., 49025., 49400., 50550., 50200., 50900., 51150.,\n",
      "       53350.]), array([56650., 58000., 59000., 59550., 60450., 59250., 59850., 61500.,\n",
      "       62250., 61800., 61500., 61250., 58850., 59250., 57800., 57400.,\n",
      "       56300., 57900., 59550., 60400., 60450., 59450., 60200., 60200.,\n",
      "       61050., 61050., 61600., 60300., 59900., 60450., 59150., 57450.,\n",
      "       57100., 56500., 56200., 54850., 54550., 56000., 56100., 57350.,\n",
      "       56700., 56500., 54300., 53200., 52100., 49225., 49850., 48175.,\n",
      "       46975., 44475., 44525., 42975., 45000., 48375., 48500., 48275.,\n",
      "       47450., 47825., 46850., 46100., 47075., 48025., 49600., 49175.,\n",
      "       49250., 48950., 48600., 48750., 48950., 51150., 50700., 49200.,\n",
      "       49175., 49900., 49375., 49550., 49700., 50050., 48800., 48850.,\n",
      "       49000., 49075., 48775., 48025., 47875., 47875., 48075., 48350.,\n",
      "       50100., 50000., 50125., 49200., 48675., 49025., 49400., 50550.,\n",
      "       50200., 50900., 51150., 53350., 55800., 54950., 55600., 55450.,\n",
      "       55400.]), array([59250., 59850., 61500., 62250., 61800., 61500., 61250., 58850.,\n",
      "       59250., 57800., 57400., 56300., 57900., 59550., 60400., 60450.,\n",
      "       59450., 60200., 60200., 61050., 61050., 61600., 60300., 59900.,\n",
      "       60450., 59150., 57450., 57100., 56500., 56200., 54850., 54550.,\n",
      "       56000., 56100., 57350., 56700., 56500., 54300., 53200., 52100.,\n",
      "       49225., 49850., 48175., 46975., 44475., 44525., 42975., 45000.,\n",
      "       48375., 48500., 48275., 47450., 47825., 46850., 46100., 47075.,\n",
      "       48025., 49600., 49175., 49250., 48950., 48600., 48750., 48950.,\n",
      "       51150., 50700., 49200., 49175., 49900., 49375., 49550., 49700.,\n",
      "       50050., 48800., 48850., 49000., 49075., 48775., 48025., 47875.,\n",
      "       47875., 48075., 48350., 50100., 50000., 50125., 49200., 48675.,\n",
      "       49025., 49400., 50550., 50200., 50900., 51150., 53350., 55800.,\n",
      "       54950., 55600., 55450., 55400., 54150., 52150., 50950., 51350.,\n",
      "       52100.]), array([61500., 61250., 58850., 59250., 57800., 57400., 56300., 57900.,\n",
      "       59550., 60400., 60450., 59450., 60200., 60200., 61050., 61050.,\n",
      "       61600., 60300., 59900., 60450., 59150., 57450., 57100., 56500.,\n",
      "       56200., 54850., 54550., 56000., 56100., 57350., 56700., 56500.,\n",
      "       54300., 53200., 52100., 49225., 49850., 48175., 46975., 44475.,\n",
      "       44525., 42975., 45000., 48375., 48500., 48275., 47450., 47825.,\n",
      "       46850., 46100., 47075., 48025., 49600., 49175., 49250., 48950.,\n",
      "       48600., 48750., 48950., 51150., 50700., 49200., 49175., 49900.,\n",
      "       49375., 49550., 49700., 50050., 48800., 48850., 49000., 49075.,\n",
      "       48775., 48025., 47875., 47875., 48075., 48350., 50100., 50000.,\n",
      "       50125., 49200., 48675., 49025., 49400., 50550., 50200., 50900.,\n",
      "       51150., 53350., 55800., 54950., 55600., 55450., 55400., 54150.,\n",
      "       52150., 50950., 51350., 52100., 51950., 52250., 52200., 51950.,\n",
      "       52750.]), array([57400., 56300., 57900., 59550., 60400., 60450., 59450., 60200.,\n",
      "       60200., 61050., 61050., 61600., 60300., 59900., 60450., 59150.,\n",
      "       57450., 57100., 56500., 56200., 54850., 54550., 56000., 56100.,\n",
      "       57350., 56700., 56500., 54300., 53200., 52100., 49225., 49850.,\n",
      "       48175., 46975., 44475., 44525., 42975., 45000., 48375., 48500.,\n",
      "       48275., 47450., 47825., 46850., 46100., 47075., 48025., 49600.,\n",
      "       49175., 49250., 48950., 48600., 48750., 48950., 51150., 50700.,\n",
      "       49200., 49175., 49900., 49375., 49550., 49700., 50050., 48800.,\n",
      "       48850., 49000., 49075., 48775., 48025., 47875., 47875., 48075.,\n",
      "       48350., 50100., 50000., 50125., 49200., 48675., 49025., 49400.,\n",
      "       50550., 50200., 50900., 51150., 53350., 55800., 54950., 55600.,\n",
      "       55450., 55400., 54150., 52150., 50950., 51350., 52100., 51950.,\n",
      "       52250., 52200., 51950., 52750., 52450., 53050., 52600., 53350.,\n",
      "       53000.]), array([60450., 59450., 60200., 60200., 61050., 61050., 61600., 60300.,\n",
      "       59900., 60450., 59150., 57450., 57100., 56500., 56200., 54850.,\n",
      "       54550., 56000., 56100., 57350., 56700., 56500., 54300., 53200.,\n",
      "       52100., 49225., 49850., 48175., 46975., 44475., 44525., 42975.,\n",
      "       45000., 48375., 48500., 48275., 47450., 47825., 46850., 46100.,\n",
      "       47075., 48025., 49600., 49175., 49250., 48950., 48600., 48750.,\n",
      "       48950., 51150., 50700., 49200., 49175., 49900., 49375., 49550.,\n",
      "       49700., 50050., 48800., 48850., 49000., 49075., 48775., 48025.,\n",
      "       47875., 47875., 48075., 48350., 50100., 50000., 50125., 49200.,\n",
      "       48675., 49025., 49400., 50550., 50200., 50900., 51150., 53350.,\n",
      "       55800., 54950., 55600., 55450., 55400., 54150., 52150., 50950.,\n",
      "       51350., 52100., 51950., 52250., 52200., 51950., 52750., 52450.,\n",
      "       53050., 52600., 53350., 53000., 52500., 53150., 54400., 54650.,\n",
      "       53400.]), array([61050., 61600., 60300., 59900., 60450., 59150., 57450., 57100.,\n",
      "       56500., 56200., 54850., 54550., 56000., 56100., 57350., 56700.,\n",
      "       56500., 54300., 53200., 52100., 49225., 49850., 48175., 46975.,\n",
      "       44475., 44525., 42975., 45000., 48375., 48500., 48275., 47450.,\n",
      "       47825., 46850., 46100., 47075., 48025., 49600., 49175., 49250.,\n",
      "       48950., 48600., 48750., 48950., 51150., 50700., 49200., 49175.,\n",
      "       49900., 49375., 49550., 49700., 50050., 48800., 48850., 49000.,\n",
      "       49075., 48775., 48025., 47875., 47875., 48075., 48350., 50100.,\n",
      "       50000., 50125., 49200., 48675., 49025., 49400., 50550., 50200.,\n",
      "       50900., 51150., 53350., 55800., 54950., 55600., 55450., 55400.,\n",
      "       54150., 52150., 50950., 51350., 52100., 51950., 52250., 52200.,\n",
      "       51950., 52750., 52450., 53050., 52600., 53350., 53000., 52500.,\n",
      "       53150., 54400., 54650., 53400., 53200., 52750., 53450., 53500.,\n",
      "       54650.]), array([59150., 57450., 57100., 56500., 56200., 54850., 54550., 56000.,\n",
      "       56100., 57350., 56700., 56500., 54300., 53200., 52100., 49225.,\n",
      "       49850., 48175., 46975., 44475., 44525., 42975., 45000., 48375.,\n",
      "       48500., 48275., 47450., 47825., 46850., 46100., 47075., 48025.,\n",
      "       49600., 49175., 49250., 48950., 48600., 48750., 48950., 51150.,\n",
      "       50700., 49200., 49175., 49900., 49375., 49550., 49700., 50050.,\n",
      "       48800., 48850., 49000., 49075., 48775., 48025., 47875., 47875.,\n",
      "       48075., 48350., 50100., 50000., 50125., 49200., 48675., 49025.,\n",
      "       49400., 50550., 50200., 50900., 51150., 53350., 55800., 54950.,\n",
      "       55600., 55450., 55400., 54150., 52150., 50950., 51350., 52100.,\n",
      "       51950., 52250., 52200., 51950., 52750., 52450., 53050., 52600.,\n",
      "       53350., 53000., 52500., 53150., 54400., 54650., 53400., 53200.,\n",
      "       52750., 53450., 53500., 54650., 54300., 54400., 54400., 55100.,\n",
      "       55100.]), array([54850., 54550., 56000., 56100., 57350., 56700., 56500., 54300.,\n",
      "       53200., 52100., 49225., 49850., 48175., 46975., 44475., 44525.,\n",
      "       42975., 45000., 48375., 48500., 48275., 47450., 47825., 46850.,\n",
      "       46100., 47075., 48025., 49600., 49175., 49250., 48950., 48600.,\n",
      "       48750., 48950., 51150., 50700., 49200., 49175., 49900., 49375.,\n",
      "       49550., 49700., 50050., 48800., 48850., 49000., 49075., 48775.,\n",
      "       48025., 47875., 47875., 48075., 48350., 50100., 50000., 50125.,\n",
      "       49200., 48675., 49025., 49400., 50550., 50200., 50900., 51150.,\n",
      "       53350., 55800., 54950., 55600., 55450., 55400., 54150., 52150.,\n",
      "       50950., 51350., 52100., 51950., 52250., 52200., 51950., 52750.,\n",
      "       52450., 53050., 52600., 53350., 53000., 52500., 53150., 54400.,\n",
      "       54650., 53400., 53200., 52750., 53450., 53500., 54650., 54300.,\n",
      "       54400., 54400., 55100., 55100., 54250., 54050., 55000., 57600.,\n",
      "       59500.]), array([56700., 56500., 54300., 53200., 52100., 49225., 49850., 48175.,\n",
      "       46975., 44475., 44525., 42975., 45000., 48375., 48500., 48275.,\n",
      "       47450., 47825., 46850., 46100., 47075., 48025., 49600., 49175.,\n",
      "       49250., 48950., 48600., 48750., 48950., 51150., 50700., 49200.,\n",
      "       49175., 49900., 49375., 49550., 49700., 50050., 48800., 48850.,\n",
      "       49000., 49075., 48775., 48025., 47875., 47875., 48075., 48350.,\n",
      "       50100., 50000., 50125., 49200., 48675., 49025., 49400., 50550.,\n",
      "       50200., 50900., 51150., 53350., 55800., 54950., 55600., 55450.,\n",
      "       55400., 54150., 52150., 50950., 51350., 52100., 51950., 52250.,\n",
      "       52200., 51950., 52750., 52450., 53050., 52600., 53350., 53000.,\n",
      "       52500., 53150., 54400., 54650., 53400., 53200., 52750., 53450.,\n",
      "       53500., 54650., 54300., 54400., 54400., 55100., 55100., 54250.,\n",
      "       54050., 55000., 57600., 59500., 59550., 58650., 57300., 57550.,\n",
      "       56900.]), array([49225., 49850., 48175., 46975., 44475., 44525., 42975., 45000.,\n",
      "       48375., 48500., 48275., 47450., 47825., 46850., 46100., 47075.,\n",
      "       48025., 49600., 49175., 49250., 48950., 48600., 48750., 48950.,\n",
      "       51150., 50700., 49200., 49175., 49900., 49375., 49550., 49700.,\n",
      "       50050., 48800., 48850., 49000., 49075., 48775., 48025., 47875.,\n",
      "       47875., 48075., 48350., 50100., 50000., 50125., 49200., 48675.,\n",
      "       49025., 49400., 50550., 50200., 50900., 51150., 53350., 55800.,\n",
      "       54950., 55600., 55450., 55400., 54150., 52150., 50950., 51350.,\n",
      "       52100., 51950., 52250., 52200., 51950., 52750., 52450., 53050.,\n",
      "       52600., 53350., 53000., 52500., 53150., 54400., 54650., 53400.,\n",
      "       53200., 52750., 53450., 53500., 54650., 54300., 54400., 54400.,\n",
      "       55100., 55100., 54250., 54050., 55000., 57600., 59500., 59550.,\n",
      "       58650., 57300., 57550., 56900., 57750., 57750., 57900., 58650.,\n",
      "       58350.]), array([44525., 42975., 45000., 48375., 48500., 48275., 47450., 47825.,\n",
      "       46850., 46100., 47075., 48025., 49600., 49175., 49250., 48950.,\n",
      "       48600., 48750., 48950., 51150., 50700., 49200., 49175., 49900.,\n",
      "       49375., 49550., 49700., 50050., 48800., 48850., 49000., 49075.,\n",
      "       48775., 48025., 47875., 47875., 48075., 48350., 50100., 50000.,\n",
      "       50125., 49200., 48675., 49025., 49400., 50550., 50200., 50900.,\n",
      "       51150., 53350., 55800., 54950., 55600., 55450., 55400., 54150.,\n",
      "       52150., 50950., 51350., 52100., 51950., 52250., 52200., 51950.,\n",
      "       52750., 52450., 53050., 52600., 53350., 53000., 52500., 53150.,\n",
      "       54400., 54650., 53400., 53200., 52750., 53450., 53500., 54650.,\n",
      "       54300., 54400., 54400., 55100., 55100., 54250., 54050., 55000.,\n",
      "       57600., 59500., 59550., 58650., 57300., 57550., 56900., 57750.,\n",
      "       57750., 57900., 58650., 58350., 58800., 58050., 58950., 58500.,\n",
      "       56450.]), array([48275., 47450., 47825., 46850., 46100., 47075., 48025., 49600.,\n",
      "       49175., 49250., 48950., 48600., 48750., 48950., 51150., 50700.,\n",
      "       49200., 49175., 49900., 49375., 49550., 49700., 50050., 48800.,\n",
      "       48850., 49000., 49075., 48775., 48025., 47875., 47875., 48075.,\n",
      "       48350., 50100., 50000., 50125., 49200., 48675., 49025., 49400.,\n",
      "       50550., 50200., 50900., 51150., 53350., 55800., 54950., 55600.,\n",
      "       55450., 55400., 54150., 52150., 50950., 51350., 52100., 51950.,\n",
      "       52250., 52200., 51950., 52750., 52450., 53050., 52600., 53350.,\n",
      "       53000., 52500., 53150., 54400., 54650., 53400., 53200., 52750.,\n",
      "       53450., 53500., 54650., 54300., 54400., 54400., 55100., 55100.,\n",
      "       54250., 54050., 55000., 57600., 59500., 59550., 58650., 57300.,\n",
      "       57550., 56900., 57750., 57750., 57900., 58650., 58350., 58800.,\n",
      "       58050., 58950., 58500., 56450., 56350., 56000., 56450., 56100.,\n",
      "       55950.]), array([47075., 48025., 49600., 49175., 49250., 48950., 48600., 48750.,\n",
      "       48950., 51150., 50700., 49200., 49175., 49900., 49375., 49550.,\n",
      "       49700., 50050., 48800., 48850., 49000., 49075., 48775., 48025.,\n",
      "       47875., 47875., 48075., 48350., 50100., 50000., 50125., 49200.,\n",
      "       48675., 49025., 49400., 50550., 50200., 50900., 51150., 53350.,\n",
      "       55800., 54950., 55600., 55450., 55400., 54150., 52150., 50950.,\n",
      "       51350., 52100., 51950., 52250., 52200., 51950., 52750., 52450.,\n",
      "       53050., 52600., 53350., 53000., 52500., 53150., 54400., 54650.,\n",
      "       53400., 53200., 52750., 53450., 53500., 54650., 54300., 54400.,\n",
      "       54400., 55100., 55100., 54250., 54050., 55000., 57600., 59500.,\n",
      "       59550., 58650., 57300., 57550., 56900., 57750., 57750., 57900.,\n",
      "       58650., 58350., 58800., 58050., 58950., 58500., 56450., 56350.,\n",
      "       56000., 56450., 56100., 55950., 55850., 55050., 54450., 54600.,\n",
      "       56100.]), array([48950., 48600., 48750., 48950., 51150., 50700., 49200., 49175.,\n",
      "       49900., 49375., 49550., 49700., 50050., 48800., 48850., 49000.,\n",
      "       49075., 48775., 48025., 47875., 47875., 48075., 48350., 50100.,\n",
      "       50000., 50125., 49200., 48675., 49025., 49400., 50550., 50200.,\n",
      "       50900., 51150., 53350., 55800., 54950., 55600., 55450., 55400.,\n",
      "       54150., 52150., 50950., 51350., 52100., 51950., 52250., 52200.,\n",
      "       51950., 52750., 52450., 53050., 52600., 53350., 53000., 52500.,\n",
      "       53150., 54400., 54650., 53400., 53200., 52750., 53450., 53500.,\n",
      "       54650., 54300., 54400., 54400., 55100., 55100., 54250., 54050.,\n",
      "       55000., 57600., 59500., 59550., 58650., 57300., 57550., 56900.,\n",
      "       57750., 57750., 57900., 58650., 58350., 58800., 58050., 58950.,\n",
      "       58500., 56450., 56350., 56000., 56450., 56100., 55950., 55850.,\n",
      "       55050., 54450., 54600., 56100., 55450., 56550., 57950., 58550.,\n",
      "       59550.])]\n",
      "125\n"
     ]
    }
   ],
   "source": [
    "print(result)\n",
    "print(len(result))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalize Data\n",
    "\n",
    "모델이 잘 예측하게 함. \n",
    "\n",
    "### How?\n",
    "\n",
    "(맨 처음 값 - 해당 값) - 1 -> -1 해주는 이유는 처음 값을 0 으로 만들기 위함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(125, 105)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalized_data = []\n",
    "\n",
    "for window in result:\n",
    "    normalized_window = [(float(p) - min_price) / (max_price + min_price) for p in window]\n",
    "    normalized_data.append(normalized_window)\n",
    "result = np.array(normalized_data)\n",
    "result = np.array(result)\n",
    "result.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(111, 100, 1) (111, 5)\n",
      "(12, 100, 1) (12, 5)\n",
      "(2, 100, 1) (2, 5)\n"
     ]
    }
   ],
   "source": [
    "# split train and test data\n",
    "\n",
    "train = result[ :-2, : ]\n",
    "\n",
    "np.random.shuffle(train)\n",
    "\n",
    "row = int(round(train.shape[0] * 0.9))\n",
    "x_train = train[:row, :100]\n",
    "x_train = np.reshape(x_train, (x_train.shape[0], x_train.shape[1], 1))\n",
    "y_train = train[:row, 100:]\n",
    "\n",
    "x_valid = train[row:, :100]\n",
    "x_valid = np.reshape(x_valid, (x_valid.shape[0], x_valid.shape[1], 1))\n",
    "y_valid = train[row:, 100:]\n",
    "\n",
    "x_test = result[-2:, :100]\n",
    "x_test = np.reshape(x_test, (x_test.shape[0], x_test.shape[1], 1))\n",
    "y_test = result[-2:, 100:]\n",
    "\n",
    "print(x_train.shape, y_train.shape)\n",
    "print(x_valid.shape, y_valid.shape)\n",
    "print(x_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Build a Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_2 (LSTM)                (None, 100, 150)          91200     \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (None, 250)               401000    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 5)                 1255      \n",
      "=================================================================\n",
      "Total params: 493,455\n",
      "Trainable params: 493,455\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(LSTM(150, return_sequences=True, input_shape=(100, 1)))\n",
    "\n",
    "model.add(LSTM(250, return_sequences=False))\n",
    "\n",
    "model.add(Dense(5, activation='linear'))\n",
    "\n",
    "model.compile(loss='mse', optimizer='rmsprop', metrics='accuracy')\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "filename = 'tmp_checkpoint.h5'\n",
    "checkpoint = ModelCheckpoint(filename, monitor='val_loss', verbose=1, save_best_only=True, mode='auto')\n",
    "\n",
    "earlystopping = EarlyStopping(monitor='val_loss', patience=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/400\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 0.0534 - accuracy: 0.1800\n",
      "Epoch 00001: val_loss improved from inf to 0.00849, saving model to tmp_checkpoint.h5\n",
      "6/6 [==============================] - 1s 129ms/step - loss: 0.0488 - accuracy: 0.1712 - val_loss: 0.0085 - val_accuracy: 0.2500\n",
      "Epoch 2/400\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 0.0037 - accuracy: 0.2500\n",
      "Epoch 00002: val_loss improved from 0.00849 to 0.00219, saving model to tmp_checkpoint.h5\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 0.0034 - accuracy: 0.2703 - val_loss: 0.0022 - val_accuracy: 0.1667\n",
      "Epoch 3/400\n",
      "4/6 [===================>..........] - ETA: 0s - loss: 0.0011 - accuracy: 0.1625    \n",
      "Epoch 00003: val_loss improved from 0.00219 to 0.00175, saving model to tmp_checkpoint.h5\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 0.0011 - accuracy: 0.1441 - val_loss: 0.0017 - val_accuracy: 0.0833\n",
      "Epoch 4/400\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 9.5501e-04 - accuracy: 0.2300\n",
      "Epoch 00004: val_loss did not improve from 0.00175\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 9.4144e-04 - accuracy: 0.2342 - val_loss: 0.0020 - val_accuracy: 0.2500\n",
      "Epoch 5/400\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 9.9521e-04 - accuracy: 0.1900\n",
      "Epoch 00005: val_loss improved from 0.00175 to 0.00137, saving model to tmp_checkpoint.h5\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 9.5391e-04 - accuracy: 0.1982 - val_loss: 0.0014 - val_accuracy: 0.2500\n",
      "Epoch 6/400\n",
      "4/6 [===================>..........] - ETA: 0s - loss: 8.9909e-04 - accuracy: 0.1875\n",
      "Epoch 00006: val_loss improved from 0.00137 to 0.00103, saving model to tmp_checkpoint.h5\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 0.0011 - accuracy: 0.2162 - val_loss: 0.0010 - val_accuracy: 0.2500\n",
      "Epoch 7/400\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 6.4728e-04 - accuracy: 0.1900\n",
      "Epoch 00007: val_loss did not improve from 0.00103\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 6.7668e-04 - accuracy: 0.1982 - val_loss: 0.0023 - val_accuracy: 0.5000\n",
      "Epoch 8/400\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 0.0012 - accuracy: 0.1700\n",
      "Epoch 00008: val_loss did not improve from 0.00103\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.0012 - accuracy: 0.2162 - val_loss: 0.0013 - val_accuracy: 0.1667\n",
      "Epoch 9/400\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 0.0011 - accuracy: 0.2100\n",
      "Epoch 00009: val_loss improved from 0.00103 to 0.00099, saving model to tmp_checkpoint.h5\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 0.0012 - accuracy: 0.1982 - val_loss: 9.8648e-04 - val_accuracy: 0.1667\n",
      "Epoch 10/400\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 7.1692e-04 - accuracy: 0.1600\n",
      "Epoch 00010: val_loss did not improve from 0.00099\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 6.8980e-04 - accuracy: 0.1892 - val_loss: 0.0012 - val_accuracy: 0.2500\n",
      "Epoch 11/400\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 0.0012 - accuracy: 0.2900    \n",
      "Epoch 00011: val_loss improved from 0.00099 to 0.00085, saving model to tmp_checkpoint.h5\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 0.0012 - accuracy: 0.2703 - val_loss: 8.4655e-04 - val_accuracy: 0.2500\n",
      "Epoch 12/400\n",
      "4/6 [===================>..........] - ETA: 0s - loss: 6.7919e-04 - accuracy: 0.2625    \n",
      "Epoch 00012: val_loss did not improve from 0.00085\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 8.5509e-04 - accuracy: 0.2793 - val_loss: 0.0026 - val_accuracy: 0.0833\n",
      "Epoch 13/400\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 0.0012 - accuracy: 0.1500    \n",
      "Epoch 00013: val_loss did not improve from 0.00085\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.0012 - accuracy: 0.1441 - val_loss: 0.0040 - val_accuracy: 0.1667\n",
      "Epoch 14/400\n",
      "4/6 [===================>..........] - ETA: 0s - loss: 0.0012 - accuracy: 0.2625\n",
      "Epoch 00014: val_loss did not improve from 0.00085\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.0011 - accuracy: 0.2523 - val_loss: 0.0019 - val_accuracy: 0.0833\n",
      "Epoch 15/400\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 0.0014 - accuracy: 0.1800\n",
      "Epoch 00015: val_loss did not improve from 0.00085\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.0014 - accuracy: 0.1712 - val_loss: 0.0011 - val_accuracy: 0.2500\n",
      "Epoch 16/400\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 0.0010 - accuracy: 0.2400\n",
      "Epoch 00016: val_loss improved from 0.00085 to 0.00064, saving model to tmp_checkpoint.h5\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 9.3753e-04 - accuracy: 0.2432 - val_loss: 6.3612e-04 - val_accuracy: 0.1667\n",
      "Epoch 17/400\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 9.7412e-04 - accuracy: 0.3100\n",
      "Epoch 00017: val_loss did not improve from 0.00064\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.0010 - accuracy: 0.2883 - val_loss: 0.0023 - val_accuracy: 0.1667\n",
      "Epoch 18/400\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 8.9372e-04 - accuracy: 0.2400\n",
      "Epoch 00018: val_loss did not improve from 0.00064\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 8.5494e-04 - accuracy: 0.2432 - val_loss: 0.0021 - val_accuracy: 0.2500\n",
      "Epoch 19/400\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 0.0013 - accuracy: 0.1500\n",
      "Epoch 00019: val_loss did not improve from 0.00064\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.0014 - accuracy: 0.1622 - val_loss: 0.0045 - val_accuracy: 0.0833\n",
      "Epoch 20/400\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 0.0011 - accuracy: 0.1100\n",
      "Epoch 00020: val_loss did not improve from 0.00064\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.0010 - accuracy: 0.1261 - val_loss: 6.8110e-04 - val_accuracy: 0.1667\n",
      "Epoch 21/400\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 6.0111e-04 - accuracy: 0.2400\n",
      "Epoch 00021: val_loss improved from 0.00064 to 0.00059, saving model to tmp_checkpoint.h5\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 5.7679e-04 - accuracy: 0.2162 - val_loss: 5.9359e-04 - val_accuracy: 0.1667\n",
      "Epoch 22/400\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 4.7315e-04 - accuracy: 0.2400\n",
      "Epoch 00022: val_loss improved from 0.00059 to 0.00058, saving model to tmp_checkpoint.h5\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 4.5302e-04 - accuracy: 0.2342 - val_loss: 5.7720e-04 - val_accuracy: 0.2500\n",
      "Epoch 23/400\n",
      "4/6 [===================>..........] - ETA: 0s - loss: 5.2674e-04 - accuracy: 0.2125\n",
      "Epoch 00023: val_loss did not improve from 0.00058\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 5.9024e-04 - accuracy: 0.2523 - val_loss: 0.0035 - val_accuracy: 0.1667\n",
      "Epoch 24/400\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 0.0019 - accuracy: 0.2600\n",
      "Epoch 00024: val_loss did not improve from 0.00058\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.0017 - accuracy: 0.2523 - val_loss: 7.2672e-04 - val_accuracy: 0.0833\n",
      "Epoch 25/400\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 0.0011 - accuracy: 0.2400    \n",
      "Epoch 00025: val_loss did not improve from 0.00058\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.0010 - accuracy: 0.2523 - val_loss: 5.9321e-04 - val_accuracy: 0.0833\n",
      "Epoch 26/400\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 6.6627e-04 - accuracy: 0.2300\n",
      "Epoch 00026: val_loss improved from 0.00058 to 0.00054, saving model to tmp_checkpoint.h5\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 6.5032e-04 - accuracy: 0.2252 - val_loss: 5.3508e-04 - val_accuracy: 0.2500\n",
      "Epoch 27/400\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 4.7468e-04 - accuracy: 0.1400\n",
      "Epoch 00027: val_loss did not improve from 0.00054\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 4.7423e-04 - accuracy: 0.1802 - val_loss: 9.0053e-04 - val_accuracy: 0.1667\n",
      "Epoch 28/400\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 8.7694e-04 - accuracy: 0.2500\n",
      "Epoch 00028: val_loss did not improve from 0.00054\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 8.2817e-04 - accuracy: 0.2342 - val_loss: 0.0014 - val_accuracy: 0.1667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/400\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 7.6759e-04 - accuracy: 0.3000\n",
      "Epoch 00029: val_loss did not improve from 0.00054\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 7.5296e-04 - accuracy: 0.2793 - val_loss: 8.3197e-04 - val_accuracy: 0.2500\n",
      "Epoch 30/400\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 4.2127e-04 - accuracy: 0.1900\n",
      "Epoch 00030: val_loss did not improve from 0.00054\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 4.4226e-04 - accuracy: 0.1892 - val_loss: 7.2884e-04 - val_accuracy: 0.2500\n",
      "Epoch 31/400\n",
      "4/6 [===================>..........] - ETA: 0s - loss: 6.2894e-04 - accuracy: 0.2625\n",
      "Epoch 00031: val_loss did not improve from 0.00054\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 7.1887e-04 - accuracy: 0.2252 - val_loss: 0.0015 - val_accuracy: 0.1667\n",
      "Epoch 32/400\n",
      "4/6 [===================>..........] - ETA: 0s - loss: 6.5436e-04 - accuracy: 0.1875\n",
      "Epoch 00032: val_loss did not improve from 0.00054\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 7.5852e-04 - accuracy: 0.1802 - val_loss: 9.3022e-04 - val_accuracy: 0.2500\n",
      "Epoch 33/400\n",
      "4/6 [===================>..........] - ETA: 0s - loss: 4.2341e-04 - accuracy: 0.1625\n",
      "Epoch 00033: val_loss did not improve from 0.00054\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 4.7983e-04 - accuracy: 0.1802 - val_loss: 0.0012 - val_accuracy: 0.1667\n",
      "Epoch 34/400\n",
      "4/6 [===================>..........] - ETA: 0s - loss: 0.0011 - accuracy: 0.1875\n",
      "Epoch 00034: val_loss did not improve from 0.00054\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.0011 - accuracy: 0.1802 - val_loss: 0.0029 - val_accuracy: 0.0833\n",
      "Epoch 35/400\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 6.4420e-04 - accuracy: 0.2800\n",
      "Epoch 00035: val_loss improved from 0.00054 to 0.00052, saving model to tmp_checkpoint.h5\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 6.4328e-04 - accuracy: 0.2613 - val_loss: 5.1816e-04 - val_accuracy: 0.1667\n",
      "Epoch 36/400\n",
      "4/6 [===================>..........] - ETA: 0s - loss: 6.8404e-04 - accuracy: 0.2625\n",
      "Epoch 00036: val_loss improved from 0.00052 to 0.00050, saving model to tmp_checkpoint.h5\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 5.6356e-04 - accuracy: 0.2252 - val_loss: 5.0382e-04 - val_accuracy: 0.2500\n",
      "Epoch 37/400\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 3.6918e-04 - accuracy: 0.3000\n",
      "Epoch 00037: val_loss improved from 0.00050 to 0.00045, saving model to tmp_checkpoint.h5\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 3.4329e-04 - accuracy: 0.2703 - val_loss: 4.4726e-04 - val_accuracy: 0.1667\n",
      "Epoch 38/400\n",
      "4/6 [===================>..........] - ETA: 0s - loss: 3.6600e-04 - accuracy: 0.2500\n",
      "Epoch 00038: val_loss did not improve from 0.00045\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 5.9353e-04 - accuracy: 0.2252 - val_loss: 0.0015 - val_accuracy: 0.1667\n",
      "Epoch 39/400\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 7.7209e-04 - accuracy: 0.1900\n",
      "Epoch 00039: val_loss did not improve from 0.00045\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 7.1958e-04 - accuracy: 0.2072 - val_loss: 4.6214e-04 - val_accuracy: 0.0833\n",
      "Epoch 40/400\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 4.4927e-04 - accuracy: 0.2900\n",
      "Epoch 00040: val_loss did not improve from 0.00045\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 4.3689e-04 - accuracy: 0.2973 - val_loss: 5.6836e-04 - val_accuracy: 0.1667\n",
      "Epoch 41/400\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 4.6350e-04 - accuracy: 0.3000\n",
      "Epoch 00041: val_loss did not improve from 0.00045\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 4.9052e-04 - accuracy: 0.2883 - val_loss: 8.0767e-04 - val_accuracy: 0.0833\n",
      "Epoch 42/400\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 8.3692e-04 - accuracy: 0.2400\n",
      "Epoch 00042: val_loss did not improve from 0.00045\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 7.7651e-04 - accuracy: 0.2252 - val_loss: 5.3023e-04 - val_accuracy: 0.2500\n",
      "Epoch 43/400\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 4.7282e-04 - accuracy: 0.2400\n",
      "Epoch 00043: val_loss did not improve from 0.00045\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 5.1495e-04 - accuracy: 0.2342 - val_loss: 0.0013 - val_accuracy: 0.0833\n",
      "Epoch 44/400\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 4.4473e-04 - accuracy: 0.2000\n",
      "Epoch 00044: val_loss did not improve from 0.00045\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 4.2340e-04 - accuracy: 0.1982 - val_loss: 5.2901e-04 - val_accuracy: 0.3333\n",
      "Epoch 45/400\n",
      "4/6 [===================>..........] - ETA: 0s - loss: 4.0076e-04 - accuracy: 0.2125\n",
      "Epoch 00045: val_loss did not improve from 0.00045\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 4.8063e-04 - accuracy: 0.2162 - val_loss: 0.0014 - val_accuracy: 0.1667\n",
      "Epoch 46/400\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 8.7922e-04 - accuracy: 0.1800\n",
      "Epoch 00046: val_loss did not improve from 0.00045\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 8.4496e-04 - accuracy: 0.1982 - val_loss: 5.4439e-04 - val_accuracy: 0.3333\n",
      "Epoch 47/400\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 3.5042e-04 - accuracy: 0.2900\n",
      "Epoch 00047: val_loss did not improve from 0.00045\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 3.4493e-04 - accuracy: 0.2793 - val_loss: 4.5563e-04 - val_accuracy: 0.3333\n",
      "Epoch 48/400\n",
      "4/6 [===================>..........] - ETA: 0s - loss: 2.7573e-04 - accuracy: 0.2250\n",
      "Epoch 00048: val_loss improved from 0.00045 to 0.00044, saving model to tmp_checkpoint.h5\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 3.1275e-04 - accuracy: 0.2072 - val_loss: 4.4232e-04 - val_accuracy: 0.0833\n",
      "Epoch 49/400\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 4.5636e-04 - accuracy: 0.2100\n",
      "Epoch 00049: val_loss did not improve from 0.00044\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 4.6735e-04 - accuracy: 0.1892 - val_loss: 0.0010 - val_accuracy: 0.0000e+00\n",
      "Epoch 50/400\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 6.4139e-04 - accuracy: 0.2600\n",
      "Epoch 00050: val_loss did not improve from 0.00044\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 5.9068e-04 - accuracy: 0.2523 - val_loss: 4.9019e-04 - val_accuracy: 0.2500\n",
      "Epoch 51/400\n",
      "4/6 [===================>..........] - ETA: 0s - loss: 4.1663e-04 - accuracy: 0.2875\n",
      "Epoch 00051: val_loss did not improve from 0.00044\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 4.5646e-04 - accuracy: 0.2793 - val_loss: 9.6400e-04 - val_accuracy: 0.2500\n",
      "Epoch 52/400\n",
      "4/6 [===================>..........] - ETA: 0s - loss: 3.5847e-04 - accuracy: 0.2250\n",
      "Epoch 00052: val_loss did not improve from 0.00044\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 3.2687e-04 - accuracy: 0.2703 - val_loss: 5.2056e-04 - val_accuracy: 0.1667\n",
      "Epoch 53/400\n",
      "4/6 [===================>..........] - ETA: 0s - loss: 6.7855e-04 - accuracy: 0.2000\n",
      "Epoch 00053: val_loss did not improve from 0.00044\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 6.4145e-04 - accuracy: 0.2162 - val_loss: 4.5817e-04 - val_accuracy: 0.1667\n",
      "Epoch 54/400\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 5.5378e-04 - accuracy: 0.2500\n",
      "Epoch 00054: val_loss did not improve from 0.00044\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 5.5319e-04 - accuracy: 0.2432 - val_loss: 8.8591e-04 - val_accuracy: 0.2500\n",
      "Epoch 55/400\n",
      "4/6 [===================>..........] - ETA: 0s - loss: 5.2576e-04 - accuracy: 0.2875\n",
      "Epoch 00055: val_loss did not improve from 0.00044\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 4.4725e-04 - accuracy: 0.2342 - val_loss: 5.9106e-04 - val_accuracy: 0.0833\n",
      "Epoch 56/400\n",
      "4/6 [===================>..........] - ETA: 0s - loss: 3.5259e-04 - accuracy: 0.2625\n",
      "Epoch 00056: val_loss did not improve from 0.00044\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 3.4312e-04 - accuracy: 0.2432 - val_loss: 7.7515e-04 - val_accuracy: 0.0833\n",
      "Epoch 57/400\n",
      "4/6 [===================>..........] - ETA: 0s - loss: 6.7316e-04 - accuracy: 0.1875\n",
      "Epoch 00057: val_loss did not improve from 0.00044\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 6.8225e-04 - accuracy: 0.1802 - val_loss: 5.1322e-04 - val_accuracy: 0.2500\n",
      "Epoch 58/400\n",
      "4/6 [===================>..........] - ETA: 0s - loss: 2.6119e-04 - accuracy: 0.2375\n",
      "Epoch 00058: val_loss did not improve from 0.00044\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 2.8611e-04 - accuracy: 0.2342 - val_loss: 0.0010 - val_accuracy: 0.1667\n",
      "Epoch 59/400\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 4.1770e-04 - accuracy: 0.2400\n",
      "Epoch 00059: val_loss did not improve from 0.00044\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 4.0631e-04 - accuracy: 0.2432 - val_loss: 6.9098e-04 - val_accuracy: 0.1667\n",
      "Epoch 60/400\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 4.6001e-04 - accuracy: 0.3000\n",
      "Epoch 00060: val_loss did not improve from 0.00044\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 4.6038e-04 - accuracy: 0.2703 - val_loss: 9.7095e-04 - val_accuracy: 0.2500\n",
      "Epoch 61/400\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 3.0753e-04 - accuracy: 0.3100\n",
      "Epoch 00061: val_loss did not improve from 0.00044\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 3.5659e-04 - accuracy: 0.2973 - val_loss: 0.0011 - val_accuracy: 0.0833\n",
      "Epoch 62/400\n",
      "4/6 [===================>..........] - ETA: 0s - loss: 4.1741e-04 - accuracy: 0.3000\n",
      "Epoch 00062: val_loss did not improve from 0.00044\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 3.8251e-04 - accuracy: 0.2883 - val_loss: 8.0738e-04 - val_accuracy: 0.1667\n",
      "Epoch 63/400\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 5.3498e-04 - accuracy: 0.2100\n",
      "Epoch 00063: val_loss did not improve from 0.00044\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 5.4103e-04 - accuracy: 0.2162 - val_loss: 0.0012 - val_accuracy: 0.1667\n",
      "Epoch 64/400\n",
      "4/6 [===================>..........] - ETA: 0s - loss: 3.3441e-04 - accuracy: 0.3375\n",
      "Epoch 00064: val_loss improved from 0.00044 to 0.00031, saving model to tmp_checkpoint.h5\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 3.4025e-04 - accuracy: 0.3333 - val_loss: 3.1266e-04 - val_accuracy: 0.0833\n",
      "Epoch 65/400\n",
      "4/6 [===================>..........] - ETA: 0s - loss: 4.3698e-04 - accuracy: 0.2125\n",
      "Epoch 00065: val_loss did not improve from 0.00031\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 4.0611e-04 - accuracy: 0.2432 - val_loss: 3.1543e-04 - val_accuracy: 0.0833\n",
      "Epoch 66/400\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 2.8048e-04 - accuracy: 0.2500\n",
      "Epoch 00066: val_loss improved from 0.00031 to 0.00028, saving model to tmp_checkpoint.h5\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 2.7098e-04 - accuracy: 0.2432 - val_loss: 2.8251e-04 - val_accuracy: 0.1667\n",
      "Epoch 67/400\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 2.8429e-04 - accuracy: 0.2000\n",
      "Epoch 00067: val_loss did not improve from 0.00028\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 3.0281e-04 - accuracy: 0.1982 - val_loss: 6.3790e-04 - val_accuracy: 0.0833\n",
      "Epoch 68/400\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 5.7732e-04 - accuracy: 0.3100\n",
      "Epoch 00068: val_loss did not improve from 0.00028\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 5.7368e-04 - accuracy: 0.2973 - val_loss: 3.8502e-04 - val_accuracy: 0.0833\n",
      "Epoch 69/400\n",
      "4/6 [===================>..........] - ETA: 0s - loss: 3.6303e-04 - accuracy: 0.3250\n",
      "Epoch 00069: val_loss did not improve from 0.00028\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 3.4887e-04 - accuracy: 0.2973 - val_loss: 3.8916e-04 - val_accuracy: 0.1667\n",
      "Epoch 70/400\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 4.0577e-04 - accuracy: 0.2500\n",
      "Epoch 00070: val_loss did not improve from 0.00028\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 3.8535e-04 - accuracy: 0.2523 - val_loss: 3.3910e-04 - val_accuracy: 0.1667\n",
      "Epoch 71/400\n",
      "4/6 [===================>..........] - ETA: 0s - loss: 3.1135e-04 - accuracy: 0.2250\n",
      "Epoch 00071: val_loss did not improve from 0.00028\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 3.3755e-04 - accuracy: 0.2072 - val_loss: 3.8834e-04 - val_accuracy: 0.1667\n",
      "Epoch 72/400\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 3.7346e-04 - accuracy: 0.3400\n",
      "Epoch 00072: val_loss did not improve from 0.00028\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 3.8411e-04 - accuracy: 0.3423 - val_loss: 4.7795e-04 - val_accuracy: 0.2500\n",
      "Epoch 73/400\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 3.8586e-04 - accuracy: 0.2300\n",
      "Epoch 00073: val_loss did not improve from 0.00028\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 3.7634e-04 - accuracy: 0.2432 - val_loss: 3.1294e-04 - val_accuracy: 0.1667\n",
      "Epoch 74/400\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 2.6376e-04 - accuracy: 0.3000\n",
      "Epoch 00074: val_loss did not improve from 0.00028\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 2.6117e-04 - accuracy: 0.2883 - val_loss: 2.9391e-04 - val_accuracy: 0.1667\n",
      "Epoch 75/400\n",
      "4/6 [===================>..........] - ETA: 0s - loss: 2.3202e-04 - accuracy: 0.2125\n",
      "Epoch 00075: val_loss did not improve from 0.00028\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 2.8022e-04 - accuracy: 0.1802 - val_loss: 4.2023e-04 - val_accuracy: 0.3333\n",
      "Epoch 76/400\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 5.0031e-04 - accuracy: 0.2300\n",
      "Epoch 00076: val_loss did not improve from 0.00028\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 5.1161e-04 - accuracy: 0.2252 - val_loss: 3.7700e-04 - val_accuracy: 0.0833\n",
      "Epoch 77/400\n",
      "4/6 [===================>..........] - ETA: 0s - loss: 3.0010e-04 - accuracy: 0.3250\n",
      "Epoch 00077: val_loss did not improve from 0.00028\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 2.6287e-04 - accuracy: 0.3423 - val_loss: 3.2860e-04 - val_accuracy: 0.1667\n",
      "Epoch 78/400\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 3.1588e-04 - accuracy: 0.2700\n",
      "Epoch 00078: val_loss did not improve from 0.00028\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 3.1036e-04 - accuracy: 0.2703 - val_loss: 2.9932e-04 - val_accuracy: 0.1667\n",
      "Epoch 79/400\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 3.4709e-04 - accuracy: 0.2100\n",
      "Epoch 00079: val_loss did not improve from 0.00028\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 3.6609e-04 - accuracy: 0.2252 - val_loss: 3.4403e-04 - val_accuracy: 0.0833\n",
      "Epoch 80/400\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 4.2106e-04 - accuracy: 0.2300\n",
      "Epoch 00080: val_loss did not improve from 0.00028\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 4.4068e-04 - accuracy: 0.2523 - val_loss: 3.7526e-04 - val_accuracy: 0.1667\n",
      "Epoch 81/400\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 2.5634e-04 - accuracy: 0.2600\n",
      "Epoch 00081: val_loss did not improve from 0.00028\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 2.7461e-04 - accuracy: 0.2613 - val_loss: 3.9684e-04 - val_accuracy: 0.0833\n",
      "Epoch 82/400\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 2.3222e-04 - accuracy: 0.2300\n",
      "Epoch 00082: val_loss did not improve from 0.00028\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 2.3524e-04 - accuracy: 0.2252 - val_loss: 3.0568e-04 - val_accuracy: 0.0833\n",
      "Epoch 83/400\n",
      "4/6 [===================>..........] - ETA: 0s - loss: 3.6868e-04 - accuracy: 0.1875\n",
      "Epoch 00083: val_loss did not improve from 0.00028\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 3.5004e-04 - accuracy: 0.2252 - val_loss: 4.9920e-04 - val_accuracy: 0.2500\n",
      "Epoch 84/400\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 5.0082e-04 - accuracy: 0.3000\n",
      "Epoch 00084: val_loss did not improve from 0.00028\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 4.8955e-04 - accuracy: 0.3243 - val_loss: 4.5946e-04 - val_accuracy: 0.1667\n",
      "Epoch 85/400\n",
      "4/6 [===================>..........] - ETA: 0s - loss: 3.8030e-04 - accuracy: 0.2875\n",
      "Epoch 00085: val_loss did not improve from 0.00028\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 3.3103e-04 - accuracy: 0.2883 - val_loss: 3.2939e-04 - val_accuracy: 0.1667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 86/400\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 2.4245e-04 - accuracy: 0.2600\n",
      "Epoch 00086: val_loss did not improve from 0.00028\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 2.4166e-04 - accuracy: 0.2523 - val_loss: 5.3416e-04 - val_accuracy: 0.2500\n",
      "Epoch 87/400\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 2.5282e-04 - accuracy: 0.1700\n",
      "Epoch 00087: val_loss did not improve from 0.00028\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 2.8166e-04 - accuracy: 0.1712 - val_loss: 3.8298e-04 - val_accuracy: 0.1667\n",
      "Epoch 88/400\n",
      "4/6 [===================>..........] - ETA: 0s - loss: 3.8563e-04 - accuracy: 0.1875\n",
      "Epoch 00088: val_loss did not improve from 0.00028\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 3.7781e-04 - accuracy: 0.1982 - val_loss: 2.9567e-04 - val_accuracy: 0.0833\n",
      "Epoch 89/400\n",
      "4/6 [===================>..........] - ETA: 0s - loss: 2.9888e-04 - accuracy: 0.2875\n",
      "Epoch 00089: val_loss did not improve from 0.00028\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 3.2011e-04 - accuracy: 0.3063 - val_loss: 3.6749e-04 - val_accuracy: 0.2500\n",
      "Epoch 90/400\n",
      "4/6 [===================>..........] - ETA: 0s - loss: 1.8660e-04 - accuracy: 0.2500\n",
      "Epoch 00090: val_loss did not improve from 0.00028\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 2.2561e-04 - accuracy: 0.2432 - val_loss: 4.3200e-04 - val_accuracy: 0.1667\n",
      "Epoch 91/400\n",
      "4/6 [===================>..........] - ETA: 0s - loss: 4.1274e-04 - accuracy: 0.1625\n",
      "Epoch 00091: val_loss did not improve from 0.00028\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 3.8923e-04 - accuracy: 0.2432 - val_loss: 6.0079e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 92/400\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 4.1990e-04 - accuracy: 0.2700\n",
      "Epoch 00092: val_loss did not improve from 0.00028\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 3.9316e-04 - accuracy: 0.2883 - val_loss: 2.8465e-04 - val_accuracy: 0.1667\n",
      "Epoch 93/400\n",
      "4/6 [===================>..........] - ETA: 0s - loss: 2.7125e-04 - accuracy: 0.2125\n",
      "Epoch 00093: val_loss did not improve from 0.00028\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 2.9723e-04 - accuracy: 0.2613 - val_loss: 3.2993e-04 - val_accuracy: 0.1667\n",
      "Epoch 94/400\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 2.9680e-04 - accuracy: 0.2800\n",
      "Epoch 00094: val_loss did not improve from 0.00028\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 2.8349e-04 - accuracy: 0.2703 - val_loss: 3.5036e-04 - val_accuracy: 0.2500\n",
      "Epoch 95/400\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 2.5884e-04 - accuracy: 0.2000\n",
      "Epoch 00095: val_loss did not improve from 0.00028\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 2.4717e-04 - accuracy: 0.1802 - val_loss: 3.5904e-04 - val_accuracy: 0.1667\n",
      "Epoch 96/400\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 3.5313e-04 - accuracy: 0.2200\n",
      "Epoch 00096: val_loss did not improve from 0.00028\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 3.4463e-04 - accuracy: 0.2342 - val_loss: 2.9471e-04 - val_accuracy: 0.2500\n",
      "Epoch 97/400\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 3.0327e-04 - accuracy: 0.2700\n",
      "Epoch 00097: val_loss did not improve from 0.00028\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 2.9704e-04 - accuracy: 0.2432 - val_loss: 3.5756e-04 - val_accuracy: 0.2500\n",
      "Epoch 98/400\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 4.3929e-04 - accuracy: 0.2600\n",
      "Epoch 00098: val_loss did not improve from 0.00028\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 4.1596e-04 - accuracy: 0.2703 - val_loss: 3.5219e-04 - val_accuracy: 0.0833\n",
      "Epoch 99/400\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 2.8963e-04 - accuracy: 0.3300\n",
      "Epoch 00099: val_loss did not improve from 0.00028\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 2.8523e-04 - accuracy: 0.3243 - val_loss: 5.0519e-04 - val_accuracy: 0.1667\n",
      "Epoch 100/400\n",
      "4/6 [===================>..........] - ETA: 0s - loss: 2.8112e-04 - accuracy: 0.2500\n",
      "Epoch 00100: val_loss did not improve from 0.00028\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 3.3696e-04 - accuracy: 0.2523 - val_loss: 0.0014 - val_accuracy: 0.1667\n",
      "Epoch 101/400\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 3.8743e-04 - accuracy: 0.2200\n",
      "Epoch 00101: val_loss did not improve from 0.00028\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 3.7889e-04 - accuracy: 0.2432 - val_loss: 4.2000e-04 - val_accuracy: 0.0833\n",
      "Epoch 102/400\n",
      "4/6 [===================>..........] - ETA: 0s - loss: 2.5128e-04 - accuracy: 0.2375\n",
      "Epoch 00102: val_loss did not improve from 0.00028\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 2.2984e-04 - accuracy: 0.2252 - val_loss: 3.3392e-04 - val_accuracy: 0.1667\n",
      "Epoch 103/400\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 1.8953e-04 - accuracy: 0.2200\n",
      "Epoch 00103: val_loss did not improve from 0.00028\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 2.2232e-04 - accuracy: 0.2072 - val_loss: 8.8918e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 104/400\n",
      "4/6 [===================>..........] - ETA: 0s - loss: 3.0535e-04 - accuracy: 0.1875\n",
      "Epoch 00104: val_loss did not improve from 0.00028\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 2.7999e-04 - accuracy: 0.2523 - val_loss: 3.3724e-04 - val_accuracy: 0.0833\n",
      "Epoch 105/400\n",
      "4/6 [===================>..........] - ETA: 0s - loss: 4.2774e-04 - accuracy: 0.2125\n",
      "Epoch 00105: val_loss did not improve from 0.00028\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 3.9156e-04 - accuracy: 0.1802 - val_loss: 3.3701e-04 - val_accuracy: 0.3333\n",
      "Epoch 106/400\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 2.4219e-04 - accuracy: 0.2800\n",
      "Epoch 00106: val_loss did not improve from 0.00028\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 2.4208e-04 - accuracy: 0.2703 - val_loss: 2.8740e-04 - val_accuracy: 0.0833\n",
      "Epoch 107/400\n",
      "4/6 [===================>..........] - ETA: 0s - loss: 2.5145e-04 - accuracy: 0.3375\n",
      "Epoch 00107: val_loss did not improve from 0.00028\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 2.4469e-04 - accuracy: 0.3063 - val_loss: 4.4309e-04 - val_accuracy: 0.0833\n",
      "Epoch 108/400\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 3.6929e-04 - accuracy: 0.2800\n",
      "Epoch 00108: val_loss did not improve from 0.00028\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 3.6486e-04 - accuracy: 0.2883 - val_loss: 3.7703e-04 - val_accuracy: 0.2500\n",
      "Epoch 109/400\n",
      "4/6 [===================>..........] - ETA: 0s - loss: 2.3184e-04 - accuracy: 0.2625\n",
      "Epoch 00109: val_loss did not improve from 0.00028\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 2.2425e-04 - accuracy: 0.2432 - val_loss: 4.9868e-04 - val_accuracy: 0.2500\n",
      "Epoch 110/400\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 3.9973e-04 - accuracy: 0.3000\n",
      "Epoch 00110: val_loss did not improve from 0.00028\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 3.7936e-04 - accuracy: 0.2973 - val_loss: 4.4052e-04 - val_accuracy: 0.3333\n",
      "Epoch 111/400\n",
      "4/6 [===================>..........] - ETA: 0s - loss: 3.3204e-04 - accuracy: 0.2000\n",
      "Epoch 00111: val_loss did not improve from 0.00028\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 2.7907e-04 - accuracy: 0.2613 - val_loss: 2.8525e-04 - val_accuracy: 0.2500\n",
      "Epoch 112/400\n",
      "4/6 [===================>..........] - ETA: 0s - loss: 2.0524e-04 - accuracy: 0.2750\n",
      "Epoch 00112: val_loss did not improve from 0.00028\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 2.6040e-04 - accuracy: 0.3423 - val_loss: 5.5271e-04 - val_accuracy: 0.4167\n",
      "Epoch 113/400\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 2.6257e-04 - accuracy: 0.3100\n",
      "Epoch 00113: val_loss did not improve from 0.00028\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 2.7436e-04 - accuracy: 0.3333 - val_loss: 3.7196e-04 - val_accuracy: 0.2500\n",
      "Epoch 114/400\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 2.9737e-04 - accuracy: 0.3200\n",
      "Epoch 00114: val_loss did not improve from 0.00028\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 2.8560e-04 - accuracy: 0.3243 - val_loss: 3.0933e-04 - val_accuracy: 0.0833\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 115/400\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 3.3369e-04 - accuracy: 0.2500\n",
      "Epoch 00115: val_loss did not improve from 0.00028\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 3.4011e-04 - accuracy: 0.2703 - val_loss: 3.5727e-04 - val_accuracy: 0.2500\n",
      "Epoch 116/400\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 2.1805e-04 - accuracy: 0.3300\n",
      "Epoch 00116: val_loss did not improve from 0.00028\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 2.4788e-04 - accuracy: 0.3063 - val_loss: 8.5522e-04 - val_accuracy: 0.0833\n",
      "Epoch 117/400\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 2.7249e-04 - accuracy: 0.2700\n",
      "Epoch 00117: val_loss did not improve from 0.00028\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 2.6219e-04 - accuracy: 0.2883 - val_loss: 2.8979e-04 - val_accuracy: 0.2500\n",
      "Epoch 118/400\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 3.5649e-04 - accuracy: 0.2500\n",
      "Epoch 00118: val_loss did not improve from 0.00028\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 3.4386e-04 - accuracy: 0.2523 - val_loss: 2.9893e-04 - val_accuracy: 0.2500\n",
      "Epoch 119/400\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 2.3687e-04 - accuracy: 0.3200\n",
      "Epoch 00119: val_loss did not improve from 0.00028\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 2.2611e-04 - accuracy: 0.2883 - val_loss: 3.1344e-04 - val_accuracy: 0.3333\n",
      "Epoch 120/400\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 2.0599e-04 - accuracy: 0.2100\n",
      "Epoch 00120: val_loss did not improve from 0.00028\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 2.0490e-04 - accuracy: 0.2072 - val_loss: 4.6161e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 121/400\n",
      "4/6 [===================>..........] - ETA: 0s - loss: 4.0594e-04 - accuracy: 0.3500\n",
      "Epoch 00121: val_loss did not improve from 0.00028\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 3.7250e-04 - accuracy: 0.2793 - val_loss: 2.9333e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 122/400\n",
      "4/6 [===================>..........] - ETA: 0s - loss: 2.3880e-04 - accuracy: 0.2375\n",
      "Epoch 00122: val_loss improved from 0.00028 to 0.00027, saving model to tmp_checkpoint.h5\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 2.2320e-04 - accuracy: 0.2342 - val_loss: 2.7272e-04 - val_accuracy: 0.2500\n",
      "Epoch 123/400\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 2.3881e-04 - accuracy: 0.2400\n",
      "Epoch 00123: val_loss did not improve from 0.00027\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 2.3558e-04 - accuracy: 0.2523 - val_loss: 3.4384e-04 - val_accuracy: 0.0833\n",
      "Epoch 124/400\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 2.8367e-04 - accuracy: 0.2500\n",
      "Epoch 00124: val_loss did not improve from 0.00027\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 2.7142e-04 - accuracy: 0.2703 - val_loss: 4.3581e-04 - val_accuracy: 0.1667\n",
      "Epoch 125/400\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 3.1232e-04 - accuracy: 0.2600\n",
      "Epoch 00125: val_loss did not improve from 0.00027\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 3.1126e-04 - accuracy: 0.2613 - val_loss: 5.3200e-04 - val_accuracy: 0.0833\n",
      "Epoch 126/400\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 1.9978e-04 - accuracy: 0.3100\n",
      "Epoch 00126: val_loss did not improve from 0.00027\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 2.0475e-04 - accuracy: 0.3063 - val_loss: 5.0551e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 127/400\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 3.0241e-04 - accuracy: 0.2600\n",
      "Epoch 00127: val_loss did not improve from 0.00027\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 2.9325e-04 - accuracy: 0.2613 - val_loss: 3.5798e-04 - val_accuracy: 0.0833\n",
      "Epoch 128/400\n",
      "4/6 [===================>..........] - ETA: 0s - loss: 1.9613e-04 - accuracy: 0.2625\n",
      "Epoch 00128: val_loss did not improve from 0.00027\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 2.7059e-04 - accuracy: 0.2793 - val_loss: 7.2967e-04 - val_accuracy: 0.0833\n",
      "Epoch 129/400\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 2.7225e-04 - accuracy: 0.3300\n",
      "Epoch 00129: val_loss did not improve from 0.00027\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 2.6147e-04 - accuracy: 0.3063 - val_loss: 3.5511e-04 - val_accuracy: 0.0833\n",
      "Epoch 130/400\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 3.4766e-04 - accuracy: 0.3400\n",
      "Epoch 00130: val_loss did not improve from 0.00027\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 3.3869e-04 - accuracy: 0.3333 - val_loss: 4.3313e-04 - val_accuracy: 0.0833\n",
      "Epoch 131/400\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 2.6093e-04 - accuracy: 0.2700\n",
      "Epoch 00131: val_loss did not improve from 0.00027\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 2.5316e-04 - accuracy: 0.2613 - val_loss: 3.6168e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 132/400\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 2.1805e-04 - accuracy: 0.3400\n",
      "Epoch 00132: val_loss did not improve from 0.00027\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 2.0687e-04 - accuracy: 0.3423 - val_loss: 3.5025e-04 - val_accuracy: 0.2500\n",
      "Epoch 133/400\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 1.8812e-04 - accuracy: 0.3000\n",
      "Epoch 00133: val_loss did not improve from 0.00027\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 1.9392e-04 - accuracy: 0.2883 - val_loss: 5.2185e-04 - val_accuracy: 0.0833\n",
      "Epoch 134/400\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 3.6438e-04 - accuracy: 0.2900\n",
      "Epoch 00134: val_loss did not improve from 0.00027\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 3.4183e-04 - accuracy: 0.2703 - val_loss: 4.5917e-04 - val_accuracy: 0.0833\n",
      "Epoch 135/400\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 2.0132e-04 - accuracy: 0.3600\n",
      "Epoch 00135: val_loss did not improve from 0.00027\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 2.1673e-04 - accuracy: 0.3784 - val_loss: 5.0153e-04 - val_accuracy: 0.0833\n",
      "Epoch 136/400\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 3.1250e-04 - accuracy: 0.3200\n",
      "Epoch 00136: val_loss did not improve from 0.00027\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 2.8936e-04 - accuracy: 0.3153 - val_loss: 3.2743e-04 - val_accuracy: 0.2500\n",
      "Epoch 137/400\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 2.6804e-04 - accuracy: 0.3500\n",
      "Epoch 00137: val_loss did not improve from 0.00027\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 3.1617e-04 - accuracy: 0.3423 - val_loss: 4.8323e-04 - val_accuracy: 0.2500\n",
      "Epoch 138/400\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 2.3600e-04 - accuracy: 0.2200\n",
      "Epoch 00138: val_loss did not improve from 0.00027\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 2.4186e-04 - accuracy: 0.2252 - val_loss: 3.3780e-04 - val_accuracy: 0.0833\n",
      "Epoch 139/400\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 2.3321e-04 - accuracy: 0.2900\n",
      "Epoch 00139: val_loss did not improve from 0.00027\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 2.2706e-04 - accuracy: 0.3063 - val_loss: 2.7776e-04 - val_accuracy: 0.1667\n",
      "Epoch 140/400\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 2.0276e-04 - accuracy: 0.3800\n",
      "Epoch 00140: val_loss did not improve from 0.00027\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 1.9822e-04 - accuracy: 0.3604 - val_loss: 3.3924e-04 - val_accuracy: 0.0833\n",
      "Epoch 141/400\n",
      "4/6 [===================>..........] - ETA: 0s - loss: 2.6020e-04 - accuracy: 0.2500\n",
      "Epoch 00141: val_loss did not improve from 0.00027\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 2.8081e-04 - accuracy: 0.2703 - val_loss: 5.6785e-04 - val_accuracy: 0.0833\n",
      "Epoch 142/400\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 2.7866e-04 - accuracy: 0.2900\n",
      "Epoch 00142: val_loss did not improve from 0.00027\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 2.7073e-04 - accuracy: 0.2703 - val_loss: 2.8126e-04 - val_accuracy: 0.0833\n",
      "Epoch 143/400\n",
      "4/6 [===================>..........] - ETA: 0s - loss: 1.6948e-04 - accuracy: 0.2625\n",
      "Epoch 00143: val_loss did not improve from 0.00027\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 2.0356e-04 - accuracy: 0.2432 - val_loss: 3.5143e-04 - val_accuracy: 0.3333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 144/400\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 2.8904e-04 - accuracy: 0.2500\n",
      "Epoch 00144: val_loss did not improve from 0.00027\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 2.9323e-04 - accuracy: 0.2523 - val_loss: 3.4927e-04 - val_accuracy: 0.2500\n",
      "Epoch 145/400\n",
      "4/6 [===================>..........] - ETA: 0s - loss: 3.2793e-04 - accuracy: 0.2875\n",
      "Epoch 00145: val_loss did not improve from 0.00027\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 2.8259e-04 - accuracy: 0.2883 - val_loss: 0.0137 - val_accuracy: 0.3333\n",
      "Epoch 146/400\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 0.0044 - accuracy: 0.3200\n",
      "Epoch 00146: val_loss did not improve from 0.00027\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.0040 - accuracy: 0.3333 - val_loss: 2.9305e-04 - val_accuracy: 0.0833\n",
      "Epoch 147/400\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 1.9811e-04 - accuracy: 0.3700\n",
      "Epoch 00147: val_loss did not improve from 0.00027\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 1.9056e-04 - accuracy: 0.3874 - val_loss: 2.8588e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 148/400\n",
      "4/6 [===================>..........] - ETA: 0s - loss: 1.5394e-04 - accuracy: 0.3000\n",
      "Epoch 00148: val_loss did not improve from 0.00027\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 1.7760e-04 - accuracy: 0.3333 - val_loss: 3.3802e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 149/400\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 1.9499e-04 - accuracy: 0.2800\n",
      "Epoch 00149: val_loss did not improve from 0.00027\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 2.1612e-04 - accuracy: 0.2883 - val_loss: 3.6932e-04 - val_accuracy: 0.0833\n",
      "Epoch 150/400\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 1.9529e-04 - accuracy: 0.3300\n",
      "Epoch 00150: val_loss did not improve from 0.00027\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 2.1077e-04 - accuracy: 0.3333 - val_loss: 3.3713e-04 - val_accuracy: 0.1667\n",
      "Epoch 151/400\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 1.9408e-04 - accuracy: 0.3600\n",
      "Epoch 00151: val_loss did not improve from 0.00027\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 1.8920e-04 - accuracy: 0.3333 - val_loss: 3.1356e-04 - val_accuracy: 0.1667\n",
      "Epoch 152/400\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 2.1056e-04 - accuracy: 0.3200\n",
      "Epoch 00152: val_loss did not improve from 0.00027\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 2.1221e-04 - accuracy: 0.3063 - val_loss: 3.8081e-04 - val_accuracy: 0.0833\n",
      "Epoch 153/400\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 2.2913e-04 - accuracy: 0.3300\n",
      "Epoch 00153: val_loss did not improve from 0.00027\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 2.2842e-04 - accuracy: 0.3333 - val_loss: 3.7183e-04 - val_accuracy: 0.0833\n",
      "Epoch 154/400\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 2.0062e-04 - accuracy: 0.3200\n",
      "Epoch 00154: val_loss did not improve from 0.00027\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 2.1319e-04 - accuracy: 0.3153 - val_loss: 5.6655e-04 - val_accuracy: 0.1667\n",
      "Epoch 155/400\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 2.8446e-04 - accuracy: 0.3500\n",
      "Epoch 00155: val_loss did not improve from 0.00027\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 2.7162e-04 - accuracy: 0.3514 - val_loss: 3.0909e-04 - val_accuracy: 0.0833\n",
      "Epoch 156/400\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 1.7767e-04 - accuracy: 0.3100\n",
      "Epoch 00156: val_loss did not improve from 0.00027\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 1.7903e-04 - accuracy: 0.3063 - val_loss: 4.2055e-04 - val_accuracy: 0.1667\n",
      "Epoch 157/400\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 2.6251e-04 - accuracy: 0.3700\n",
      "Epoch 00157: val_loss did not improve from 0.00027\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 2.5704e-04 - accuracy: 0.3423 - val_loss: 2.7392e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 158/400\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 2.2913e-04 - accuracy: 0.2000\n",
      "Epoch 00158: val_loss did not improve from 0.00027\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 2.2772e-04 - accuracy: 0.2342 - val_loss: 4.6150e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 159/400\n",
      "4/6 [===================>..........] - ETA: 0s - loss: 2.8023e-04 - accuracy: 0.3375\n",
      "Epoch 00159: val_loss did not improve from 0.00027\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 2.7453e-04 - accuracy: 0.3063 - val_loss: 3.7753e-04 - val_accuracy: 0.0833\n",
      "Epoch 160/400\n",
      "4/6 [===================>..........] - ETA: 0s - loss: 2.3796e-04 - accuracy: 0.3125\n",
      "Epoch 00160: val_loss did not improve from 0.00027\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 2.2859e-04 - accuracy: 0.3153 - val_loss: 3.3717e-04 - val_accuracy: 0.2500\n",
      "Epoch 161/400\n",
      "4/6 [===================>..........] - ETA: 0s - loss: 1.9083e-04 - accuracy: 0.3000\n",
      "Epoch 00161: val_loss did not improve from 0.00027\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 2.1028e-04 - accuracy: 0.3514 - val_loss: 3.3121e-04 - val_accuracy: 0.0833\n",
      "Epoch 162/400\n",
      "4/6 [===================>..........] - ETA: 0s - loss: 1.9746e-04 - accuracy: 0.2500\n",
      "Epoch 00162: val_loss did not improve from 0.00027\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 2.5582e-04 - accuracy: 0.2523 - val_loss: 4.4657e-04 - val_accuracy: 0.3333\n",
      "Epoch 163/400\n",
      "4/6 [===================>..........] - ETA: 0s - loss: 2.5712e-04 - accuracy: 0.3000\n",
      "Epoch 00163: val_loss did not improve from 0.00027\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 2.7512e-04 - accuracy: 0.2793 - val_loss: 3.2729e-04 - val_accuracy: 0.2500\n",
      "Epoch 164/400\n",
      "4/6 [===================>..........] - ETA: 0s - loss: 1.9602e-04 - accuracy: 0.2500\n",
      "Epoch 00164: val_loss did not improve from 0.00027\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 1.9809e-04 - accuracy: 0.2883 - val_loss: 2.8861e-04 - val_accuracy: 0.2500\n",
      "Epoch 165/400\n",
      "4/6 [===================>..........] - ETA: 0s - loss: 2.4320e-04 - accuracy: 0.3625\n",
      "Epoch 00165: val_loss did not improve from 0.00027\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 2.6886e-04 - accuracy: 0.3153 - val_loss: 4.2714e-04 - val_accuracy: 0.2500\n",
      "Epoch 166/400\n",
      "4/6 [===================>..........] - ETA: 0s - loss: 2.2570e-04 - accuracy: 0.3000\n",
      "Epoch 00166: val_loss did not improve from 0.00027\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 2.1426e-04 - accuracy: 0.2883 - val_loss: 3.0878e-04 - val_accuracy: 0.2500\n",
      "Epoch 167/400\n",
      "4/6 [===================>..........] - ETA: 0s - loss: 2.1630e-04 - accuracy: 0.2875\n",
      "Epoch 00167: val_loss did not improve from 0.00027\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 2.2003e-04 - accuracy: 0.2613 - val_loss: 3.5791e-04 - val_accuracy: 0.1667\n",
      "Epoch 168/400\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 3.1987e-04 - accuracy: 0.3200\n",
      "Epoch 00168: val_loss did not improve from 0.00027\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 3.0708e-04 - accuracy: 0.3243 - val_loss: 2.9149e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 169/400\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 2.2784e-04 - accuracy: 0.2600\n",
      "Epoch 00169: val_loss did not improve from 0.00027\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 2.1796e-04 - accuracy: 0.2703 - val_loss: 3.2034e-04 - val_accuracy: 0.1667\n",
      "Epoch 170/400\n",
      "4/6 [===================>..........] - ETA: 0s - loss: 2.1954e-04 - accuracy: 0.3000\n",
      "Epoch 00170: val_loss did not improve from 0.00027\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 2.3620e-04 - accuracy: 0.3243 - val_loss: 3.8514e-04 - val_accuracy: 0.0833\n",
      "Epoch 171/400\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 2.5584e-04 - accuracy: 0.3300\n",
      "Epoch 00171: val_loss did not improve from 0.00027\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 2.5208e-04 - accuracy: 0.3153 - val_loss: 3.3757e-04 - val_accuracy: 0.3333\n",
      "Epoch 172/400\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 2.0910e-04 - accuracy: 0.2600\n",
      "Epoch 00172: val_loss did not improve from 0.00027\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 1.9825e-04 - accuracy: 0.2432 - val_loss: 2.8916e-04 - val_accuracy: 0.0833\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 173/400\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 1.7637e-04 - accuracy: 0.3100\n",
      "Epoch 00173: val_loss did not improve from 0.00027\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 1.8487e-04 - accuracy: 0.3063 - val_loss: 4.1516e-04 - val_accuracy: 0.0833\n",
      "Epoch 174/400\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 4.1012e-04 - accuracy: 0.3000\n",
      "Epoch 00174: val_loss did not improve from 0.00027\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 4.0035e-04 - accuracy: 0.3153 - val_loss: 4.7835e-04 - val_accuracy: 0.0833\n",
      "Epoch 175/400\n",
      "4/6 [===================>..........] - ETA: 0s - loss: 2.5274e-04 - accuracy: 0.2875\n",
      "Epoch 00175: val_loss did not improve from 0.00027\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 2.5947e-04 - accuracy: 0.2883 - val_loss: 3.0116e-04 - val_accuracy: 0.2500\n",
      "Epoch 176/400\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 2.1903e-04 - accuracy: 0.2700\n",
      "Epoch 00176: val_loss did not improve from 0.00027\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 2.1316e-04 - accuracy: 0.2973 - val_loss: 3.5556e-04 - val_accuracy: 0.3333\n",
      "Epoch 177/400\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 3.4871e-04 - accuracy: 0.2800\n",
      "Epoch 00177: val_loss did not improve from 0.00027\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 3.4243e-04 - accuracy: 0.2883 - val_loss: 3.6816e-04 - val_accuracy: 0.0833\n",
      "Epoch 178/400\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 1.8497e-04 - accuracy: 0.2500\n",
      "Epoch 00178: val_loss did not improve from 0.00027\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 1.8564e-04 - accuracy: 0.2613 - val_loss: 3.5751e-04 - val_accuracy: 0.1667\n",
      "Epoch 179/400\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 3.2898e-04 - accuracy: 0.3000\n",
      "Epoch 00179: val_loss did not improve from 0.00027\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 3.1958e-04 - accuracy: 0.3153 - val_loss: 5.0017e-04 - val_accuracy: 0.2500\n",
      "Epoch 180/400\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 2.2010e-04 - accuracy: 0.3200\n",
      "Epoch 00180: val_loss did not improve from 0.00027\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 2.1218e-04 - accuracy: 0.3063 - val_loss: 2.9303e-04 - val_accuracy: 0.1667\n",
      "Epoch 181/400\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 2.3199e-04 - accuracy: 0.2900\n",
      "Epoch 00181: val_loss did not improve from 0.00027\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 2.3842e-04 - accuracy: 0.2973 - val_loss: 3.4338e-04 - val_accuracy: 0.3333\n",
      "Epoch 182/400\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 2.0814e-04 - accuracy: 0.3100\n",
      "Epoch 00182: val_loss did not improve from 0.00027\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 2.1095e-04 - accuracy: 0.3063 - val_loss: 3.9951e-04 - val_accuracy: 0.3333\n",
      "Epoch 183/400\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 2.9751e-04 - accuracy: 0.3100\n",
      "Epoch 00183: val_loss did not improve from 0.00027\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 2.9302e-04 - accuracy: 0.3243 - val_loss: 3.4368e-04 - val_accuracy: 0.3333\n",
      "Epoch 184/400\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 2.0512e-04 - accuracy: 0.3100\n",
      "Epoch 00184: val_loss did not improve from 0.00027\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 1.9442e-04 - accuracy: 0.3063 - val_loss: 2.9926e-04 - val_accuracy: 0.1667\n",
      "Epoch 185/400\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 2.5961e-04 - accuracy: 0.2500\n",
      "Epoch 00185: val_loss did not improve from 0.00027\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 2.5037e-04 - accuracy: 0.2523 - val_loss: 3.5168e-04 - val_accuracy: 0.0833\n",
      "Epoch 186/400\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 2.5142e-04 - accuracy: 0.2300\n",
      "Epoch 00186: val_loss did not improve from 0.00027\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 2.5373e-04 - accuracy: 0.2523 - val_loss: 3.8905e-04 - val_accuracy: 0.0833\n",
      "Epoch 187/400\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 1.7895e-04 - accuracy: 0.3100\n",
      "Epoch 00187: val_loss did not improve from 0.00027\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 2.2577e-04 - accuracy: 0.3243 - val_loss: 8.0008e-04 - val_accuracy: 0.3333\n",
      "Epoch 188/400\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 2.8347e-04 - accuracy: 0.2600\n",
      "Epoch 00188: val_loss did not improve from 0.00027\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 2.6721e-04 - accuracy: 0.2523 - val_loss: 3.2200e-04 - val_accuracy: 0.1667\n",
      "Epoch 189/400\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 1.9456e-04 - accuracy: 0.3200\n",
      "Epoch 00189: val_loss did not improve from 0.00027\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 1.8631e-04 - accuracy: 0.3423 - val_loss: 3.4722e-04 - val_accuracy: 0.1667\n",
      "Epoch 190/400\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 2.0075e-04 - accuracy: 0.2100\n",
      "Epoch 00190: val_loss did not improve from 0.00027\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 2.1411e-04 - accuracy: 0.2523 - val_loss: 6.9442e-04 - val_accuracy: 0.2500\n",
      "Epoch 191/400\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 3.1868e-04 - accuracy: 0.2300\n",
      "Epoch 00191: val_loss did not improve from 0.00027\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 3.0563e-04 - accuracy: 0.2342 - val_loss: 4.0219e-04 - val_accuracy: 0.1667\n",
      "Epoch 192/400\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 1.9813e-04 - accuracy: 0.3000\n",
      "Epoch 00192: val_loss improved from 0.00027 to 0.00027, saving model to tmp_checkpoint.h5\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 1.9132e-04 - accuracy: 0.3063 - val_loss: 2.6819e-04 - val_accuracy: 0.1667\n",
      "Epoch 193/400\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 2.3239e-04 - accuracy: 0.2700\n",
      "Epoch 00193: val_loss did not improve from 0.00027\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 2.2967e-04 - accuracy: 0.2793 - val_loss: 3.7533e-04 - val_accuracy: 0.0833\n",
      "Epoch 194/400\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 2.5349e-04 - accuracy: 0.2900\n",
      "Epoch 00194: val_loss did not improve from 0.00027\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 2.4374e-04 - accuracy: 0.3063 - val_loss: 3.3164e-04 - val_accuracy: 0.0833\n",
      "Epoch 195/400\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 2.7371e-04 - accuracy: 0.3800\n",
      "Epoch 00195: val_loss did not improve from 0.00027\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 2.6480e-04 - accuracy: 0.3874 - val_loss: 2.8807e-04 - val_accuracy: 0.0833\n",
      "Epoch 196/400\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 2.6165e-04 - accuracy: 0.2800\n",
      "Epoch 00196: val_loss did not improve from 0.00027\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 2.4587e-04 - accuracy: 0.3063 - val_loss: 4.6270e-04 - val_accuracy: 0.0833\n",
      "Epoch 197/400\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 2.3140e-04 - accuracy: 0.3400\n",
      "Epoch 00197: val_loss did not improve from 0.00027\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 2.3508e-04 - accuracy: 0.3514 - val_loss: 3.7909e-04 - val_accuracy: 0.0833\n",
      "Epoch 198/400\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 2.1804e-04 - accuracy: 0.1800\n",
      "Epoch 00198: val_loss did not improve from 0.00027\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 2.0490e-04 - accuracy: 0.1802 - val_loss: 3.2205e-04 - val_accuracy: 0.3333\n",
      "Epoch 199/400\n",
      "4/6 [===================>..........] - ETA: 0s - loss: 2.2303e-04 - accuracy: 0.2750\n",
      "Epoch 00199: val_loss did not improve from 0.00027\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 2.3830e-04 - accuracy: 0.2793 - val_loss: 4.6761e-04 - val_accuracy: 0.0833\n",
      "Epoch 200/400\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 2.3074e-04 - accuracy: 0.3300\n",
      "Epoch 00200: val_loss did not improve from 0.00027\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 2.4841e-04 - accuracy: 0.3063 - val_loss: 4.1611e-04 - val_accuracy: 0.3333\n",
      "Epoch 201/400\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 2.4394e-04 - accuracy: 0.3100\n",
      "Epoch 00201: val_loss did not improve from 0.00027\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 2.4716e-04 - accuracy: 0.3153 - val_loss: 3.4336e-04 - val_accuracy: 0.1667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 202/400\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 2.2465e-04 - accuracy: 0.3600\n",
      "Epoch 00202: val_loss did not improve from 0.00027\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 2.1702e-04 - accuracy: 0.3694 - val_loss: 3.3388e-04 - val_accuracy: 0.1667\n",
      "Epoch 203/400\n",
      "4/6 [===================>..........] - ETA: 0s - loss: 1.6888e-04 - accuracy: 0.4250\n",
      "Epoch 00203: val_loss did not improve from 0.00027\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 1.8769e-04 - accuracy: 0.3423 - val_loss: 3.9105e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 204/400\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 2.8952e-04 - accuracy: 0.3100\n",
      "Epoch 00204: val_loss did not improve from 0.00027\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 2.9440e-04 - accuracy: 0.3063 - val_loss: 5.4889e-04 - val_accuracy: 0.3333\n",
      "Epoch 205/400\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 2.6504e-04 - accuracy: 0.3000\n",
      "Epoch 00205: val_loss did not improve from 0.00027\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 2.5110e-04 - accuracy: 0.3243 - val_loss: 3.5071e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 206/400\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 2.2085e-04 - accuracy: 0.2700\n",
      "Epoch 00206: val_loss did not improve from 0.00027\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 2.1718e-04 - accuracy: 0.2883 - val_loss: 3.5184e-04 - val_accuracy: 0.2500\n",
      "Epoch 207/400\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 2.2062e-04 - accuracy: 0.2800\n",
      "Epoch 00207: val_loss did not improve from 0.00027\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 2.1615e-04 - accuracy: 0.2973 - val_loss: 3.9920e-04 - val_accuracy: 0.2500\n",
      "Epoch 208/400\n",
      "4/6 [===================>..........] - ETA: 0s - loss: 2.0533e-04 - accuracy: 0.2375\n",
      "Epoch 00208: val_loss did not improve from 0.00027\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 2.2920e-04 - accuracy: 0.2523 - val_loss: 4.3337e-04 - val_accuracy: 0.2500\n",
      "Epoch 209/400\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 2.1446e-04 - accuracy: 0.2900\n",
      "Epoch 00209: val_loss did not improve from 0.00027\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 2.3025e-04 - accuracy: 0.2793 - val_loss: 6.6954e-04 - val_accuracy: 0.0833\n",
      "Epoch 210/400\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 2.8697e-04 - accuracy: 0.3100\n",
      "Epoch 00210: val_loss did not improve from 0.00027\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 2.6939e-04 - accuracy: 0.2973 - val_loss: 3.1047e-04 - val_accuracy: 0.0833\n",
      "Epoch 211/400\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 1.9389e-04 - accuracy: 0.2800\n",
      "Epoch 00211: val_loss did not improve from 0.00027\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 2.0329e-04 - accuracy: 0.2793 - val_loss: 4.5167e-04 - val_accuracy: 0.2500\n",
      "Epoch 212/400\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 2.8157e-04 - accuracy: 0.2900\n",
      "Epoch 00212: val_loss did not improve from 0.00027\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 2.8487e-04 - accuracy: 0.2883 - val_loss: 4.6129e-04 - val_accuracy: 0.1667\n",
      "Epoch 213/400\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 2.6801e-04 - accuracy: 0.3600\n",
      "Epoch 00213: val_loss did not improve from 0.00027\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 2.5287e-04 - accuracy: 0.3694 - val_loss: 3.4202e-04 - val_accuracy: 0.2500\n",
      "Epoch 214/400\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 1.9347e-04 - accuracy: 0.3200\n",
      "Epoch 00214: val_loss did not improve from 0.00027\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 2.0642e-04 - accuracy: 0.2973 - val_loss: 4.8569e-04 - val_accuracy: 0.0833\n",
      "Epoch 215/400\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 2.5481e-04 - accuracy: 0.2800\n",
      "Epoch 00215: val_loss did not improve from 0.00027\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 2.5589e-04 - accuracy: 0.2883 - val_loss: 3.1556e-04 - val_accuracy: 0.2500\n",
      "Epoch 216/400\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 2.2891e-04 - accuracy: 0.3000\n",
      "Epoch 00216: val_loss did not improve from 0.00027\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 2.2282e-04 - accuracy: 0.2973 - val_loss: 3.1475e-04 - val_accuracy: 0.3333\n",
      "Epoch 217/400\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 1.8628e-04 - accuracy: 0.2900\n",
      "Epoch 00217: val_loss did not improve from 0.00027\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 2.2304e-04 - accuracy: 0.2883 - val_loss: 5.9880e-04 - val_accuracy: 0.1667\n",
      "Epoch 218/400\n",
      "4/6 [===================>..........] - ETA: 0s - loss: 2.7433e-04 - accuracy: 0.2750\n",
      "Epoch 00218: val_loss did not improve from 0.00027\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 2.2418e-04 - accuracy: 0.2793 - val_loss: 2.8952e-04 - val_accuracy: 0.0833\n",
      "Epoch 219/400\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 2.9424e-04 - accuracy: 0.2700\n",
      "Epoch 00219: val_loss did not improve from 0.00027\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 2.7435e-04 - accuracy: 0.2973 - val_loss: 3.0749e-04 - val_accuracy: 0.2500\n",
      "Epoch 220/400\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 1.8747e-04 - accuracy: 0.2200\n",
      "Epoch 00220: val_loss did not improve from 0.00027\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 1.9140e-04 - accuracy: 0.2523 - val_loss: 4.0654e-04 - val_accuracy: 0.3333\n",
      "Epoch 221/400\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 2.4952e-04 - accuracy: 0.3800\n",
      "Epoch 00221: val_loss did not improve from 0.00027\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 2.3831e-04 - accuracy: 0.3604 - val_loss: 2.9877e-04 - val_accuracy: 0.0833\n",
      "Epoch 222/400\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 2.4445e-04 - accuracy: 0.2800\n",
      "Epoch 00222: val_loss did not improve from 0.00027\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 2.3589e-04 - accuracy: 0.2703 - val_loss: 3.6388e-04 - val_accuracy: 0.2500\n",
      "Epoch 223/400\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 2.2321e-04 - accuracy: 0.3100\n",
      "Epoch 00223: val_loss did not improve from 0.00027\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 2.2387e-04 - accuracy: 0.3153 - val_loss: 3.0591e-04 - val_accuracy: 0.0833\n",
      "Epoch 224/400\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 2.1748e-04 - accuracy: 0.3300\n",
      "Epoch 00224: val_loss did not improve from 0.00027\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 2.4316e-04 - accuracy: 0.3063 - val_loss: 5.5749e-04 - val_accuracy: 0.2500\n",
      "Epoch 225/400\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 2.9368e-04 - accuracy: 0.4000\n",
      "Epoch 00225: val_loss did not improve from 0.00027\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 2.9869e-04 - accuracy: 0.3874 - val_loss: 4.2310e-04 - val_accuracy: 0.2500\n",
      "Epoch 226/400\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 2.0048e-04 - accuracy: 0.2700\n",
      "Epoch 00226: val_loss did not improve from 0.00027\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 2.0029e-04 - accuracy: 0.2883 - val_loss: 3.5359e-04 - val_accuracy: 0.0833\n",
      "Epoch 227/400\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 1.9961e-04 - accuracy: 0.2800\n",
      "Epoch 00227: val_loss did not improve from 0.00027\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 1.9451e-04 - accuracy: 0.2883 - val_loss: 3.5645e-04 - val_accuracy: 0.3333\n",
      "Epoch 228/400\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 2.2314e-04 - accuracy: 0.2300\n",
      "Epoch 00228: val_loss did not improve from 0.00027\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 2.0934e-04 - accuracy: 0.2252 - val_loss: 3.1161e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 229/400\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 2.8720e-04 - accuracy: 0.2700\n",
      "Epoch 00229: val_loss did not improve from 0.00027\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 2.9042e-04 - accuracy: 0.2883 - val_loss: 4.3510e-04 - val_accuracy: 0.1667\n",
      "Epoch 230/400\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 2.0112e-04 - accuracy: 0.2600\n",
      "Epoch 00230: val_loss did not improve from 0.00027\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 1.9490e-04 - accuracy: 0.2703 - val_loss: 3.3620e-04 - val_accuracy: 0.1667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 231/400\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 1.9123e-04 - accuracy: 0.3000\n",
      "Epoch 00231: val_loss did not improve from 0.00027\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 2.1428e-04 - accuracy: 0.2793 - val_loss: 7.3297e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 232/400\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 2.8214e-04 - accuracy: 0.3700\n",
      "Epoch 00232: val_loss did not improve from 0.00027\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 2.9206e-04 - accuracy: 0.3604 - val_loss: 4.5375e-04 - val_accuracy: 0.0833\n",
      "Epoch 233/400\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 2.1441e-04 - accuracy: 0.3400\n",
      "Epoch 00233: val_loss did not improve from 0.00027\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 2.1978e-04 - accuracy: 0.3063 - val_loss: 4.2284e-04 - val_accuracy: 0.2500\n",
      "Epoch 234/400\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 2.2395e-04 - accuracy: 0.3400\n",
      "Epoch 00234: val_loss did not improve from 0.00027\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 2.2094e-04 - accuracy: 0.3333 - val_loss: 3.5218e-04 - val_accuracy: 0.1667\n",
      "Epoch 235/400\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 2.5109e-04 - accuracy: 0.2900\n",
      "Epoch 00235: val_loss did not improve from 0.00027\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 2.7901e-04 - accuracy: 0.2703 - val_loss: 5.5697e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 236/400\n",
      "4/6 [===================>..........] - ETA: 0s - loss: 2.6339e-04 - accuracy: 0.2750\n",
      "Epoch 00236: val_loss did not improve from 0.00027\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 2.2834e-04 - accuracy: 0.2793 - val_loss: 3.1215e-04 - val_accuracy: 0.0833\n",
      "Epoch 237/400\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 1.7358e-04 - accuracy: 0.2700\n",
      "Epoch 00237: val_loss did not improve from 0.00027\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 1.7681e-04 - accuracy: 0.2883 - val_loss: 3.3314e-04 - val_accuracy: 0.0833\n",
      "Epoch 238/400\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 1.9854e-04 - accuracy: 0.2800\n",
      "Epoch 00238: val_loss did not improve from 0.00027\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 1.9311e-04 - accuracy: 0.2613 - val_loss: 4.0959e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 239/400\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 2.2886e-04 - accuracy: 0.3000\n",
      "Epoch 00239: val_loss did not improve from 0.00027\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 2.3141e-04 - accuracy: 0.2883 - val_loss: 3.8106e-04 - val_accuracy: 0.0833\n",
      "Epoch 240/400\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 2.3094e-04 - accuracy: 0.2900\n",
      "Epoch 00240: val_loss did not improve from 0.00027\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 2.2517e-04 - accuracy: 0.2613 - val_loss: 3.1181e-04 - val_accuracy: 0.3333\n",
      "Epoch 241/400\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 2.1828e-04 - accuracy: 0.2600\n",
      "Epoch 00241: val_loss did not improve from 0.00027\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 2.3411e-04 - accuracy: 0.2523 - val_loss: 5.7528e-04 - val_accuracy: 0.0833\n",
      "Epoch 242/400\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 2.5908e-04 - accuracy: 0.3100\n",
      "Epoch 00242: val_loss did not improve from 0.00027\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 2.5279e-04 - accuracy: 0.3423 - val_loss: 4.0165e-04 - val_accuracy: 0.2500\n",
      "Epoch 243/400\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 2.1309e-04 - accuracy: 0.3200\n",
      "Epoch 00243: val_loss did not improve from 0.00027\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 2.1801e-04 - accuracy: 0.3153 - val_loss: 3.6322e-04 - val_accuracy: 0.0833\n",
      "Epoch 244/400\n",
      "4/6 [===================>..........] - ETA: 0s - loss: 2.1224e-04 - accuracy: 0.2375\n",
      "Epoch 00244: val_loss did not improve from 0.00027\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 2.2186e-04 - accuracy: 0.2342 - val_loss: 4.0353e-04 - val_accuracy: 0.0833\n",
      "Epoch 245/400\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 2.0125e-04 - accuracy: 0.3000\n",
      "Epoch 00245: val_loss did not improve from 0.00027\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 1.9911e-04 - accuracy: 0.2793 - val_loss: 3.9811e-04 - val_accuracy: 0.2500\n",
      "Epoch 246/400\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 2.3596e-04 - accuracy: 0.40 - ETA: 0s - loss: 2.1402e-04 - accuracy: 0.3000\n",
      "Epoch 00246: val_loss did not improve from 0.00027\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 2.0480e-04 - accuracy: 0.3243 - val_loss: 3.2167e-04 - val_accuracy: 0.0833\n",
      "Epoch 247/400\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 2.5137e-04 - accuracy: 0.3000\n",
      "Epoch 00247: val_loss did not improve from 0.00027\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 2.5025e-04 - accuracy: 0.2793 - val_loss: 3.6767e-04 - val_accuracy: 0.1667\n",
      "Epoch 248/400\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 1.9202e-04 - accuracy: 0.2900\n",
      "Epoch 00248: val_loss did not improve from 0.00027\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 1.8520e-04 - accuracy: 0.2793 - val_loss: 2.9085e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 249/400\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 2.2930e-04 - accuracy: 0.3200\n",
      "Epoch 00249: val_loss did not improve from 0.00027\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 2.3924e-04 - accuracy: 0.2973 - val_loss: 5.5345e-04 - val_accuracy: 0.3333\n",
      "Epoch 250/400\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 2.7399e-04 - accuracy: 0.3600\n",
      "Epoch 00250: val_loss did not improve from 0.00027\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 2.6944e-04 - accuracy: 0.3604 - val_loss: 3.8372e-04 - val_accuracy: 0.1667\n",
      "Epoch 251/400\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 1.9024e-04 - accuracy: 0.3300\n",
      "Epoch 00251: val_loss did not improve from 0.00027\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 1.9249e-04 - accuracy: 0.3153 - val_loss: 4.7260e-04 - val_accuracy: 0.0833\n",
      "Epoch 252/400\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 2.0710e-04 - accuracy: 0.2800\n",
      "Epoch 00252: val_loss did not improve from 0.00027\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 2.0042e-04 - accuracy: 0.2973 - val_loss: 3.5356e-04 - val_accuracy: 0.1667\n",
      "Epoch 253/400\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 1.7633e-04 - accuracy: 0.3300\n",
      "Epoch 00253: val_loss did not improve from 0.00027\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 1.9082e-04 - accuracy: 0.3153 - val_loss: 5.0776e-04 - val_accuracy: 0.1667\n",
      "Epoch 254/400\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 2.5019e-04 - accuracy: 0.2500\n",
      "Epoch 00254: val_loss did not improve from 0.00027\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 2.4266e-04 - accuracy: 0.2703 - val_loss: 4.2392e-04 - val_accuracy: 0.1667\n",
      "Epoch 255/400\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 2.5021e-04 - accuracy: 0.2700\n",
      "Epoch 00255: val_loss did not improve from 0.00027\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 2.4097e-04 - accuracy: 0.2703 - val_loss: 4.7601e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 256/400\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 2.4772e-04 - accuracy: 0.2700\n",
      "Epoch 00256: val_loss did not improve from 0.00027\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 2.4929e-04 - accuracy: 0.2793 - val_loss: 4.1748e-04 - val_accuracy: 0.2500\n",
      "Epoch 257/400\n",
      "4/6 [===================>..........] - ETA: 0s - loss: 2.1114e-04 - accuracy: 0.3750\n",
      "Epoch 00257: val_loss did not improve from 0.00027\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 2.0769e-04 - accuracy: 0.2883 - val_loss: 4.5191e-04 - val_accuracy: 0.3333\n",
      "Epoch 258/400\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 2.4807e-04 - accuracy: 0.3400\n",
      "Epoch 00258: val_loss did not improve from 0.00027\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 2.3367e-04 - accuracy: 0.3333 - val_loss: 4.2191e-04 - val_accuracy: 0.1667\n",
      "Epoch 259/400\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 1.8789e-04 - accuracy: 0.2900\n",
      "Epoch 00259: val_loss did not improve from 0.00027\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 1.9674e-04 - accuracy: 0.2973 - val_loss: 3.0350e-04 - val_accuracy: 0.2500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 260/400\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 2.5104e-04 - accuracy: 0.2800\n",
      "Epoch 00260: val_loss did not improve from 0.00027\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 2.4793e-04 - accuracy: 0.2793 - val_loss: 3.3662e-04 - val_accuracy: 0.1667\n",
      "Epoch 261/400\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 2.6361e-04 - accuracy: 0.2700\n",
      "Epoch 00261: val_loss did not improve from 0.00027\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 2.8548e-04 - accuracy: 0.2793 - val_loss: 3.4558e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 262/400\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 1.9814e-04 - accuracy: 0.3200\n",
      "Epoch 00262: val_loss did not improve from 0.00027\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 1.9548e-04 - accuracy: 0.3243 - val_loss: 3.4712e-04 - val_accuracy: 0.2500\n",
      "Epoch 263/400\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 2.0172e-04 - accuracy: 0.2800\n",
      "Epoch 00263: val_loss did not improve from 0.00027\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 2.1861e-04 - accuracy: 0.2793 - val_loss: 4.3318e-04 - val_accuracy: 0.1667\n",
      "Epoch 264/400\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 2.1722e-04 - accuracy: 0.3200\n",
      "Epoch 00264: val_loss did not improve from 0.00027\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 2.1223e-04 - accuracy: 0.3153 - val_loss: 3.3712e-04 - val_accuracy: 0.3333\n",
      "Epoch 265/400\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 2.1011e-04 - accuracy: 0.3100\n",
      "Epoch 00265: val_loss did not improve from 0.00027\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 2.0786e-04 - accuracy: 0.3153 - val_loss: 3.3417e-04 - val_accuracy: 0.0833\n",
      "Epoch 266/400\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 1.8440e-04 - accuracy: 0.3900\n",
      "Epoch 00266: val_loss did not improve from 0.00027\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 1.8275e-04 - accuracy: 0.3604 - val_loss: 5.5971e-04 - val_accuracy: 0.2500\n",
      "Epoch 267/400\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 2.8717e-04 - accuracy: 0.2700\n",
      "Epoch 00267: val_loss did not improve from 0.00027\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 2.6821e-04 - accuracy: 0.2793 - val_loss: 3.4874e-04 - val_accuracy: 0.2500\n",
      "Epoch 268/400\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 2.3391e-04 - accuracy: 0.3000\n",
      "Epoch 00268: val_loss did not improve from 0.00027\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 2.2830e-04 - accuracy: 0.2973 - val_loss: 3.0314e-04 - val_accuracy: 0.1667\n",
      "Epoch 269/400\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 1.8148e-04 - accuracy: 0.3100\n",
      "Epoch 00269: val_loss did not improve from 0.00027\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 1.8163e-04 - accuracy: 0.3063 - val_loss: 4.2905e-04 - val_accuracy: 0.0833\n",
      "Epoch 270/400\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 2.2773e-04 - accuracy: 0.2700\n",
      "Epoch 00270: val_loss did not improve from 0.00027\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 2.2907e-04 - accuracy: 0.2793 - val_loss: 4.3118e-04 - val_accuracy: 0.0833\n",
      "Epoch 271/400\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 2.3374e-04 - accuracy: 0.3300\n",
      "Epoch 00271: val_loss did not improve from 0.00027\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 2.2354e-04 - accuracy: 0.3243 - val_loss: 3.6917e-04 - val_accuracy: 0.0833\n",
      "Epoch 272/400\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 2.2421e-04 - accuracy: 0.3100\n",
      "Epoch 00272: val_loss did not improve from 0.00027\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 2.1642e-04 - accuracy: 0.3153 - val_loss: 3.4821e-04 - val_accuracy: 0.1667\n",
      "Epoch 273/400\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 2.5957e-04 - accuracy: 0.2900\n",
      "Epoch 00273: val_loss did not improve from 0.00027\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 2.6434e-04 - accuracy: 0.2883 - val_loss: 3.6537e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 274/400\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 2.1833e-04 - accuracy: 0.3200\n",
      "Epoch 00274: val_loss did not improve from 0.00027\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 2.1008e-04 - accuracy: 0.3243 - val_loss: 3.4242e-04 - val_accuracy: 0.0833\n",
      "Epoch 275/400\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 2.3036e-04 - accuracy: 0.3800\n",
      "Epoch 00275: val_loss did not improve from 0.00027\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 2.2199e-04 - accuracy: 0.3964 - val_loss: 5.6804e-04 - val_accuracy: 0.2500\n",
      "Epoch 276/400\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 1.9327e-04 - accuracy: 0.2800\n",
      "Epoch 00276: val_loss did not improve from 0.00027\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 1.9884e-04 - accuracy: 0.2883 - val_loss: 4.2359e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 277/400\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 2.4252e-04 - accuracy: 0.3400\n",
      "Epoch 00277: val_loss did not improve from 0.00027\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 2.3899e-04 - accuracy: 0.3153 - val_loss: 3.8100e-04 - val_accuracy: 0.1667\n",
      "Epoch 278/400\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 2.0597e-04 - accuracy: 0.3500\n",
      "Epoch 00278: val_loss did not improve from 0.00027\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 1.9933e-04 - accuracy: 0.3423 - val_loss: 3.8087e-04 - val_accuracy: 0.1667\n",
      "Epoch 279/400\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 1.8146e-04 - accuracy: 0.2400\n",
      "Epoch 00279: val_loss did not improve from 0.00027\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 1.7649e-04 - accuracy: 0.2613 - val_loss: 3.8714e-04 - val_accuracy: 0.1667\n",
      "Epoch 280/400\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 2.8803e-04 - accuracy: 0.2900\n",
      "Epoch 00280: val_loss did not improve from 0.00027\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 2.8120e-04 - accuracy: 0.2973 - val_loss: 4.9088e-04 - val_accuracy: 0.1667\n",
      "Epoch 281/400\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 2.2347e-04 - accuracy: 0.2300\n",
      "Epoch 00281: val_loss did not improve from 0.00027\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 2.3220e-04 - accuracy: 0.2252 - val_loss: 4.0434e-04 - val_accuracy: 0.0833\n",
      "Epoch 282/400\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 1.8181e-04 - accuracy: 0.2800\n",
      "Epoch 00282: val_loss did not improve from 0.00027\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 1.9648e-04 - accuracy: 0.3063 - val_loss: 5.8925e-04 - val_accuracy: 0.1667\n",
      "Epoch 283/400\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 2.3850e-04 - accuracy: 0.2800\n",
      "Epoch 00283: val_loss did not improve from 0.00027\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 2.2339e-04 - accuracy: 0.2883 - val_loss: 3.0802e-04 - val_accuracy: 0.1667\n",
      "Epoch 284/400\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 1.7318e-04 - accuracy: 0.2700\n",
      "Epoch 00284: val_loss did not improve from 0.00027\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 1.8044e-04 - accuracy: 0.2793 - val_loss: 3.9314e-04 - val_accuracy: 0.1667\n",
      "Epoch 285/400\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 1.8691e-04 - accuracy: 0.3100\n",
      "Epoch 00285: val_loss did not improve from 0.00027\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 2.0513e-04 - accuracy: 0.3153 - val_loss: 3.3194e-04 - val_accuracy: 0.1667\n",
      "Epoch 286/400\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 2.5582e-04 - accuracy: 0.3400\n",
      "Epoch 00286: val_loss did not improve from 0.00027\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 2.4770e-04 - accuracy: 0.3423 - val_loss: 4.1218e-04 - val_accuracy: 0.3333\n",
      "Epoch 287/400\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 1.9850e-04 - accuracy: 0.4100\n",
      "Epoch 00287: val_loss did not improve from 0.00027\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 1.9496e-04 - accuracy: 0.3964 - val_loss: 3.3495e-04 - val_accuracy: 0.1667\n",
      "Epoch 288/400\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 2.1567e-04 - accuracy: 0.2900\n",
      "Epoch 00288: val_loss did not improve from 0.00027\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 2.3536e-04 - accuracy: 0.2883 - val_loss: 4.7909e-04 - val_accuracy: 0.2500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 289/400\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 2.5359e-04 - accuracy: 0.3100\n",
      "Epoch 00289: val_loss did not improve from 0.00027\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 2.4354e-04 - accuracy: 0.2883 - val_loss: 4.9976e-04 - val_accuracy: 0.1667\n",
      "Epoch 290/400\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 2.1436e-04 - accuracy: 0.3400\n",
      "Epoch 00290: val_loss did not improve from 0.00027\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 2.0623e-04 - accuracy: 0.3423 - val_loss: 4.0692e-04 - val_accuracy: 0.1667\n",
      "Epoch 291/400\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 1.9595e-04 - accuracy: 0.3000\n",
      "Epoch 00291: val_loss did not improve from 0.00027\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 1.8403e-04 - accuracy: 0.2973 - val_loss: 3.1790e-04 - val_accuracy: 0.1667\n",
      "Epoch 292/400\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 1.9434e-04 - accuracy: 0.3400\n",
      "Epoch 00292: val_loss did not improve from 0.00027\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 1.9448e-04 - accuracy: 0.3514 - val_loss: 4.9574e-04 - val_accuracy: 0.2500\n",
      "Epoch 293/400\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 2.5818e-04 - accuracy: 0.2600\n",
      "Epoch 00293: val_loss did not improve from 0.00027\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 2.5164e-04 - accuracy: 0.2613 - val_loss: 3.8752e-04 - val_accuracy: 0.2500\n",
      "Epoch 294/400\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 2.2323e-04 - accuracy: 0.3300\n",
      "Epoch 00294: val_loss did not improve from 0.00027\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 2.1633e-04 - accuracy: 0.3153 - val_loss: 4.1790e-04 - val_accuracy: 0.0833\n",
      "Epoch 295/400\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 2.5855e-04 - accuracy: 0.3300\n",
      "Epoch 00295: val_loss did not improve from 0.00027\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 2.5805e-04 - accuracy: 0.3423 - val_loss: 3.5351e-04 - val_accuracy: 0.2500\n",
      "Epoch 296/400\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 1.9658e-04 - accuracy: 0.3400\n",
      "Epoch 00296: val_loss did not improve from 0.00027\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 1.9002e-04 - accuracy: 0.3514 - val_loss: 2.8769e-04 - val_accuracy: 0.1667\n",
      "Epoch 297/400\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 1.7414e-04 - accuracy: 0.2500\n",
      "Epoch 00297: val_loss did not improve from 0.00027\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 1.7800e-04 - accuracy: 0.2252 - val_loss: 3.2555e-04 - val_accuracy: 0.2500\n",
      "Epoch 298/400\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 1.7273e-04 - accuracy: 0.2600\n",
      "Epoch 00298: val_loss did not improve from 0.00027\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 1.7862e-04 - accuracy: 0.2703 - val_loss: 3.8959e-04 - val_accuracy: 0.0833\n",
      "Epoch 299/400\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 1.9421e-04 - accuracy: 0.2800\n",
      "Epoch 00299: val_loss did not improve from 0.00027\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 1.9686e-04 - accuracy: 0.2703 - val_loss: 4.7083e-04 - val_accuracy: 0.0833\n",
      "Epoch 300/400\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 3.1599e-04 - accuracy: 0.3700\n",
      "Epoch 00300: val_loss did not improve from 0.00027\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 2.9928e-04 - accuracy: 0.3514 - val_loss: 4.5005e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 301/400\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 2.1979e-04 - accuracy: 0.3000\n",
      "Epoch 00301: val_loss did not improve from 0.00027\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 2.0822e-04 - accuracy: 0.3153 - val_loss: 3.5284e-04 - val_accuracy: 0.2500\n",
      "Epoch 302/400\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 1.7530e-04 - accuracy: 0.3400\n",
      "Epoch 00302: val_loss did not improve from 0.00027\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 1.7436e-04 - accuracy: 0.3514 - val_loss: 3.4866e-04 - val_accuracy: 0.0833\n",
      "Epoch 303/400\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 2.8572e-04 - accuracy: 0.3600\n",
      "Epoch 00303: val_loss did not improve from 0.00027\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 2.7633e-04 - accuracy: 0.3874 - val_loss: 4.2258e-04 - val_accuracy: 0.2500\n",
      "Epoch 304/400\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 2.3239e-04 - accuracy: 0.3000\n",
      "Epoch 00304: val_loss did not improve from 0.00027\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 2.2524e-04 - accuracy: 0.2973 - val_loss: 3.3775e-04 - val_accuracy: 0.2500\n",
      "Epoch 305/400\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 1.8655e-04 - accuracy: 0.3700\n",
      "Epoch 00305: val_loss did not improve from 0.00027\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 1.7992e-04 - accuracy: 0.3604 - val_loss: 3.1094e-04 - val_accuracy: 0.1667\n",
      "Epoch 306/400\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 1.9693e-04 - accuracy: 0.3600\n",
      "Epoch 00306: val_loss did not improve from 0.00027\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 1.9066e-04 - accuracy: 0.3423 - val_loss: 4.3291e-04 - val_accuracy: 0.1667\n",
      "Epoch 307/400\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 2.2350e-04 - accuracy: 0.3100\n",
      "Epoch 00307: val_loss did not improve from 0.00027\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 2.2445e-04 - accuracy: 0.3153 - val_loss: 4.1075e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 308/400\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 1.9656e-04 - accuracy: 0.3400\n",
      "Epoch 00308: val_loss did not improve from 0.00027\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 1.8975e-04 - accuracy: 0.3153 - val_loss: 3.2365e-04 - val_accuracy: 0.3333\n",
      "Epoch 309/400\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 2.8558e-04 - accuracy: 0.3100\n",
      "Epoch 00309: val_loss did not improve from 0.00027\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 2.6974e-04 - accuracy: 0.3153 - val_loss: 5.4692e-04 - val_accuracy: 0.2500\n",
      "Epoch 310/400\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 2.0634e-04 - accuracy: 0.3800\n",
      "Epoch 00310: val_loss did not improve from 0.00027\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 1.9023e-04 - accuracy: 0.3694 - val_loss: 3.3527e-04 - val_accuracy: 0.2500\n",
      "Epoch 311/400\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 2.8113e-04 - accuracy: 0.2400\n",
      "Epoch 00311: val_loss did not improve from 0.00027\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 2.7110e-04 - accuracy: 0.2252 - val_loss: 3.0467e-04 - val_accuracy: 0.3333\n",
      "Epoch 312/400\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 2.1661e-04 - accuracy: 0.2700\n",
      "Epoch 00312: val_loss did not improve from 0.00027\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 2.1005e-04 - accuracy: 0.2703 - val_loss: 3.9819e-04 - val_accuracy: 0.0833\n",
      "Epoch 313/400\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 2.0022e-04 - accuracy: 0.2800\n",
      "Epoch 00313: val_loss did not improve from 0.00027\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 2.0674e-04 - accuracy: 0.2613 - val_loss: 4.5203e-04 - val_accuracy: 0.2500\n",
      "Epoch 314/400\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 2.0936e-04 - accuracy: 0.2600\n",
      "Epoch 00314: val_loss did not improve from 0.00027\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 2.1843e-04 - accuracy: 0.2613 - val_loss: 4.2904e-04 - val_accuracy: 0.3333\n",
      "Epoch 315/400\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 1.9366e-04 - accuracy: 0.3200\n",
      "Epoch 00315: val_loss did not improve from 0.00027\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 2.2222e-04 - accuracy: 0.3243 - val_loss: 4.2787e-04 - val_accuracy: 0.3333\n",
      "Epoch 316/400\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 2.1939e-04 - accuracy: 0.2800\n",
      "Epoch 00316: val_loss did not improve from 0.00027\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 2.1326e-04 - accuracy: 0.2703 - val_loss: 3.2189e-04 - val_accuracy: 0.1667\n",
      "Epoch 317/400\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 1.7979e-04 - accuracy: 0.3400\n",
      "Epoch 00317: val_loss did not improve from 0.00027\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 1.7734e-04 - accuracy: 0.3333 - val_loss: 3.5109e-04 - val_accuracy: 0.1667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 318/400\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 1.9421e-04 - accuracy: 0.3300\n",
      "Epoch 00318: val_loss did not improve from 0.00027\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 2.1314e-04 - accuracy: 0.3333 - val_loss: 4.0967e-04 - val_accuracy: 0.1667\n",
      "Epoch 319/400\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 2.2056e-04 - accuracy: 0.2600\n",
      "Epoch 00319: val_loss did not improve from 0.00027\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 2.2483e-04 - accuracy: 0.2883 - val_loss: 4.5469e-04 - val_accuracy: 0.2500\n",
      "Epoch 320/400\n",
      "4/6 [===================>..........] - ETA: 0s - loss: 1.8944e-04 - accuracy: 0.3625\n",
      "Epoch 00320: val_loss did not improve from 0.00027\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 1.8121e-04 - accuracy: 0.3423 - val_loss: 3.8101e-04 - val_accuracy: 0.3333\n",
      "Epoch 321/400\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 2.0154e-04 - accuracy: 0.3300\n",
      "Epoch 00321: val_loss did not improve from 0.00027\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 2.1776e-04 - accuracy: 0.3243 - val_loss: 4.7439e-04 - val_accuracy: 0.0833\n",
      "Epoch 322/400\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 2.2628e-04 - accuracy: 0.3200\n",
      "Epoch 00322: val_loss did not improve from 0.00027\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 2.2929e-04 - accuracy: 0.3153 - val_loss: 3.9882e-04 - val_accuracy: 0.3333\n",
      "Epoch 323/400\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 1.8912e-04 - accuracy: 0.2900\n",
      "Epoch 00323: val_loss did not improve from 0.00027\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 1.8438e-04 - accuracy: 0.2973 - val_loss: 3.6536e-04 - val_accuracy: 0.2500\n",
      "Epoch 324/400\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 2.1712e-04 - accuracy: 0.3200\n",
      "Epoch 00324: val_loss did not improve from 0.00027\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 2.1519e-04 - accuracy: 0.3423 - val_loss: 4.0493e-04 - val_accuracy: 0.1667\n",
      "Epoch 325/400\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 2.3195e-04 - accuracy: 0.3100\n",
      "Epoch 00325: val_loss did not improve from 0.00027\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 2.1945e-04 - accuracy: 0.2883 - val_loss: 3.0479e-04 - val_accuracy: 0.3333\n",
      "Epoch 326/400\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 2.8350e-04 - accuracy: 0.3100\n",
      "Epoch 00326: val_loss did not improve from 0.00027\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 2.6762e-04 - accuracy: 0.3243 - val_loss: 3.6216e-04 - val_accuracy: 0.1667\n",
      "Epoch 327/400\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 1.7932e-04 - accuracy: 0.3300\n",
      "Epoch 00327: val_loss did not improve from 0.00027\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 1.7937e-04 - accuracy: 0.2973 - val_loss: 3.9242e-04 - val_accuracy: 0.1667\n",
      "Epoch 328/400\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 1.9079e-04 - accuracy: 0.3200\n",
      "Epoch 00328: val_loss did not improve from 0.00027\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 1.9192e-04 - accuracy: 0.2973 - val_loss: 3.3737e-04 - val_accuracy: 0.2500\n",
      "Epoch 329/400\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 1.9357e-04 - accuracy: 0.3100\n",
      "Epoch 00329: val_loss did not improve from 0.00027\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 1.9363e-04 - accuracy: 0.3063 - val_loss: 3.8503e-04 - val_accuracy: 0.0833\n",
      "Epoch 330/400\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 2.5035e-04 - accuracy: 0.2600\n",
      "Epoch 00330: val_loss did not improve from 0.00027\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 2.3603e-04 - accuracy: 0.2523 - val_loss: 4.1491e-04 - val_accuracy: 0.1667\n",
      "Epoch 331/400\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 1.9969e-04 - accuracy: 0.3300\n",
      "Epoch 00331: val_loss did not improve from 0.00027\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 1.8951e-04 - accuracy: 0.3243 - val_loss: 4.0331e-04 - val_accuracy: 0.0833\n",
      "Epoch 332/400\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 2.5486e-04 - accuracy: 0.2600\n",
      "Epoch 00332: val_loss did not improve from 0.00027\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 2.5908e-04 - accuracy: 0.2793 - val_loss: 6.4418e-04 - val_accuracy: 0.2500\n",
      "Epoch 333/400\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 2.7015e-04 - accuracy: 0.3600\n",
      "Epoch 00333: val_loss did not improve from 0.00027\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 2.5711e-04 - accuracy: 0.3694 - val_loss: 3.3657e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 334/400\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 1.7518e-04 - accuracy: 0.3200\n",
      "Epoch 00334: val_loss did not improve from 0.00027\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 1.9280e-04 - accuracy: 0.3063 - val_loss: 5.7748e-04 - val_accuracy: 0.2500\n",
      "Epoch 335/400\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 2.1562e-04 - accuracy: 0.3200\n",
      "Epoch 00335: val_loss did not improve from 0.00027\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 2.1068e-04 - accuracy: 0.3153 - val_loss: 3.4571e-04 - val_accuracy: 0.3333\n",
      "Epoch 336/400\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 2.0148e-04 - accuracy: 0.3100\n",
      "Epoch 00336: val_loss did not improve from 0.00027\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 2.0792e-04 - accuracy: 0.3063 - val_loss: 3.2682e-04 - val_accuracy: 0.0833\n",
      "Epoch 337/400\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 1.8272e-04 - accuracy: 0.3800\n",
      "Epoch 00337: val_loss did not improve from 0.00027\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 1.8758e-04 - accuracy: 0.3604 - val_loss: 3.7870e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 338/400\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 1.8416e-04 - accuracy: 0.2600\n",
      "Epoch 00338: val_loss did not improve from 0.00027\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 1.8036e-04 - accuracy: 0.2613 - val_loss: 3.6393e-04 - val_accuracy: 0.2500\n",
      "Epoch 339/400\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 2.0987e-04 - accuracy: 0.2800\n",
      "Epoch 00339: val_loss did not improve from 0.00027\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 2.3408e-04 - accuracy: 0.2883 - val_loss: 5.5641e-04 - val_accuracy: 0.2500\n",
      "Epoch 340/400\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 2.4830e-04 - accuracy: 0.3100\n",
      "Epoch 00340: val_loss did not improve from 0.00027\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 2.3203e-04 - accuracy: 0.2883 - val_loss: 3.3036e-04 - val_accuracy: 0.2500\n",
      "Epoch 341/400\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 2.0325e-04 - accuracy: 0.3200\n",
      "Epoch 00341: val_loss did not improve from 0.00027\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 1.9685e-04 - accuracy: 0.2973 - val_loss: 3.9626e-04 - val_accuracy: 0.0833\n",
      "Epoch 342/400\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 1.7890e-04 - accuracy: 0.2800\n",
      "Epoch 00342: val_loss did not improve from 0.00027\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 1.7920e-04 - accuracy: 0.2973 - val_loss: 3.7818e-04 - val_accuracy: 0.1667\n",
      "Epoch 343/400\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 2.4057e-04 - accuracy: 0.3500\n",
      "Epoch 00343: val_loss did not improve from 0.00027\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 2.2869e-04 - accuracy: 0.3243 - val_loss: 4.0966e-04 - val_accuracy: 0.1667\n",
      "Epoch 344/400\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 1.7321e-04 - accuracy: 0.3200\n",
      "Epoch 00344: val_loss did not improve from 0.00027\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 1.8256e-04 - accuracy: 0.3423 - val_loss: 6.9557e-04 - val_accuracy: 0.0833\n",
      "Epoch 345/400\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 2.4762e-04 - accuracy: 0.3500\n",
      "Epoch 00345: val_loss did not improve from 0.00027\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 2.4121e-04 - accuracy: 0.3243 - val_loss: 3.5376e-04 - val_accuracy: 0.0833\n",
      "Epoch 346/400\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 2.3437e-04 - accuracy: 0.3400\n",
      "Epoch 00346: val_loss did not improve from 0.00027\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 2.2625e-04 - accuracy: 0.3514 - val_loss: 4.2126e-04 - val_accuracy: 0.1667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 347/400\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 2.3506e-04 - accuracy: 0.2600\n",
      "Epoch 00347: val_loss did not improve from 0.00027\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 2.3946e-04 - accuracy: 0.2613 - val_loss: 4.1175e-04 - val_accuracy: 0.2500\n",
      "Epoch 348/400\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 1.9184e-04 - accuracy: 0.3900\n",
      "Epoch 00348: val_loss did not improve from 0.00027\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 1.8892e-04 - accuracy: 0.3874 - val_loss: 3.0055e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 349/400\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 2.1435e-04 - accuracy: 0.2600\n",
      "Epoch 00349: val_loss did not improve from 0.00027\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 2.1217e-04 - accuracy: 0.2613 - val_loss: 4.1951e-04 - val_accuracy: 0.0833\n",
      "Epoch 350/400\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 1.7667e-04 - accuracy: 0.3500\n",
      "Epoch 00350: val_loss did not improve from 0.00027\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 1.7666e-04 - accuracy: 0.3423 - val_loss: 3.4884e-04 - val_accuracy: 0.3333\n",
      "Epoch 351/400\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 2.0037e-04 - accuracy: 0.3700\n",
      "Epoch 00351: val_loss did not improve from 0.00027\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 1.9093e-04 - accuracy: 0.3604 - val_loss: 3.1533e-04 - val_accuracy: 0.0833\n",
      "Epoch 352/400\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 2.8288e-04 - accuracy: 0.3400\n",
      "Epoch 00352: val_loss did not improve from 0.00027\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 2.8071e-04 - accuracy: 0.3694 - val_loss: 4.0526e-04 - val_accuracy: 0.1667\n",
      "Epoch 353/400\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 1.8321e-04 - accuracy: 0.3700\n",
      "Epoch 00353: val_loss did not improve from 0.00027\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 1.7906e-04 - accuracy: 0.3333 - val_loss: 3.6344e-04 - val_accuracy: 0.0833\n",
      "Epoch 354/400\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 1.8931e-04 - accuracy: 0.2800\n",
      "Epoch 00354: val_loss did not improve from 0.00027\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 1.8424e-04 - accuracy: 0.2703 - val_loss: 3.6876e-04 - val_accuracy: 0.1667\n",
      "Epoch 355/400\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 1.7355e-04 - accuracy: 0.3200\n",
      "Epoch 00355: val_loss did not improve from 0.00027\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 1.8238e-04 - accuracy: 0.3063 - val_loss: 4.9061e-04 - val_accuracy: 0.0833\n",
      "Epoch 356/400\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 2.4359e-04 - accuracy: 0.3200\n",
      "Epoch 00356: val_loss did not improve from 0.00027\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 2.3556e-04 - accuracy: 0.3243 - val_loss: 3.1425e-04 - val_accuracy: 0.3333\n",
      "Epoch 357/400\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 1.7557e-04 - accuracy: 0.3200\n",
      "Epoch 00357: val_loss did not improve from 0.00027\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 1.7922e-04 - accuracy: 0.3153 - val_loss: 3.6391e-04 - val_accuracy: 0.1667\n",
      "Epoch 358/400\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 2.1145e-04 - accuracy: 0.2300\n",
      "Epoch 00358: val_loss did not improve from 0.00027\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 2.2026e-04 - accuracy: 0.2342 - val_loss: 4.2147e-04 - val_accuracy: 0.1667\n",
      "Epoch 359/400\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 2.3628e-04 - accuracy: 0.3400\n",
      "Epoch 00359: val_loss did not improve from 0.00027\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 2.2736e-04 - accuracy: 0.3604 - val_loss: 3.3879e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 360/400\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 1.9997e-04 - accuracy: 0.3700\n",
      "Epoch 00360: val_loss did not improve from 0.00027\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 2.1556e-04 - accuracy: 0.3423 - val_loss: 4.2581e-04 - val_accuracy: 0.2500\n",
      "Epoch 361/400\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 2.5469e-04 - accuracy: 0.2800\n",
      "Epoch 00361: val_loss did not improve from 0.00027\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 2.4066e-04 - accuracy: 0.2883 - val_loss: 3.5721e-04 - val_accuracy: 0.1667\n",
      "Epoch 362/400\n",
      "4/6 [===================>..........] - ETA: 0s - loss: 2.1832e-04 - accuracy: 0.3000\n",
      "Epoch 00362: val_loss did not improve from 0.00027\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 1.9668e-04 - accuracy: 0.2973 - val_loss: 3.8242e-04 - val_accuracy: 0.0833\n",
      "Epoch 363/400\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 2.0918e-04 - accuracy: 0.3200\n",
      "Epoch 00363: val_loss did not improve from 0.00027\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 2.1308e-04 - accuracy: 0.2973 - val_loss: 4.4714e-04 - val_accuracy: 0.1667\n",
      "Epoch 364/400\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 1.8765e-04 - accuracy: 0.2900\n",
      "Epoch 00364: val_loss did not improve from 0.00027\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 1.9644e-04 - accuracy: 0.2793 - val_loss: 3.7504e-04 - val_accuracy: 0.2500\n",
      "Epoch 365/400\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 2.5879e-04 - accuracy: 0.3300\n",
      "Epoch 00365: val_loss did not improve from 0.00027\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 2.4909e-04 - accuracy: 0.3333 - val_loss: 3.5839e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 366/400\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 1.9708e-04 - accuracy: 0.2700\n",
      "Epoch 00366: val_loss did not improve from 0.00027\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 1.9020e-04 - accuracy: 0.2703 - val_loss: 3.6040e-04 - val_accuracy: 0.2500\n",
      "Epoch 367/400\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 2.0146e-04 - accuracy: 0.3000\n",
      "Epoch 00367: val_loss did not improve from 0.00027\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 2.3398e-04 - accuracy: 0.2883 - val_loss: 5.1622e-04 - val_accuracy: 0.0833\n",
      "Epoch 368/400\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 2.0638e-04 - accuracy: 0.2600\n",
      "Epoch 00368: val_loss did not improve from 0.00027\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 2.0603e-04 - accuracy: 0.2703 - val_loss: 3.4517e-04 - val_accuracy: 0.0833\n",
      "Epoch 369/400\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 1.8413e-04 - accuracy: 0.3700\n",
      "Epoch 00369: val_loss did not improve from 0.00027\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 1.8207e-04 - accuracy: 0.3423 - val_loss: 4.0562e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 370/400\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 2.0914e-04 - accuracy: 0.2400\n",
      "Epoch 00370: val_loss did not improve from 0.00027\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 2.1677e-04 - accuracy: 0.2432 - val_loss: 4.5090e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 371/400\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 2.1972e-04 - accuracy: 0.2800\n",
      "Epoch 00371: val_loss did not improve from 0.00027\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 2.1437e-04 - accuracy: 0.2883 - val_loss: 3.4623e-04 - val_accuracy: 0.2500\n",
      "Epoch 372/400\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 1.9305e-04 - accuracy: 0.2900\n",
      "Epoch 00372: val_loss did not improve from 0.00027\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 1.9316e-04 - accuracy: 0.2883 - val_loss: 4.5788e-04 - val_accuracy: 0.0833\n",
      "Epoch 373/400\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 1.9245e-04 - accuracy: 0.3300\n",
      "Epoch 00373: val_loss did not improve from 0.00027\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 1.9365e-04 - accuracy: 0.3423 - val_loss: 4.7922e-04 - val_accuracy: 0.2500\n",
      "Epoch 374/400\n",
      "4/6 [===================>..........] - ETA: 0s - loss: 2.2194e-04 - accuracy: 0.3375\n",
      "Epoch 00374: val_loss did not improve from 0.00027\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 2.3253e-04 - accuracy: 0.3153 - val_loss: 3.3366e-04 - val_accuracy: 0.1667\n",
      "Epoch 375/400\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 1.8683e-04 - accuracy: 0.3000\n",
      "Epoch 00375: val_loss did not improve from 0.00027\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 1.8731e-04 - accuracy: 0.3063 - val_loss: 5.0987e-04 - val_accuracy: 0.0833\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 376/400\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 2.2401e-04 - accuracy: 0.3100\n",
      "Epoch 00376: val_loss did not improve from 0.00027\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 2.2028e-04 - accuracy: 0.3333 - val_loss: 3.3300e-04 - val_accuracy: 0.0833\n",
      "Epoch 377/400\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 1.9795e-04 - accuracy: 0.3300\n",
      "Epoch 00377: val_loss did not improve from 0.00027\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 1.9987e-04 - accuracy: 0.3063 - val_loss: 3.8912e-04 - val_accuracy: 0.2500\n",
      "Epoch 378/400\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 2.2122e-04 - accuracy: 0.3000\n",
      "Epoch 00378: val_loss did not improve from 0.00027\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 2.1358e-04 - accuracy: 0.3153 - val_loss: 3.8339e-04 - val_accuracy: 0.3333\n",
      "Epoch 379/400\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 1.9612e-04 - accuracy: 0.3000\n",
      "Epoch 00379: val_loss did not improve from 0.00027\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 1.9730e-04 - accuracy: 0.3063 - val_loss: 3.4390e-04 - val_accuracy: 0.1667\n",
      "Epoch 380/400\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 2.2208e-04 - accuracy: 0.3300\n",
      "Epoch 00380: val_loss did not improve from 0.00027\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 2.1591e-04 - accuracy: 0.3063 - val_loss: 4.2671e-04 - val_accuracy: 0.2500\n",
      "Epoch 381/400\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 2.0319e-04 - accuracy: 0.3700\n",
      "Epoch 00381: val_loss did not improve from 0.00027\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 2.0388e-04 - accuracy: 0.3784 - val_loss: 4.4296e-04 - val_accuracy: 0.1667\n",
      "Epoch 382/400\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 1.8430e-04 - accuracy: 0.2500\n",
      "Epoch 00382: val_loss did not improve from 0.00027\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 2.0108e-04 - accuracy: 0.2523 - val_loss: 4.8692e-04 - val_accuracy: 0.2500\n",
      "Epoch 383/400\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 2.1706e-04 - accuracy: 0.3200\n",
      "Epoch 00383: val_loss did not improve from 0.00027\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 2.0997e-04 - accuracy: 0.3243 - val_loss: 4.3913e-04 - val_accuracy: 0.1667\n",
      "Epoch 384/400\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 2.0224e-04 - accuracy: 0.3300\n",
      "Epoch 00384: val_loss did not improve from 0.00027\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 1.9079e-04 - accuracy: 0.3243 - val_loss: 3.4732e-04 - val_accuracy: 0.1667\n",
      "Epoch 385/400\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 2.0864e-04 - accuracy: 0.3400\n",
      "Epoch 00385: val_loss did not improve from 0.00027\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 1.9598e-04 - accuracy: 0.3423 - val_loss: 3.7076e-04 - val_accuracy: 0.0833\n",
      "Epoch 386/400\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 2.3509e-04 - accuracy: 0.2300\n",
      "Epoch 00386: val_loss did not improve from 0.00027\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 2.2664e-04 - accuracy: 0.2252 - val_loss: 3.5362e-04 - val_accuracy: 0.1667\n",
      "Epoch 387/400\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 1.8289e-04 - accuracy: 0.2900\n",
      "Epoch 00387: val_loss did not improve from 0.00027\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 1.8070e-04 - accuracy: 0.2703 - val_loss: 4.8315e-04 - val_accuracy: 0.1667\n",
      "Epoch 388/400\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 2.2384e-04 - accuracy: 0.2500\n",
      "Epoch 00388: val_loss did not improve from 0.00027\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 2.2696e-04 - accuracy: 0.2523 - val_loss: 4.5212e-04 - val_accuracy: 0.1667\n",
      "Epoch 389/400\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 2.1132e-04 - accuracy: 0.3500\n",
      "Epoch 00389: val_loss did not improve from 0.00027\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 1.9835e-04 - accuracy: 0.3604 - val_loss: 3.4866e-04 - val_accuracy: 0.3333\n",
      "Epoch 390/400\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 1.8951e-04 - accuracy: 0.2800\n",
      "Epoch 00390: val_loss did not improve from 0.00027\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 1.9740e-04 - accuracy: 0.3063 - val_loss: 4.4518e-04 - val_accuracy: 0.2500\n",
      "Epoch 391/400\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 1.7211e-04 - accuracy: 0.2300\n",
      "Epoch 00391: val_loss did not improve from 0.00027\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 1.9584e-04 - accuracy: 0.2252 - val_loss: 4.9383e-04 - val_accuracy: 0.2500\n",
      "Epoch 392/400\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 2.1638e-04 - accuracy: 0.3300\n",
      "Epoch 00392: val_loss did not improve from 0.00027\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 2.0855e-04 - accuracy: 0.3153 - val_loss: 4.4316e-04 - val_accuracy: 0.1667\n",
      "Epoch 393/400\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 2.2789e-04 - accuracy: 0.4000\n",
      "Epoch 00393: val_loss did not improve from 0.00027\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 2.2016e-04 - accuracy: 0.3784 - val_loss: 3.0554e-04 - val_accuracy: 0.1667\n",
      "Epoch 394/400\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 1.9757e-04 - accuracy: 0.2700\n",
      "Epoch 00394: val_loss did not improve from 0.00027\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 1.9174e-04 - accuracy: 0.2703 - val_loss: 4.1820e-04 - val_accuracy: 0.1667\n",
      "Epoch 395/400\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 1.9246e-04 - accuracy: 0.3500\n",
      "Epoch 00395: val_loss did not improve from 0.00027\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 2.0064e-04 - accuracy: 0.3604 - val_loss: 5.4558e-04 - val_accuracy: 0.3333\n",
      "Epoch 396/400\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 1.6372e-04 - accuracy: 0.2900\n",
      "Epoch 00396: val_loss did not improve from 0.00027\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 1.8552e-04 - accuracy: 0.2973 - val_loss: 5.7669e-04 - val_accuracy: 0.3333\n",
      "Epoch 397/400\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 2.1060e-04 - accuracy: 0.3000\n",
      "Epoch 00397: val_loss did not improve from 0.00027\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 2.0219e-04 - accuracy: 0.3243 - val_loss: 3.4589e-04 - val_accuracy: 0.4167\n",
      "Epoch 398/400\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 2.3226e-04 - accuracy: 0.3400\n",
      "Epoch 00398: val_loss did not improve from 0.00027\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 2.1536e-04 - accuracy: 0.3333 - val_loss: 4.0213e-04 - val_accuracy: 0.2500\n",
      "Epoch 399/400\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 2.0410e-04 - accuracy: 0.2800\n",
      "Epoch 00399: val_loss did not improve from 0.00027\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 2.1593e-04 - accuracy: 0.3153 - val_loss: 4.2833e-04 - val_accuracy: 0.0833\n",
      "Epoch 400/400\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 1.7339e-04 - accuracy: 0.3300\n",
      "Epoch 00400: val_loss did not improve from 0.00027\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 1.9437e-04 - accuracy: 0.3153 - val_loss: 3.9746e-04 - val_accuracy: 0.1667\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x19c595e44c0>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, validation_data=(x_valid, y_valid), batch_size=20, epochs=400, \n",
    "          callbacks=[checkpoint])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 모델 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 998us/step - loss: 3.6344e-04 - accuracy: 0.0000e+00\n"
     ]
    }
   ],
   "source": [
    "scores = model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.00036344019463285804, 0.0]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores # loss 와 metrics 를 담고있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.0004, accuracy: 0.00%\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = scores\n",
    "print(f'loss: {loss:.4f}, accuracy: {accuracy*100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(x_test)\n",
    "\n",
    "# pred / y_test -> 2차원 이되, 일렬 데이터로 변경..\n",
    "pred = pred.reshape(-1, 1)\n",
    "y_test_ = y_test.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x720 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(facecolor='white', figsize=(20, 10))\n",
    "ax = fig.add_subplot(111)\n",
    "ax.plot(y_test_, label='True')\n",
    "ax.plot(pred, label='Prediction')\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 100 -> 5 Val loss = 0.0007 Epoch = 300 accuracy = 70%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.1787484 ]\n",
      " [0.17457569]\n",
      " [0.17246799]\n",
      " [0.17790619]\n",
      " [0.17510667]\n",
      " [0.18613231]\n",
      " [0.18479025]\n",
      " [0.18252158]\n",
      " [0.18661103]\n",
      " [0.18224074]]\n"
     ]
    }
   ],
   "source": [
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[55005.996]\n",
      " [54590.914]\n",
      " [54381.254]\n",
      " [54922.22 ]\n",
      " [54643.734]\n",
      " [55740.51 ]\n",
      " [55607.008]\n",
      " [55381.336]\n",
      " [55788.133]\n",
      " [55353.4  ]]\n"
     ]
    }
   ],
   "source": [
    "counter_normalize = (pred * (max_price + min_price)) + min_price\n",
    "print(counter_normalize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openpyxl in c:\\users\\mosan\\anaconda3\\envs\\ottflab\\lib\\site-packages (3.0.5)\n",
      "Requirement already satisfied: et-xmlfile in c:\\users\\mosan\\anaconda3\\envs\\ottflab\\lib\\site-packages (from openpyxl) (1.0.1)\n",
      "Requirement already satisfied: jdcal in c:\\users\\mosan\\anaconda3\\envs\\ottflab\\lib\\site-packages (from openpyxl) (1.4.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55005.996\n",
      "54590.914\n",
      "54381.254\n",
      "54922.22\n",
      "54643.734\n",
      "55740.51\n",
      "55607.008\n",
      "55381.336\n",
      "55788.133\n",
      "55353.4\n"
     ]
    }
   ],
   "source": [
    "for data in counter_normalize:\n",
    "    print(data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openpyxl import Workbook\n",
    "\n",
    "wb = Workbook()\n",
    "ws1 = wb.active\n",
    "ws1.title = \"lstm_predicted_data\"\n",
    "ws1.append([\"예측 가격\"])\n",
    "\n",
    "for data in counter_normalize:\n",
    "    ws1.append([data[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "wb.save(filename='articles.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index in range(2):\n",
    "    print(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
