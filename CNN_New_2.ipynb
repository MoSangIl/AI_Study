{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#Parameter 정리\n",
    "\n",
    "RP 알고리즘을 구현함에 있어서 직접적으로 사용되는 Parameter : dpi = 96, width, height = 28, 28\n",
    "pyts.images.fit_transform 내부에서 사용되고 있는 Parameter : (self, X, y = None, **fit_params)\n",
    "\n",
    "*input parameter*\n",
    "1. X : Training Set. [n_samples, n_features] 크기의 numpy array\n",
    "2. y : Target Value. [n_samples] 크기의 numpy array\n",
    "3. **fit_params : Additional fit parameters, dict의 형태\n",
    "\n",
    "*return parameter*\n",
    "X_new : Transformed된 배열, [n_samples, n_features] 크기의 numpy array\n",
    "\n",
    "RP 알고리즘 자체의 전체적인 Parameter\n",
    "1. Dimension : 궤적의 차원, int, float(default값은 1) 형태로 적용, float인 경우, 각 time-series 크기의 확률, 0~1 사이의 값으로 도출되어야 함\n",
    "2. Time-Delay : 궤적의 두 연속 지점 사이의 시간 간격, int, float(default값은 1) 형태로 적용, float인 경우, 각 time-series 크기의 확률, 0~1 사이의 값으로 도출되어야 함\n",
    "3. Threshold : 최소 거리의 임계값, float, 'point', 'distance' or None(default값은 None) 형태로 적용, None인 경우, RP 이미지는 binarize되지 않음, Point의 경우, 'Point'의 확률이 임계값보다 작았을 때의 임계값 계산, 'Distance'의 경우, 임계값은 최대 거리의 확률임\n",
    "4. Percentage : int, float(default값은 10)으로 적용, 임계값이 Point인 경우, 검은 색 점의 확률이며, 임계값이 Distance인 경우, 임계값에 대한 최대거리의 확률, 임계값이 None 또는 float값인 경우 무시됨\n",
    "5. Flatten : bool(default값은 false)로 적용, True로 적용된 경우, 이미지가 1차원으로 늘려짐"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "tf.keras.layers.Conv2D(\n",
    "    filters, kernel_size, strides=(1, 1), padding='valid',\n",
    "    data_format=None, dilation_rate=(1, 1), groups=1, activation=None,\n",
    "    use_bias=True, kernel_initializer='glorot_uniform',\n",
    "    bias_initializer='zeros', kernel_regularizer=None,\n",
    "    bias_regularizer=None, activity_regularizer=None, kernel_constraint=None,\n",
    "    bias_constraint=None, **kwargs\n",
    "\n",
    "filters : filter의 개수\n",
    "kernel_size : 2D Convolution Window의 높이*넓이\n",
    "strides : stride의 높이*넓이\n",
    "padding = padding 기능 사용 여부\n",
    "data_format : (batch_size, height, width, channel), (batch_size, channel, height, width) 둘 중 어떤 데이터 차원 형식을 사용할 건지의 여부\n",
    "dilation_rate : 얼마나 Convoluition을 확장할 지에 대한 비율\n",
    "groups : 채널축에 따라 분할되는 그룹 수를 지정하는 역할\n",
    "activation : 사용할 활성화 함수 종류\n",
    "use_bias : 해당 층이 bias 벡터를 사용할 지에 대한 여부\n",
    "kernel_initializer : kernel 가중치 행렬을 초기화하는 기능에 대한 종류\n",
    "bias_initializer : bias 벡터를 초기화하는 기능에 대한 종류\n",
    "kernel_regularizer : kernel 가중치 행렬을 정규화하는 데 적용하는 함수 종류\n",
    "bias_regularizer : bias 벡터를 정규화하는 데 적용하는 함수 종류\n",
    "activity_regularizer : 해당 층의 출력 결과에 적용하는 정규화 함수 종류\n",
    "kernel_constraint : kernel 행렬에 적용하는 제약 함수 종류\n",
    "bias_constraint : bias 벡터에 적용하는 제약 함수 종류"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "tf.keras.layers.MaxPool2D(\n",
    "    pool_size=(2, 2), strides=None, padding='valid', data_format=None,\n",
    "    **kwargs\n",
    ")\n",
    "\n",
    "pool_size : 각 숫자에 대한 최대값을 얻을 수 있는 창의 크기\n",
    "strides : 각 풀링 단계에서 풀링 창의 이동거리\n",
    "padding : padding 기능 사용 여부\n",
    "data_format : (batch_size, height, width, channel), (batch_size, channel, height, width) 둘 중 어떤 데이터 차원 형식을 사용할 건지의 여부"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "tf.keras.layers.UpSampling2D(\n",
    "    size=(2, 2), data_format=None, interpolation='nearest', **kwargs\n",
    ")\n",
    "\n",
    "size : Upsampling 해야할 부분의 행과 열의 크기\n",
    "data_format : (batch_size, height, width, channel), (batch_size, channel, height, width) 둘 중 어떤 데이터 차원 형식을 사용할 건지의 여부\n",
    "interpolation : 가장 가까운 것 중 하나"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "tf.keras.optimizers.Adam(\n",
    "    learning_rate=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-07, amsgrad=False,\n",
    "    name='Adam', **kwargs\n",
    ")\n",
    "\n",
    "learning_rate : 학습 진행 비율\n",
    "beta_1 : 첫 번째 모멘트 추정치의 지수 붕괴율\n",
    "beta_2 : 두 번째 모멘트 추정치의 지수 붕괴율\n",
    "epsilon : 수치 안정성을 위한 작은 상수\n",
    "amsgrad : 이 알고리즘의 AMSGrad 변형을 적용할지 여부\n",
    "name : 기울기 적용 시 생성된 연산의 선택적 이름"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "fit(\n",
    "    x=None, y=None, batch_size=None, epochs=1, verbose=1, callbacks=None,\n",
    "    validation_split=0.0, validation_data=None, shuffle=True, class_weight=None,\n",
    "    sample_weight=None, initial_epoch=0, steps_per_epoch=None,\n",
    "    validation_steps=None, validation_batch_size=None, validation_freq=1,\n",
    "    max_queue_size=10, workers=1, use_multiprocessing=False\n",
    ")\n",
    "\n",
    "compile(\n",
    "    optimizer='rmsprop', loss=None, metrics=None, loss_weights=None,\n",
    "    weighted_metrics=None, run_eagerly=None, steps_per_execution=None, **kwargs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          chip    wire parameter  segment     value\n",
      "0        CHIP1  WIRE10     CLAMP        1  2.236858\n",
      "1        CHIP1  WIRE10     CLAMP        1  1.909297\n",
      "2        CHIP1  WIRE10     CLAMP        1  1.554571\n",
      "3        CHIP1  WIRE10     CLAMP        1  1.205214\n",
      "4        CHIP1  WIRE10     CLAMP        1  1.132879\n",
      "...        ...     ...       ...      ...       ...\n",
      "480063  CHIP10   WIRE9     CLAMP        6  2.349941\n",
      "480064  CHIP10   WIRE9     CLAMP        6  2.346782\n",
      "480065  CHIP10   WIRE9     CLAMP        6  2.347098\n",
      "480066  CHIP10   WIRE9     CLAMP        6  2.366051\n",
      "480067  CHIP10   WIRE9     CLAMP        6  2.546415\n",
      "\n",
      "[480068 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def readFile(filepath):\n",
    "    finalData = {}\n",
    "    data = pd.read_csv(filepath)\n",
    "    print(data)\n",
    "    uniqueChip = data['chip'].unique()\n",
    "    uniqueWire = data['wire'].unique()\n",
    "    uniquePar = data['parameter'].unique()\n",
    "    uniqueSeg = data['segment'].unique()\n",
    "\n",
    "    for chip in uniqueChip:\n",
    "        for wire in uniqueWire:\n",
    "            for par in uniquePar:\n",
    "                for seg in uniqueSeg:\n",
    "                    chipFilter = data.loc[data[\"chip\"] == chip]\n",
    "                    wireFilter = chipFilter.loc[data[\"wire\"] == wire]\n",
    "                    parFilter = wireFilter.loc[data[\"parameter\"] == par]\n",
    "                    segFilter = parFilter.loc[data[\"segment\"] == seg, \"value\"]\n",
    "                    result = segFilter.to_numpy()\n",
    "                    result = np.reshape(result,(1,len(result)))\n",
    "                    label = chip + \"_\" + wire + \"_\" + par +\"_\" +str(seg)\n",
    "                    finalData[label] = result\n",
    "    return finalData\n",
    "    \n",
    "#AXISX_data = readFile(\"resources/AXISX_resample.csv\")\n",
    "CLAMP_data = readFile(\"resources/CLAMP_resample.csv\")\n",
    "# AXISX_data CLAMP_data 합치기?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\이원빈\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\pandas\\plotting\\_matplotlib\\core.py:337: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  fig = self.plt.figure(figsize=self.figsize)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "CLAMP1_list = []\n",
    "CLAMP2_list = []\n",
    "CLAMP3_list = []\n",
    "CLAMP4_list = []\n",
    "CLAMP5_list = []\n",
    "CLAMP6_list = []\n",
    "\n",
    "PATH = \"resources/images/\"\n",
    "plt.rcParams[\"figure.figsize\"] = (1.333333333348571,1.333333333348571)\n",
    "\n",
    "for key, values in CLAMP_data.items():\n",
    "    classDir = key.split(\"_\")[2] + key.split(\"_\")[3] + \"/\"\n",
    "    \n",
    "    try:\n",
    "        if not os.path.exists(PATH + classDir):\n",
    "            os.makedirs(PATH + classDir)\n",
    "    except OSError:\n",
    "        print ('Error: Creating directory. ' +  PATH + classDir)\n",
    "\n",
    "    if '_CLAMP_1' in key:\n",
    "        CLAMP1_list.append(values)\n",
    "        for i in range(len(CLAMP1_list)):\n",
    "            CLAMP1_list_DF = pd.DataFrame(CLAMP1_list[i][0])\n",
    "            CLAMP1_list_DF.plot(color = \"#ff0000\")\n",
    "            plt.plot(CLAMP1_list_DF, marker = '*', color = 'r')\n",
    "            filename = PATH + classDir + key + '.png'\n",
    "            plt.savefig(filename)\n",
    "    if '_CLAMP_2' in key:\n",
    "        CLAMP2_list.append(values)\n",
    "        for i in range(len(CLAMP2_list)):\n",
    "            CLAMP2_list_DF = pd.DataFrame(CLAMP2_list[i][0])\n",
    "            CLAMP2_list_DF.plot(color = \"#ff0000\")\n",
    "            plt.plot(CLAMP2_list_DF, marker = '*', color = 'r')\n",
    "            filename = PATH + classDir + key + '.png'\n",
    "            plt.savefig(filename)\n",
    "    if '_CLAMP_3' in key:\n",
    "        CLAMP3_list.append(values)\n",
    "        for i in range(len(CLAMP3_list)):\n",
    "            CLAMP3_list_DF = pd.DataFrame(CLAMP3_list[i][0])\n",
    "            CLAMP3_list_DF.plot(color = \"#ff0000\")\n",
    "            plt.plot(CLAMP3_list_DF, marker = '*', color = 'r')\n",
    "            filename = PATH + classDir + key + '.png'\n",
    "            plt.savefig(filename)\n",
    "    if '_CLAMP_4' in key:\n",
    "        CLAMP4_list.append(values)\n",
    "        for i in range(len(CLAMP4_list)):\n",
    "            CLAMP4_list_DF = pd.DataFrame(CLAMP4_list[i][0])\n",
    "            CLAMP4_list_DF.plot(color = \"#ff0000\")\n",
    "            plt.plot(CLAMP4_list_DF, marker = '*', color = 'r')\n",
    "            filename = PATH + classDir + key + '.png'\n",
    "            plt.savefig(filename)\n",
    "    if '_CLAMP_5' in key:\n",
    "        CLAMP5_list.append(values)\n",
    "        for i in range(len(CLAMP5_list)):\n",
    "            CLAMP5_list_DF = pd.DataFrame(CLAMP5_list[i][0])\n",
    "            CLAMP5_list_DF.plot(color = \"#ff0000\")\n",
    "            plt.plot(CLAMP5_list_DF, marker = '*', color = 'r')\n",
    "            filename = PATH + classDir + key + '.png'\n",
    "            plt.savefig(filename)\n",
    "    if '_CLAMP_6' in key:\n",
    "        CLAMP6_list.append(values)\n",
    "        for i in range(len(CLAMP6_list)):\n",
    "            CLAMP6_list_DF = pd.DataFrame(CLAMP6_list[i][0])\n",
    "            CLAMP6_list_DF.plot(color = \"#ff0000\")\n",
    "            plt.plot(CLAMP6_list_DF, marker = '*', color = 'r')\n",
    "            filename = PATH + classDir + key + '.png'\n",
    "            plt.savefig(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, re, glob\n",
    "import cv2\n",
    "import numpy as np\n",
    "#from keras.preprocessing import image\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "groups_folder_path = './resources/images/'\n",
    "categories = [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\"]\n",
    "num_classes = len(categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "Y = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['CLAMP1', 'CLAMP2', 'CLAMP3', 'CLAMP4', 'CLAMP5', 'CLAMP6']\n",
      "CLAMP1\n",
      "./resources/images/CLAMP1/CHIP10_WIRE10_CLAMP_1.png\n",
      "./resources/images/CLAMP1/CHIP10_WIRE11_CLAMP_1.png\n",
      "./resources/images/CLAMP1/CHIP1_WIRE10_CLAMP_1.png\n",
      "./resources/images/CLAMP1/CHIP1_WIRE11_CLAMP_1.png\n",
      "./resources/images/CLAMP1/CHIP1_WIRE12_CLAMP_1.png\n",
      "./resources/images/CLAMP1/CHIP1_WIRE13_CLAMP_1.png\n",
      "./resources/images/CLAMP1/CHIP1_WIRE14_CLAMP_1.png\n",
      "./resources/images/CLAMP1/CHIP1_WIRE15_CLAMP_1.png\n",
      "./resources/images/CLAMP1/CHIP1_WIRE16_CLAMP_1.png\n",
      "./resources/images/CLAMP1/CHIP1_WIRE17_CLAMP_1.png\n",
      "./resources/images/CLAMP1/CHIP1_WIRE18_CLAMP_1.png\n",
      "./resources/images/CLAMP1/CHIP1_WIRE19_CLAMP_1.png\n",
      "./resources/images/CLAMP1/CHIP1_WIRE1_CLAMP_1.png\n",
      "./resources/images/CLAMP1/CHIP1_WIRE2_CLAMP_1.png\n",
      "./resources/images/CLAMP1/CHIP1_WIRE3_CLAMP_1.png\n",
      "./resources/images/CLAMP1/CHIP1_WIRE4_CLAMP_1.png\n",
      "./resources/images/CLAMP1/CHIP1_WIRE5_CLAMP_1.png\n",
      "./resources/images/CLAMP1/CHIP1_WIRE6_CLAMP_1.png\n",
      "./resources/images/CLAMP1/CHIP1_WIRE7_CLAMP_1.png\n",
      "./resources/images/CLAMP1/CHIP1_WIRE8_CLAMP_1.png\n",
      "./resources/images/CLAMP1/CHIP1_WIRE9_CLAMP_1.png\n",
      "./resources/images/CLAMP1/CHIP2_WIRE10_CLAMP_1.png\n",
      "./resources/images/CLAMP1/CHIP2_WIRE11_CLAMP_1.png\n",
      "./resources/images/CLAMP1/CHIP2_WIRE12_CLAMP_1.png\n",
      "./resources/images/CLAMP1/CHIP2_WIRE13_CLAMP_1.png\n",
      "./resources/images/CLAMP1/CHIP2_WIRE14_CLAMP_1.png\n",
      "./resources/images/CLAMP1/CHIP2_WIRE15_CLAMP_1.png\n",
      "./resources/images/CLAMP1/CHIP2_WIRE16_CLAMP_1.png\n",
      "./resources/images/CLAMP1/CHIP2_WIRE17_CLAMP_1.png\n",
      "./resources/images/CLAMP1/CHIP2_WIRE18_CLAMP_1.png\n",
      "./resources/images/CLAMP1/CHIP2_WIRE19_CLAMP_1.png\n",
      "./resources/images/CLAMP1/CHIP2_WIRE1_CLAMP_1.png\n",
      "./resources/images/CLAMP1/CHIP2_WIRE2_CLAMP_1.png\n",
      "./resources/images/CLAMP1/CHIP2_WIRE3_CLAMP_1.png\n",
      "./resources/images/CLAMP1/CHIP2_WIRE4_CLAMP_1.png\n",
      "./resources/images/CLAMP1/CHIP2_WIRE5_CLAMP_1.png\n",
      "./resources/images/CLAMP1/CHIP2_WIRE6_CLAMP_1.png\n",
      "./resources/images/CLAMP1/CHIP2_WIRE7_CLAMP_1.png\n",
      "./resources/images/CLAMP1/CHIP2_WIRE8_CLAMP_1.png\n",
      "./resources/images/CLAMP1/CHIP2_WIRE9_CLAMP_1.png\n",
      "./resources/images/CLAMP1/CHIP3_WIRE10_CLAMP_1.png\n",
      "./resources/images/CLAMP1/CHIP3_WIRE11_CLAMP_1.png\n",
      "./resources/images/CLAMP1/CHIP3_WIRE12_CLAMP_1.png\n",
      "./resources/images/CLAMP1/CHIP3_WIRE13_CLAMP_1.png\n",
      "./resources/images/CLAMP1/CHIP3_WIRE14_CLAMP_1.png\n",
      "./resources/images/CLAMP1/CHIP3_WIRE15_CLAMP_1.png\n",
      "./resources/images/CLAMP1/CHIP3_WIRE16_CLAMP_1.png\n",
      "./resources/images/CLAMP1/CHIP3_WIRE17_CLAMP_1.png\n",
      "./resources/images/CLAMP1/CHIP3_WIRE18_CLAMP_1.png\n",
      "./resources/images/CLAMP1/CHIP3_WIRE19_CLAMP_1.png\n",
      "./resources/images/CLAMP1/CHIP3_WIRE1_CLAMP_1.png\n",
      "./resources/images/CLAMP1/CHIP3_WIRE2_CLAMP_1.png\n",
      "./resources/images/CLAMP1/CHIP3_WIRE3_CLAMP_1.png\n",
      "./resources/images/CLAMP1/CHIP3_WIRE4_CLAMP_1.png\n",
      "./resources/images/CLAMP1/CHIP3_WIRE5_CLAMP_1.png\n",
      "./resources/images/CLAMP1/CHIP3_WIRE6_CLAMP_1.png\n",
      "./resources/images/CLAMP1/CHIP3_WIRE7_CLAMP_1.png\n",
      "./resources/images/CLAMP1/CHIP3_WIRE8_CLAMP_1.png\n",
      "./resources/images/CLAMP1/CHIP3_WIRE9_CLAMP_1.png\n",
      "./resources/images/CLAMP1/CHIP4_WIRE10_CLAMP_1.png\n",
      "./resources/images/CLAMP1/CHIP4_WIRE11_CLAMP_1.png\n",
      "./resources/images/CLAMP1/CHIP4_WIRE12_CLAMP_1.png\n",
      "./resources/images/CLAMP1/CHIP4_WIRE13_CLAMP_1.png\n",
      "./resources/images/CLAMP1/CHIP4_WIRE14_CLAMP_1.png\n",
      "./resources/images/CLAMP1/CHIP4_WIRE15_CLAMP_1.png\n",
      "./resources/images/CLAMP1/CHIP4_WIRE16_CLAMP_1.png\n",
      "./resources/images/CLAMP1/CHIP4_WIRE17_CLAMP_1.png\n",
      "./resources/images/CLAMP1/CHIP4_WIRE18_CLAMP_1.png\n",
      "./resources/images/CLAMP1/CHIP4_WIRE19_CLAMP_1.png\n",
      "./resources/images/CLAMP1/CHIP4_WIRE1_CLAMP_1.png\n",
      "./resources/images/CLAMP1/CHIP4_WIRE2_CLAMP_1.png\n",
      "./resources/images/CLAMP1/CHIP4_WIRE3_CLAMP_1.png\n",
      "./resources/images/CLAMP1/CHIP4_WIRE4_CLAMP_1.png\n",
      "./resources/images/CLAMP1/CHIP4_WIRE5_CLAMP_1.png\n",
      "./resources/images/CLAMP1/CHIP4_WIRE6_CLAMP_1.png\n",
      "./resources/images/CLAMP1/CHIP4_WIRE7_CLAMP_1.png\n",
      "./resources/images/CLAMP1/CHIP4_WIRE8_CLAMP_1.png\n",
      "./resources/images/CLAMP1/CHIP4_WIRE9_CLAMP_1.png\n",
      "./resources/images/CLAMP1/CHIP5_WIRE10_CLAMP_1.png\n",
      "./resources/images/CLAMP1/CHIP5_WIRE11_CLAMP_1.png\n",
      "./resources/images/CLAMP1/CHIP5_WIRE12_CLAMP_1.png\n",
      "./resources/images/CLAMP1/CHIP5_WIRE13_CLAMP_1.png\n",
      "./resources/images/CLAMP1/CHIP5_WIRE14_CLAMP_1.png\n",
      "./resources/images/CLAMP1/CHIP5_WIRE15_CLAMP_1.png\n",
      "./resources/images/CLAMP1/CHIP5_WIRE16_CLAMP_1.png\n",
      "./resources/images/CLAMP1/CHIP5_WIRE17_CLAMP_1.png\n",
      "./resources/images/CLAMP1/CHIP5_WIRE18_CLAMP_1.png\n",
      "./resources/images/CLAMP1/CHIP5_WIRE19_CLAMP_1.png\n",
      "./resources/images/CLAMP1/CHIP5_WIRE1_CLAMP_1.png\n",
      "./resources/images/CLAMP1/CHIP5_WIRE2_CLAMP_1.png\n",
      "./resources/images/CLAMP1/CHIP5_WIRE3_CLAMP_1.png\n",
      "./resources/images/CLAMP1/CHIP5_WIRE4_CLAMP_1.png\n",
      "./resources/images/CLAMP1/CHIP5_WIRE5_CLAMP_1.png\n",
      "./resources/images/CLAMP1/CHIP5_WIRE6_CLAMP_1.png\n",
      "./resources/images/CLAMP1/CHIP5_WIRE7_CLAMP_1.png\n",
      "./resources/images/CLAMP1/CHIP5_WIRE8_CLAMP_1.png\n",
      "./resources/images/CLAMP1/CHIP5_WIRE9_CLAMP_1.png\n",
      "./resources/images/CLAMP1/CHIP6_WIRE10_CLAMP_1.png\n",
      "./resources/images/CLAMP1/CHIP6_WIRE11_CLAMP_1.png\n",
      "./resources/images/CLAMP1/CHIP6_WIRE12_CLAMP_1.png\n",
      "./resources/images/CLAMP1/CHIP6_WIRE13_CLAMP_1.png\n",
      "./resources/images/CLAMP1/CHIP6_WIRE14_CLAMP_1.png\n",
      "./resources/images/CLAMP1/CHIP6_WIRE15_CLAMP_1.png\n",
      "./resources/images/CLAMP1/CHIP6_WIRE16_CLAMP_1.png\n",
      "./resources/images/CLAMP1/CHIP6_WIRE17_CLAMP_1.png\n",
      "./resources/images/CLAMP1/CHIP6_WIRE18_CLAMP_1.png\n",
      "./resources/images/CLAMP1/CHIP6_WIRE19_CLAMP_1.png\n",
      "./resources/images/CLAMP1/CHIP6_WIRE1_CLAMP_1.png\n",
      "./resources/images/CLAMP1/CHIP6_WIRE2_CLAMP_1.png\n",
      "./resources/images/CLAMP1/CHIP6_WIRE3_CLAMP_1.png\n",
      "./resources/images/CLAMP1/CHIP6_WIRE4_CLAMP_1.png\n",
      "./resources/images/CLAMP1/CHIP6_WIRE5_CLAMP_1.png\n",
      "./resources/images/CLAMP1/CHIP6_WIRE6_CLAMP_1.png\n",
      "./resources/images/CLAMP1/CHIP6_WIRE7_CLAMP_1.png\n",
      "./resources/images/CLAMP1/CHIP6_WIRE8_CLAMP_1.png\n",
      "./resources/images/CLAMP1/CHIP6_WIRE9_CLAMP_1.png\n",
      "./resources/images/CLAMP1/CHIP7_WIRE10_CLAMP_1.png\n",
      "./resources/images/CLAMP1/CHIP7_WIRE11_CLAMP_1.png\n",
      "./resources/images/CLAMP1/CHIP7_WIRE12_CLAMP_1.png\n",
      "./resources/images/CLAMP1/CHIP7_WIRE13_CLAMP_1.png\n",
      "./resources/images/CLAMP1/CHIP7_WIRE14_CLAMP_1.png\n",
      "./resources/images/CLAMP1/CHIP7_WIRE15_CLAMP_1.png\n",
      "./resources/images/CLAMP1/CHIP7_WIRE16_CLAMP_1.png\n",
      "./resources/images/CLAMP1/CHIP7_WIRE17_CLAMP_1.png\n",
      "./resources/images/CLAMP1/CHIP7_WIRE18_CLAMP_1.png\n",
      "./resources/images/CLAMP1/CHIP7_WIRE19_CLAMP_1.png\n",
      "./resources/images/CLAMP1/CHIP7_WIRE1_CLAMP_1.png\n",
      "./resources/images/CLAMP1/CHIP7_WIRE2_CLAMP_1.png\n",
      "./resources/images/CLAMP1/CHIP7_WIRE3_CLAMP_1.png\n",
      "./resources/images/CLAMP1/CHIP7_WIRE4_CLAMP_1.png\n",
      "./resources/images/CLAMP1/CHIP7_WIRE5_CLAMP_1.png\n",
      "./resources/images/CLAMP1/CHIP7_WIRE6_CLAMP_1.png\n",
      "./resources/images/CLAMP1/CHIP7_WIRE7_CLAMP_1.png\n",
      "./resources/images/CLAMP1/CHIP7_WIRE8_CLAMP_1.png\n",
      "./resources/images/CLAMP1/CHIP7_WIRE9_CLAMP_1.png\n",
      "./resources/images/CLAMP1/CHIP8_WIRE10_CLAMP_1.png\n",
      "./resources/images/CLAMP1/CHIP8_WIRE11_CLAMP_1.png\n",
      "./resources/images/CLAMP1/CHIP8_WIRE12_CLAMP_1.png\n",
      "./resources/images/CLAMP1/CHIP8_WIRE13_CLAMP_1.png\n",
      "./resources/images/CLAMP1/CHIP8_WIRE14_CLAMP_1.png\n",
      "./resources/images/CLAMP1/CHIP8_WIRE15_CLAMP_1.png\n",
      "./resources/images/CLAMP1/CHIP8_WIRE16_CLAMP_1.png\n",
      "./resources/images/CLAMP1/CHIP8_WIRE17_CLAMP_1.png\n",
      "./resources/images/CLAMP1/CHIP8_WIRE18_CLAMP_1.png\n",
      "./resources/images/CLAMP1/CHIP8_WIRE19_CLAMP_1.png\n",
      "./resources/images/CLAMP1/CHIP8_WIRE1_CLAMP_1.png\n",
      "./resources/images/CLAMP1/CHIP8_WIRE2_CLAMP_1.png\n",
      "./resources/images/CLAMP1/CHIP8_WIRE3_CLAMP_1.png\n",
      "./resources/images/CLAMP1/CHIP8_WIRE4_CLAMP_1.png\n",
      "./resources/images/CLAMP1/CHIP8_WIRE5_CLAMP_1.png\n",
      "./resources/images/CLAMP1/CHIP8_WIRE6_CLAMP_1.png\n",
      "./resources/images/CLAMP1/CHIP8_WIRE7_CLAMP_1.png\n",
      "./resources/images/CLAMP1/CHIP8_WIRE8_CLAMP_1.png\n",
      "./resources/images/CLAMP1/CHIP8_WIRE9_CLAMP_1.png\n",
      "./resources/images/CLAMP1/CHIP9_WIRE10_CLAMP_1.png\n",
      "./resources/images/CLAMP1/CHIP9_WIRE11_CLAMP_1.png\n",
      "./resources/images/CLAMP1/CHIP9_WIRE12_CLAMP_1.png\n",
      "./resources/images/CLAMP1/CHIP9_WIRE13_CLAMP_1.png\n",
      "./resources/images/CLAMP1/CHIP9_WIRE14_CLAMP_1.png\n",
      "./resources/images/CLAMP1/CHIP9_WIRE15_CLAMP_1.png\n",
      "./resources/images/CLAMP1/CHIP9_WIRE16_CLAMP_1.png\n",
      "./resources/images/CLAMP1/CHIP9_WIRE17_CLAMP_1.png\n",
      "./resources/images/CLAMP1/CHIP9_WIRE18_CLAMP_1.png\n",
      "./resources/images/CLAMP1/CHIP9_WIRE19_CLAMP_1.png\n",
      "./resources/images/CLAMP1/CHIP9_WIRE1_CLAMP_1.png\n",
      "./resources/images/CLAMP1/CHIP9_WIRE2_CLAMP_1.png\n",
      "./resources/images/CLAMP1/CHIP9_WIRE3_CLAMP_1.png\n",
      "./resources/images/CLAMP1/CHIP9_WIRE4_CLAMP_1.png\n",
      "./resources/images/CLAMP1/CHIP9_WIRE5_CLAMP_1.png\n",
      "./resources/images/CLAMP1/CHIP9_WIRE6_CLAMP_1.png\n",
      "./resources/images/CLAMP1/CHIP9_WIRE7_CLAMP_1.png\n",
      "./resources/images/CLAMP1/CHIP9_WIRE8_CLAMP_1.png\n",
      "./resources/images/CLAMP1/CHIP9_WIRE9_CLAMP_1.png\n",
      "./resources/images/CLAMP1\n",
      "CLAMP2\n",
      "./resources/images/CLAMP2/CHIP10_WIRE10_CLAMP_2.png\n",
      "./resources/images/CLAMP2/CHIP10_WIRE11_CLAMP_2.png\n",
      "./resources/images/CLAMP2/CHIP1_WIRE10_CLAMP_2.png\n",
      "./resources/images/CLAMP2/CHIP1_WIRE11_CLAMP_2.png\n",
      "./resources/images/CLAMP2/CHIP1_WIRE12_CLAMP_2.png\n",
      "./resources/images/CLAMP2/CHIP1_WIRE13_CLAMP_2.png\n",
      "./resources/images/CLAMP2/CHIP1_WIRE14_CLAMP_2.png\n",
      "./resources/images/CLAMP2/CHIP1_WIRE15_CLAMP_2.png\n",
      "./resources/images/CLAMP2/CHIP1_WIRE16_CLAMP_2.png\n",
      "./resources/images/CLAMP2/CHIP1_WIRE17_CLAMP_2.png\n",
      "./resources/images/CLAMP2/CHIP1_WIRE18_CLAMP_2.png\n",
      "./resources/images/CLAMP2/CHIP1_WIRE19_CLAMP_2.png\n",
      "./resources/images/CLAMP2/CHIP1_WIRE1_CLAMP_2.png\n",
      "./resources/images/CLAMP2/CHIP1_WIRE2_CLAMP_2.png\n",
      "./resources/images/CLAMP2/CHIP1_WIRE3_CLAMP_2.png\n",
      "./resources/images/CLAMP2/CHIP1_WIRE4_CLAMP_2.png\n",
      "./resources/images/CLAMP2/CHIP1_WIRE5_CLAMP_2.png\n",
      "./resources/images/CLAMP2/CHIP1_WIRE6_CLAMP_2.png\n",
      "./resources/images/CLAMP2/CHIP1_WIRE7_CLAMP_2.png\n",
      "./resources/images/CLAMP2/CHIP1_WIRE8_CLAMP_2.png\n",
      "./resources/images/CLAMP2/CHIP1_WIRE9_CLAMP_2.png\n",
      "./resources/images/CLAMP2/CHIP2_WIRE10_CLAMP_2.png\n",
      "./resources/images/CLAMP2/CHIP2_WIRE11_CLAMP_2.png\n",
      "./resources/images/CLAMP2/CHIP2_WIRE12_CLAMP_2.png\n",
      "./resources/images/CLAMP2/CHIP2_WIRE13_CLAMP_2.png\n",
      "./resources/images/CLAMP2/CHIP2_WIRE14_CLAMP_2.png\n",
      "./resources/images/CLAMP2/CHIP2_WIRE15_CLAMP_2.png\n",
      "./resources/images/CLAMP2/CHIP2_WIRE16_CLAMP_2.png\n",
      "./resources/images/CLAMP2/CHIP2_WIRE17_CLAMP_2.png\n",
      "./resources/images/CLAMP2/CHIP2_WIRE18_CLAMP_2.png\n",
      "./resources/images/CLAMP2/CHIP2_WIRE19_CLAMP_2.png\n",
      "./resources/images/CLAMP2/CHIP2_WIRE1_CLAMP_2.png\n",
      "./resources/images/CLAMP2/CHIP2_WIRE2_CLAMP_2.png\n",
      "./resources/images/CLAMP2/CHIP2_WIRE3_CLAMP_2.png\n",
      "./resources/images/CLAMP2/CHIP2_WIRE4_CLAMP_2.png\n",
      "./resources/images/CLAMP2/CHIP2_WIRE5_CLAMP_2.png\n",
      "./resources/images/CLAMP2/CHIP2_WIRE6_CLAMP_2.png\n",
      "./resources/images/CLAMP2/CHIP2_WIRE7_CLAMP_2.png\n",
      "./resources/images/CLAMP2/CHIP2_WIRE8_CLAMP_2.png\n",
      "./resources/images/CLAMP2/CHIP2_WIRE9_CLAMP_2.png\n",
      "./resources/images/CLAMP2/CHIP3_WIRE10_CLAMP_2.png\n",
      "./resources/images/CLAMP2/CHIP3_WIRE11_CLAMP_2.png\n",
      "./resources/images/CLAMP2/CHIP3_WIRE12_CLAMP_2.png\n",
      "./resources/images/CLAMP2/CHIP3_WIRE13_CLAMP_2.png\n",
      "./resources/images/CLAMP2/CHIP3_WIRE14_CLAMP_2.png\n",
      "./resources/images/CLAMP2/CHIP3_WIRE15_CLAMP_2.png\n",
      "./resources/images/CLAMP2/CHIP3_WIRE16_CLAMP_2.png\n",
      "./resources/images/CLAMP2/CHIP3_WIRE17_CLAMP_2.png\n",
      "./resources/images/CLAMP2/CHIP3_WIRE18_CLAMP_2.png\n",
      "./resources/images/CLAMP2/CHIP3_WIRE19_CLAMP_2.png\n",
      "./resources/images/CLAMP2/CHIP3_WIRE1_CLAMP_2.png\n",
      "./resources/images/CLAMP2/CHIP3_WIRE2_CLAMP_2.png\n",
      "./resources/images/CLAMP2/CHIP3_WIRE3_CLAMP_2.png\n",
      "./resources/images/CLAMP2/CHIP3_WIRE4_CLAMP_2.png\n",
      "./resources/images/CLAMP2/CHIP3_WIRE5_CLAMP_2.png\n",
      "./resources/images/CLAMP2/CHIP3_WIRE6_CLAMP_2.png\n",
      "./resources/images/CLAMP2/CHIP3_WIRE7_CLAMP_2.png\n",
      "./resources/images/CLAMP2/CHIP3_WIRE8_CLAMP_2.png\n",
      "./resources/images/CLAMP2/CHIP3_WIRE9_CLAMP_2.png\n",
      "./resources/images/CLAMP2/CHIP4_WIRE10_CLAMP_2.png\n",
      "./resources/images/CLAMP2/CHIP4_WIRE11_CLAMP_2.png\n",
      "./resources/images/CLAMP2/CHIP4_WIRE12_CLAMP_2.png\n",
      "./resources/images/CLAMP2/CHIP4_WIRE13_CLAMP_2.png\n",
      "./resources/images/CLAMP2/CHIP4_WIRE14_CLAMP_2.png\n",
      "./resources/images/CLAMP2/CHIP4_WIRE15_CLAMP_2.png\n",
      "./resources/images/CLAMP2/CHIP4_WIRE16_CLAMP_2.png\n",
      "./resources/images/CLAMP2/CHIP4_WIRE17_CLAMP_2.png\n",
      "./resources/images/CLAMP2/CHIP4_WIRE18_CLAMP_2.png\n",
      "./resources/images/CLAMP2/CHIP4_WIRE19_CLAMP_2.png\n",
      "./resources/images/CLAMP2/CHIP4_WIRE1_CLAMP_2.png\n",
      "./resources/images/CLAMP2/CHIP4_WIRE2_CLAMP_2.png\n",
      "./resources/images/CLAMP2/CHIP4_WIRE3_CLAMP_2.png\n",
      "./resources/images/CLAMP2/CHIP4_WIRE4_CLAMP_2.png\n",
      "./resources/images/CLAMP2/CHIP4_WIRE5_CLAMP_2.png\n",
      "./resources/images/CLAMP2/CHIP4_WIRE6_CLAMP_2.png\n",
      "./resources/images/CLAMP2/CHIP4_WIRE7_CLAMP_2.png\n",
      "./resources/images/CLAMP2/CHIP4_WIRE8_CLAMP_2.png\n",
      "./resources/images/CLAMP2/CHIP4_WIRE9_CLAMP_2.png\n",
      "./resources/images/CLAMP2/CHIP5_WIRE10_CLAMP_2.png\n",
      "./resources/images/CLAMP2/CHIP5_WIRE11_CLAMP_2.png\n",
      "./resources/images/CLAMP2/CHIP5_WIRE12_CLAMP_2.png\n",
      "./resources/images/CLAMP2/CHIP5_WIRE13_CLAMP_2.png\n",
      "./resources/images/CLAMP2/CHIP5_WIRE14_CLAMP_2.png\n",
      "./resources/images/CLAMP2/CHIP5_WIRE15_CLAMP_2.png\n",
      "./resources/images/CLAMP2/CHIP5_WIRE16_CLAMP_2.png\n",
      "./resources/images/CLAMP2/CHIP5_WIRE17_CLAMP_2.png\n",
      "./resources/images/CLAMP2/CHIP5_WIRE18_CLAMP_2.png\n",
      "./resources/images/CLAMP2/CHIP5_WIRE19_CLAMP_2.png\n",
      "./resources/images/CLAMP2/CHIP5_WIRE1_CLAMP_2.png\n",
      "./resources/images/CLAMP2/CHIP5_WIRE2_CLAMP_2.png\n",
      "./resources/images/CLAMP2/CHIP5_WIRE3_CLAMP_2.png\n",
      "./resources/images/CLAMP2/CHIP5_WIRE4_CLAMP_2.png\n",
      "./resources/images/CLAMP2/CHIP5_WIRE5_CLAMP_2.png\n",
      "./resources/images/CLAMP2/CHIP5_WIRE6_CLAMP_2.png\n",
      "./resources/images/CLAMP2/CHIP5_WIRE7_CLAMP_2.png\n",
      "./resources/images/CLAMP2/CHIP5_WIRE8_CLAMP_2.png\n",
      "./resources/images/CLAMP2/CHIP5_WIRE9_CLAMP_2.png\n",
      "./resources/images/CLAMP2/CHIP6_WIRE10_CLAMP_2.png\n",
      "./resources/images/CLAMP2/CHIP6_WIRE11_CLAMP_2.png\n",
      "./resources/images/CLAMP2/CHIP6_WIRE12_CLAMP_2.png\n",
      "./resources/images/CLAMP2/CHIP6_WIRE13_CLAMP_2.png\n",
      "./resources/images/CLAMP2/CHIP6_WIRE14_CLAMP_2.png\n",
      "./resources/images/CLAMP2/CHIP6_WIRE15_CLAMP_2.png\n",
      "./resources/images/CLAMP2/CHIP6_WIRE16_CLAMP_2.png\n",
      "./resources/images/CLAMP2/CHIP6_WIRE17_CLAMP_2.png\n",
      "./resources/images/CLAMP2/CHIP6_WIRE18_CLAMP_2.png\n",
      "./resources/images/CLAMP2/CHIP6_WIRE19_CLAMP_2.png\n",
      "./resources/images/CLAMP2/CHIP6_WIRE1_CLAMP_2.png\n",
      "./resources/images/CLAMP2/CHIP6_WIRE2_CLAMP_2.png\n",
      "./resources/images/CLAMP2/CHIP6_WIRE3_CLAMP_2.png\n",
      "./resources/images/CLAMP2/CHIP6_WIRE4_CLAMP_2.png\n",
      "./resources/images/CLAMP2/CHIP6_WIRE5_CLAMP_2.png\n",
      "./resources/images/CLAMP2/CHIP6_WIRE6_CLAMP_2.png\n",
      "./resources/images/CLAMP2/CHIP6_WIRE7_CLAMP_2.png\n",
      "./resources/images/CLAMP2/CHIP6_WIRE8_CLAMP_2.png\n",
      "./resources/images/CLAMP2/CHIP6_WIRE9_CLAMP_2.png\n",
      "./resources/images/CLAMP2/CHIP7_WIRE10_CLAMP_2.png\n",
      "./resources/images/CLAMP2/CHIP7_WIRE11_CLAMP_2.png\n",
      "./resources/images/CLAMP2/CHIP7_WIRE12_CLAMP_2.png\n",
      "./resources/images/CLAMP2/CHIP7_WIRE13_CLAMP_2.png\n",
      "./resources/images/CLAMP2/CHIP7_WIRE14_CLAMP_2.png\n",
      "./resources/images/CLAMP2/CHIP7_WIRE15_CLAMP_2.png\n",
      "./resources/images/CLAMP2/CHIP7_WIRE16_CLAMP_2.png\n",
      "./resources/images/CLAMP2/CHIP7_WIRE17_CLAMP_2.png\n",
      "./resources/images/CLAMP2/CHIP7_WIRE18_CLAMP_2.png\n",
      "./resources/images/CLAMP2/CHIP7_WIRE19_CLAMP_2.png\n",
      "./resources/images/CLAMP2/CHIP7_WIRE1_CLAMP_2.png\n",
      "./resources/images/CLAMP2/CHIP7_WIRE2_CLAMP_2.png\n",
      "./resources/images/CLAMP2/CHIP7_WIRE3_CLAMP_2.png\n",
      "./resources/images/CLAMP2/CHIP7_WIRE4_CLAMP_2.png\n",
      "./resources/images/CLAMP2/CHIP7_WIRE5_CLAMP_2.png\n",
      "./resources/images/CLAMP2/CHIP7_WIRE6_CLAMP_2.png\n",
      "./resources/images/CLAMP2/CHIP7_WIRE7_CLAMP_2.png\n",
      "./resources/images/CLAMP2/CHIP7_WIRE8_CLAMP_2.png\n",
      "./resources/images/CLAMP2/CHIP7_WIRE9_CLAMP_2.png\n",
      "./resources/images/CLAMP2/CHIP8_WIRE10_CLAMP_2.png\n",
      "./resources/images/CLAMP2/CHIP8_WIRE11_CLAMP_2.png\n",
      "./resources/images/CLAMP2/CHIP8_WIRE12_CLAMP_2.png\n",
      "./resources/images/CLAMP2/CHIP8_WIRE13_CLAMP_2.png\n",
      "./resources/images/CLAMP2/CHIP8_WIRE14_CLAMP_2.png\n",
      "./resources/images/CLAMP2/CHIP8_WIRE15_CLAMP_2.png\n",
      "./resources/images/CLAMP2/CHIP8_WIRE16_CLAMP_2.png\n",
      "./resources/images/CLAMP2/CHIP8_WIRE17_CLAMP_2.png\n",
      "./resources/images/CLAMP2/CHIP8_WIRE18_CLAMP_2.png\n",
      "./resources/images/CLAMP2/CHIP8_WIRE19_CLAMP_2.png\n",
      "./resources/images/CLAMP2/CHIP8_WIRE1_CLAMP_2.png\n",
      "./resources/images/CLAMP2/CHIP8_WIRE2_CLAMP_2.png\n",
      "./resources/images/CLAMP2/CHIP8_WIRE3_CLAMP_2.png\n",
      "./resources/images/CLAMP2/CHIP8_WIRE4_CLAMP_2.png\n",
      "./resources/images/CLAMP2/CHIP8_WIRE5_CLAMP_2.png\n",
      "./resources/images/CLAMP2/CHIP8_WIRE6_CLAMP_2.png\n",
      "./resources/images/CLAMP2/CHIP8_WIRE7_CLAMP_2.png\n",
      "./resources/images/CLAMP2/CHIP8_WIRE8_CLAMP_2.png\n",
      "./resources/images/CLAMP2/CHIP8_WIRE9_CLAMP_2.png\n",
      "./resources/images/CLAMP2/CHIP9_WIRE10_CLAMP_2.png\n",
      "./resources/images/CLAMP2/CHIP9_WIRE11_CLAMP_2.png\n",
      "./resources/images/CLAMP2/CHIP9_WIRE12_CLAMP_2.png\n",
      "./resources/images/CLAMP2/CHIP9_WIRE13_CLAMP_2.png\n",
      "./resources/images/CLAMP2/CHIP9_WIRE14_CLAMP_2.png\n",
      "./resources/images/CLAMP2/CHIP9_WIRE15_CLAMP_2.png\n",
      "./resources/images/CLAMP2/CHIP9_WIRE16_CLAMP_2.png\n",
      "./resources/images/CLAMP2/CHIP9_WIRE17_CLAMP_2.png\n",
      "./resources/images/CLAMP2/CHIP9_WIRE18_CLAMP_2.png\n",
      "./resources/images/CLAMP2/CHIP9_WIRE19_CLAMP_2.png\n",
      "./resources/images/CLAMP2/CHIP9_WIRE1_CLAMP_2.png\n",
      "./resources/images/CLAMP2/CHIP9_WIRE2_CLAMP_2.png\n",
      "./resources/images/CLAMP2/CHIP9_WIRE3_CLAMP_2.png\n",
      "./resources/images/CLAMP2/CHIP9_WIRE4_CLAMP_2.png\n",
      "./resources/images/CLAMP2/CHIP9_WIRE5_CLAMP_2.png\n",
      "./resources/images/CLAMP2/CHIP9_WIRE6_CLAMP_2.png\n",
      "./resources/images/CLAMP2/CHIP9_WIRE7_CLAMP_2.png\n",
      "./resources/images/CLAMP2/CHIP9_WIRE8_CLAMP_2.png\n",
      "./resources/images/CLAMP2/CHIP9_WIRE9_CLAMP_2.png\n",
      "./resources/images/CLAMP2\n",
      "CLAMP3\n",
      "./resources/images/CLAMP3/CHIP10_WIRE10_CLAMP_3.png\n",
      "./resources/images/CLAMP3/CHIP10_WIRE11_CLAMP_3.png\n",
      "./resources/images/CLAMP3/CHIP1_WIRE10_CLAMP_3.png\n",
      "./resources/images/CLAMP3/CHIP1_WIRE11_CLAMP_3.png\n",
      "./resources/images/CLAMP3/CHIP1_WIRE12_CLAMP_3.png\n",
      "./resources/images/CLAMP3/CHIP1_WIRE13_CLAMP_3.png\n",
      "./resources/images/CLAMP3/CHIP1_WIRE14_CLAMP_3.png\n",
      "./resources/images/CLAMP3/CHIP1_WIRE15_CLAMP_3.png\n",
      "./resources/images/CLAMP3/CHIP1_WIRE16_CLAMP_3.png\n",
      "./resources/images/CLAMP3/CHIP1_WIRE17_CLAMP_3.png\n",
      "./resources/images/CLAMP3/CHIP1_WIRE18_CLAMP_3.png\n",
      "./resources/images/CLAMP3/CHIP1_WIRE19_CLAMP_3.png\n",
      "./resources/images/CLAMP3/CHIP1_WIRE1_CLAMP_3.png\n",
      "./resources/images/CLAMP3/CHIP1_WIRE2_CLAMP_3.png\n",
      "./resources/images/CLAMP3/CHIP1_WIRE3_CLAMP_3.png\n",
      "./resources/images/CLAMP3/CHIP1_WIRE4_CLAMP_3.png\n",
      "./resources/images/CLAMP3/CHIP1_WIRE5_CLAMP_3.png\n",
      "./resources/images/CLAMP3/CHIP1_WIRE6_CLAMP_3.png\n",
      "./resources/images/CLAMP3/CHIP1_WIRE7_CLAMP_3.png\n",
      "./resources/images/CLAMP3/CHIP1_WIRE8_CLAMP_3.png\n",
      "./resources/images/CLAMP3/CHIP1_WIRE9_CLAMP_3.png\n",
      "./resources/images/CLAMP3/CHIP2_WIRE10_CLAMP_3.png\n",
      "./resources/images/CLAMP3/CHIP2_WIRE11_CLAMP_3.png\n",
      "./resources/images/CLAMP3/CHIP2_WIRE12_CLAMP_3.png\n",
      "./resources/images/CLAMP3/CHIP2_WIRE13_CLAMP_3.png\n",
      "./resources/images/CLAMP3/CHIP2_WIRE14_CLAMP_3.png\n",
      "./resources/images/CLAMP3/CHIP2_WIRE15_CLAMP_3.png\n",
      "./resources/images/CLAMP3/CHIP2_WIRE16_CLAMP_3.png\n",
      "./resources/images/CLAMP3/CHIP2_WIRE17_CLAMP_3.png\n",
      "./resources/images/CLAMP3/CHIP2_WIRE18_CLAMP_3.png\n",
      "./resources/images/CLAMP3/CHIP2_WIRE19_CLAMP_3.png\n",
      "./resources/images/CLAMP3/CHIP2_WIRE1_CLAMP_3.png\n",
      "./resources/images/CLAMP3/CHIP2_WIRE2_CLAMP_3.png\n",
      "./resources/images/CLAMP3/CHIP2_WIRE3_CLAMP_3.png\n",
      "./resources/images/CLAMP3/CHIP2_WIRE4_CLAMP_3.png\n",
      "./resources/images/CLAMP3/CHIP2_WIRE5_CLAMP_3.png\n",
      "./resources/images/CLAMP3/CHIP2_WIRE6_CLAMP_3.png\n",
      "./resources/images/CLAMP3/CHIP2_WIRE7_CLAMP_3.png\n",
      "./resources/images/CLAMP3/CHIP2_WIRE8_CLAMP_3.png\n",
      "./resources/images/CLAMP3/CHIP2_WIRE9_CLAMP_3.png\n",
      "./resources/images/CLAMP3/CHIP3_WIRE10_CLAMP_3.png\n",
      "./resources/images/CLAMP3/CHIP3_WIRE11_CLAMP_3.png\n",
      "./resources/images/CLAMP3/CHIP3_WIRE12_CLAMP_3.png\n",
      "./resources/images/CLAMP3/CHIP3_WIRE13_CLAMP_3.png\n",
      "./resources/images/CLAMP3/CHIP3_WIRE14_CLAMP_3.png\n",
      "./resources/images/CLAMP3/CHIP3_WIRE15_CLAMP_3.png\n",
      "./resources/images/CLAMP3/CHIP3_WIRE16_CLAMP_3.png\n",
      "./resources/images/CLAMP3/CHIP3_WIRE17_CLAMP_3.png\n",
      "./resources/images/CLAMP3/CHIP3_WIRE18_CLAMP_3.png\n",
      "./resources/images/CLAMP3/CHIP3_WIRE19_CLAMP_3.png\n",
      "./resources/images/CLAMP3/CHIP3_WIRE1_CLAMP_3.png\n",
      "./resources/images/CLAMP3/CHIP3_WIRE2_CLAMP_3.png\n",
      "./resources/images/CLAMP3/CHIP3_WIRE3_CLAMP_3.png\n",
      "./resources/images/CLAMP3/CHIP3_WIRE4_CLAMP_3.png\n",
      "./resources/images/CLAMP3/CHIP3_WIRE5_CLAMP_3.png\n",
      "./resources/images/CLAMP3/CHIP3_WIRE6_CLAMP_3.png\n",
      "./resources/images/CLAMP3/CHIP3_WIRE7_CLAMP_3.png\n",
      "./resources/images/CLAMP3/CHIP3_WIRE8_CLAMP_3.png\n",
      "./resources/images/CLAMP3/CHIP3_WIRE9_CLAMP_3.png\n",
      "./resources/images/CLAMP3/CHIP4_WIRE10_CLAMP_3.png\n",
      "./resources/images/CLAMP3/CHIP4_WIRE11_CLAMP_3.png\n",
      "./resources/images/CLAMP3/CHIP4_WIRE12_CLAMP_3.png\n",
      "./resources/images/CLAMP3/CHIP4_WIRE13_CLAMP_3.png\n",
      "./resources/images/CLAMP3/CHIP4_WIRE14_CLAMP_3.png\n",
      "./resources/images/CLAMP3/CHIP4_WIRE15_CLAMP_3.png\n",
      "./resources/images/CLAMP3/CHIP4_WIRE16_CLAMP_3.png\n",
      "./resources/images/CLAMP3/CHIP4_WIRE17_CLAMP_3.png\n",
      "./resources/images/CLAMP3/CHIP4_WIRE18_CLAMP_3.png\n",
      "./resources/images/CLAMP3/CHIP4_WIRE19_CLAMP_3.png\n",
      "./resources/images/CLAMP3/CHIP4_WIRE1_CLAMP_3.png\n",
      "./resources/images/CLAMP3/CHIP4_WIRE2_CLAMP_3.png\n",
      "./resources/images/CLAMP3/CHIP4_WIRE3_CLAMP_3.png\n",
      "./resources/images/CLAMP3/CHIP4_WIRE4_CLAMP_3.png\n",
      "./resources/images/CLAMP3/CHIP4_WIRE5_CLAMP_3.png\n",
      "./resources/images/CLAMP3/CHIP4_WIRE6_CLAMP_3.png\n",
      "./resources/images/CLAMP3/CHIP4_WIRE7_CLAMP_3.png\n",
      "./resources/images/CLAMP3/CHIP4_WIRE8_CLAMP_3.png\n",
      "./resources/images/CLAMP3/CHIP4_WIRE9_CLAMP_3.png\n",
      "./resources/images/CLAMP3/CHIP5_WIRE10_CLAMP_3.png\n",
      "./resources/images/CLAMP3/CHIP5_WIRE11_CLAMP_3.png\n",
      "./resources/images/CLAMP3/CHIP5_WIRE12_CLAMP_3.png\n",
      "./resources/images/CLAMP3/CHIP5_WIRE13_CLAMP_3.png\n",
      "./resources/images/CLAMP3/CHIP5_WIRE14_CLAMP_3.png\n",
      "./resources/images/CLAMP3/CHIP5_WIRE15_CLAMP_3.png\n",
      "./resources/images/CLAMP3/CHIP5_WIRE16_CLAMP_3.png\n",
      "./resources/images/CLAMP3/CHIP5_WIRE17_CLAMP_3.png\n",
      "./resources/images/CLAMP3/CHIP5_WIRE18_CLAMP_3.png\n",
      "./resources/images/CLAMP3/CHIP5_WIRE19_CLAMP_3.png\n",
      "./resources/images/CLAMP3/CHIP5_WIRE1_CLAMP_3.png\n",
      "./resources/images/CLAMP3/CHIP5_WIRE2_CLAMP_3.png\n",
      "./resources/images/CLAMP3/CHIP5_WIRE3_CLAMP_3.png\n",
      "./resources/images/CLAMP3/CHIP5_WIRE4_CLAMP_3.png\n",
      "./resources/images/CLAMP3/CHIP5_WIRE5_CLAMP_3.png\n",
      "./resources/images/CLAMP3/CHIP5_WIRE6_CLAMP_3.png\n",
      "./resources/images/CLAMP3/CHIP5_WIRE7_CLAMP_3.png\n",
      "./resources/images/CLAMP3/CHIP5_WIRE8_CLAMP_3.png\n",
      "./resources/images/CLAMP3/CHIP5_WIRE9_CLAMP_3.png\n",
      "./resources/images/CLAMP3/CHIP6_WIRE10_CLAMP_3.png\n",
      "./resources/images/CLAMP3/CHIP6_WIRE11_CLAMP_3.png\n",
      "./resources/images/CLAMP3/CHIP6_WIRE12_CLAMP_3.png\n",
      "./resources/images/CLAMP3/CHIP6_WIRE13_CLAMP_3.png\n",
      "./resources/images/CLAMP3/CHIP6_WIRE14_CLAMP_3.png\n",
      "./resources/images/CLAMP3/CHIP6_WIRE15_CLAMP_3.png\n",
      "./resources/images/CLAMP3/CHIP6_WIRE16_CLAMP_3.png\n",
      "./resources/images/CLAMP3/CHIP6_WIRE17_CLAMP_3.png\n",
      "./resources/images/CLAMP3/CHIP6_WIRE18_CLAMP_3.png\n",
      "./resources/images/CLAMP3/CHIP6_WIRE19_CLAMP_3.png\n",
      "./resources/images/CLAMP3/CHIP6_WIRE1_CLAMP_3.png\n",
      "./resources/images/CLAMP3/CHIP6_WIRE2_CLAMP_3.png\n",
      "./resources/images/CLAMP3/CHIP6_WIRE3_CLAMP_3.png\n",
      "./resources/images/CLAMP3/CHIP6_WIRE4_CLAMP_3.png\n",
      "./resources/images/CLAMP3/CHIP6_WIRE5_CLAMP_3.png\n",
      "./resources/images/CLAMP3/CHIP6_WIRE6_CLAMP_3.png\n",
      "./resources/images/CLAMP3/CHIP6_WIRE7_CLAMP_3.png\n",
      "./resources/images/CLAMP3/CHIP6_WIRE8_CLAMP_3.png\n",
      "./resources/images/CLAMP3/CHIP6_WIRE9_CLAMP_3.png\n",
      "./resources/images/CLAMP3/CHIP7_WIRE10_CLAMP_3.png\n",
      "./resources/images/CLAMP3/CHIP7_WIRE11_CLAMP_3.png\n",
      "./resources/images/CLAMP3/CHIP7_WIRE12_CLAMP_3.png\n",
      "./resources/images/CLAMP3/CHIP7_WIRE13_CLAMP_3.png\n",
      "./resources/images/CLAMP3/CHIP7_WIRE14_CLAMP_3.png\n",
      "./resources/images/CLAMP3/CHIP7_WIRE15_CLAMP_3.png\n",
      "./resources/images/CLAMP3/CHIP7_WIRE16_CLAMP_3.png\n",
      "./resources/images/CLAMP3/CHIP7_WIRE17_CLAMP_3.png\n",
      "./resources/images/CLAMP3/CHIP7_WIRE18_CLAMP_3.png\n",
      "./resources/images/CLAMP3/CHIP7_WIRE19_CLAMP_3.png\n",
      "./resources/images/CLAMP3/CHIP7_WIRE1_CLAMP_3.png\n",
      "./resources/images/CLAMP3/CHIP7_WIRE2_CLAMP_3.png\n",
      "./resources/images/CLAMP3/CHIP7_WIRE3_CLAMP_3.png\n",
      "./resources/images/CLAMP3/CHIP7_WIRE4_CLAMP_3.png\n",
      "./resources/images/CLAMP3/CHIP7_WIRE5_CLAMP_3.png\n",
      "./resources/images/CLAMP3/CHIP7_WIRE6_CLAMP_3.png\n",
      "./resources/images/CLAMP3/CHIP7_WIRE7_CLAMP_3.png\n",
      "./resources/images/CLAMP3/CHIP7_WIRE8_CLAMP_3.png\n",
      "./resources/images/CLAMP3/CHIP7_WIRE9_CLAMP_3.png\n",
      "./resources/images/CLAMP3/CHIP8_WIRE10_CLAMP_3.png\n",
      "./resources/images/CLAMP3/CHIP8_WIRE11_CLAMP_3.png\n",
      "./resources/images/CLAMP3/CHIP8_WIRE12_CLAMP_3.png\n",
      "./resources/images/CLAMP3/CHIP8_WIRE13_CLAMP_3.png\n",
      "./resources/images/CLAMP3/CHIP8_WIRE14_CLAMP_3.png\n",
      "./resources/images/CLAMP3/CHIP8_WIRE15_CLAMP_3.png\n",
      "./resources/images/CLAMP3/CHIP8_WIRE16_CLAMP_3.png\n",
      "./resources/images/CLAMP3/CHIP8_WIRE17_CLAMP_3.png\n",
      "./resources/images/CLAMP3/CHIP8_WIRE18_CLAMP_3.png\n",
      "./resources/images/CLAMP3/CHIP8_WIRE19_CLAMP_3.png\n",
      "./resources/images/CLAMP3/CHIP8_WIRE1_CLAMP_3.png\n",
      "./resources/images/CLAMP3/CHIP8_WIRE2_CLAMP_3.png\n",
      "./resources/images/CLAMP3/CHIP8_WIRE3_CLAMP_3.png\n",
      "./resources/images/CLAMP3/CHIP8_WIRE4_CLAMP_3.png\n",
      "./resources/images/CLAMP3/CHIP8_WIRE5_CLAMP_3.png\n",
      "./resources/images/CLAMP3/CHIP8_WIRE6_CLAMP_3.png\n",
      "./resources/images/CLAMP3/CHIP8_WIRE7_CLAMP_3.png\n",
      "./resources/images/CLAMP3/CHIP8_WIRE8_CLAMP_3.png\n",
      "./resources/images/CLAMP3/CHIP8_WIRE9_CLAMP_3.png\n",
      "./resources/images/CLAMP3/CHIP9_WIRE10_CLAMP_3.png\n",
      "./resources/images/CLAMP3/CHIP9_WIRE11_CLAMP_3.png\n",
      "./resources/images/CLAMP3/CHIP9_WIRE12_CLAMP_3.png\n",
      "./resources/images/CLAMP3/CHIP9_WIRE13_CLAMP_3.png\n",
      "./resources/images/CLAMP3/CHIP9_WIRE14_CLAMP_3.png\n",
      "./resources/images/CLAMP3/CHIP9_WIRE15_CLAMP_3.png\n",
      "./resources/images/CLAMP3/CHIP9_WIRE16_CLAMP_3.png\n",
      "./resources/images/CLAMP3/CHIP9_WIRE17_CLAMP_3.png\n",
      "./resources/images/CLAMP3/CHIP9_WIRE18_CLAMP_3.png\n",
      "./resources/images/CLAMP3/CHIP9_WIRE19_CLAMP_3.png\n",
      "./resources/images/CLAMP3/CHIP9_WIRE1_CLAMP_3.png\n",
      "./resources/images/CLAMP3/CHIP9_WIRE2_CLAMP_3.png\n",
      "./resources/images/CLAMP3/CHIP9_WIRE3_CLAMP_3.png\n",
      "./resources/images/CLAMP3/CHIP9_WIRE4_CLAMP_3.png\n",
      "./resources/images/CLAMP3/CHIP9_WIRE5_CLAMP_3.png\n",
      "./resources/images/CLAMP3/CHIP9_WIRE6_CLAMP_3.png\n",
      "./resources/images/CLAMP3/CHIP9_WIRE7_CLAMP_3.png\n",
      "./resources/images/CLAMP3/CHIP9_WIRE8_CLAMP_3.png\n",
      "./resources/images/CLAMP3/CHIP9_WIRE9_CLAMP_3.png\n",
      "./resources/images/CLAMP3\n",
      "CLAMP4\n",
      "./resources/images/CLAMP4/CHIP10_WIRE10_CLAMP_4.png\n",
      "./resources/images/CLAMP4/CHIP10_WIRE11_CLAMP_4.png\n",
      "./resources/images/CLAMP4/CHIP1_WIRE10_CLAMP_4.png\n",
      "./resources/images/CLAMP4/CHIP1_WIRE11_CLAMP_4.png\n",
      "./resources/images/CLAMP4/CHIP1_WIRE12_CLAMP_4.png\n",
      "./resources/images/CLAMP4/CHIP1_WIRE13_CLAMP_4.png\n",
      "./resources/images/CLAMP4/CHIP1_WIRE14_CLAMP_4.png\n",
      "./resources/images/CLAMP4/CHIP1_WIRE15_CLAMP_4.png\n",
      "./resources/images/CLAMP4/CHIP1_WIRE16_CLAMP_4.png\n",
      "./resources/images/CLAMP4/CHIP1_WIRE17_CLAMP_4.png\n",
      "./resources/images/CLAMP4/CHIP1_WIRE18_CLAMP_4.png\n",
      "./resources/images/CLAMP4/CHIP1_WIRE19_CLAMP_4.png\n",
      "./resources/images/CLAMP4/CHIP1_WIRE1_CLAMP_4.png\n",
      "./resources/images/CLAMP4/CHIP1_WIRE2_CLAMP_4.png\n",
      "./resources/images/CLAMP4/CHIP1_WIRE3_CLAMP_4.png\n",
      "./resources/images/CLAMP4/CHIP1_WIRE4_CLAMP_4.png\n",
      "./resources/images/CLAMP4/CHIP1_WIRE5_CLAMP_4.png\n",
      "./resources/images/CLAMP4/CHIP1_WIRE6_CLAMP_4.png\n",
      "./resources/images/CLAMP4/CHIP1_WIRE7_CLAMP_4.png\n",
      "./resources/images/CLAMP4/CHIP1_WIRE8_CLAMP_4.png\n",
      "./resources/images/CLAMP4/CHIP1_WIRE9_CLAMP_4.png\n",
      "./resources/images/CLAMP4/CHIP2_WIRE10_CLAMP_4.png\n",
      "./resources/images/CLAMP4/CHIP2_WIRE11_CLAMP_4.png\n",
      "./resources/images/CLAMP4/CHIP2_WIRE12_CLAMP_4.png\n",
      "./resources/images/CLAMP4/CHIP2_WIRE13_CLAMP_4.png\n",
      "./resources/images/CLAMP4/CHIP2_WIRE14_CLAMP_4.png\n",
      "./resources/images/CLAMP4/CHIP2_WIRE15_CLAMP_4.png\n",
      "./resources/images/CLAMP4/CHIP2_WIRE16_CLAMP_4.png\n",
      "./resources/images/CLAMP4/CHIP2_WIRE17_CLAMP_4.png\n",
      "./resources/images/CLAMP4/CHIP2_WIRE18_CLAMP_4.png\n",
      "./resources/images/CLAMP4/CHIP2_WIRE19_CLAMP_4.png\n",
      "./resources/images/CLAMP4/CHIP2_WIRE1_CLAMP_4.png\n",
      "./resources/images/CLAMP4/CHIP2_WIRE2_CLAMP_4.png\n",
      "./resources/images/CLAMP4/CHIP2_WIRE3_CLAMP_4.png\n",
      "./resources/images/CLAMP4/CHIP2_WIRE4_CLAMP_4.png\n",
      "./resources/images/CLAMP4/CHIP2_WIRE5_CLAMP_4.png\n",
      "./resources/images/CLAMP4/CHIP2_WIRE6_CLAMP_4.png\n",
      "./resources/images/CLAMP4/CHIP2_WIRE7_CLAMP_4.png\n",
      "./resources/images/CLAMP4/CHIP2_WIRE8_CLAMP_4.png\n",
      "./resources/images/CLAMP4/CHIP2_WIRE9_CLAMP_4.png\n",
      "./resources/images/CLAMP4/CHIP3_WIRE10_CLAMP_4.png\n",
      "./resources/images/CLAMP4/CHIP3_WIRE11_CLAMP_4.png\n",
      "./resources/images/CLAMP4/CHIP3_WIRE12_CLAMP_4.png\n",
      "./resources/images/CLAMP4/CHIP3_WIRE13_CLAMP_4.png\n",
      "./resources/images/CLAMP4/CHIP3_WIRE14_CLAMP_4.png\n",
      "./resources/images/CLAMP4/CHIP3_WIRE15_CLAMP_4.png\n",
      "./resources/images/CLAMP4/CHIP3_WIRE16_CLAMP_4.png\n",
      "./resources/images/CLAMP4/CHIP3_WIRE17_CLAMP_4.png\n",
      "./resources/images/CLAMP4/CHIP3_WIRE18_CLAMP_4.png\n",
      "./resources/images/CLAMP4/CHIP3_WIRE19_CLAMP_4.png\n",
      "./resources/images/CLAMP4/CHIP3_WIRE1_CLAMP_4.png\n",
      "./resources/images/CLAMP4/CHIP3_WIRE2_CLAMP_4.png\n",
      "./resources/images/CLAMP4/CHIP3_WIRE3_CLAMP_4.png\n",
      "./resources/images/CLAMP4/CHIP3_WIRE4_CLAMP_4.png\n",
      "./resources/images/CLAMP4/CHIP3_WIRE5_CLAMP_4.png\n",
      "./resources/images/CLAMP4/CHIP3_WIRE6_CLAMP_4.png\n",
      "./resources/images/CLAMP4/CHIP3_WIRE7_CLAMP_4.png\n",
      "./resources/images/CLAMP4/CHIP3_WIRE8_CLAMP_4.png\n",
      "./resources/images/CLAMP4/CHIP3_WIRE9_CLAMP_4.png\n",
      "./resources/images/CLAMP4/CHIP4_WIRE10_CLAMP_4.png\n",
      "./resources/images/CLAMP4/CHIP4_WIRE11_CLAMP_4.png\n",
      "./resources/images/CLAMP4/CHIP4_WIRE12_CLAMP_4.png\n",
      "./resources/images/CLAMP4/CHIP4_WIRE13_CLAMP_4.png\n",
      "./resources/images/CLAMP4/CHIP4_WIRE14_CLAMP_4.png\n",
      "./resources/images/CLAMP4/CHIP4_WIRE15_CLAMP_4.png\n",
      "./resources/images/CLAMP4/CHIP4_WIRE16_CLAMP_4.png\n",
      "./resources/images/CLAMP4/CHIP4_WIRE17_CLAMP_4.png\n",
      "./resources/images/CLAMP4/CHIP4_WIRE18_CLAMP_4.png\n",
      "./resources/images/CLAMP4/CHIP4_WIRE19_CLAMP_4.png\n",
      "./resources/images/CLAMP4/CHIP4_WIRE1_CLAMP_4.png\n",
      "./resources/images/CLAMP4/CHIP4_WIRE2_CLAMP_4.png\n",
      "./resources/images/CLAMP4/CHIP4_WIRE3_CLAMP_4.png\n",
      "./resources/images/CLAMP4/CHIP4_WIRE4_CLAMP_4.png\n",
      "./resources/images/CLAMP4/CHIP4_WIRE5_CLAMP_4.png\n",
      "./resources/images/CLAMP4/CHIP4_WIRE6_CLAMP_4.png\n",
      "./resources/images/CLAMP4/CHIP4_WIRE7_CLAMP_4.png\n",
      "./resources/images/CLAMP4/CHIP4_WIRE8_CLAMP_4.png\n",
      "./resources/images/CLAMP4/CHIP4_WIRE9_CLAMP_4.png\n",
      "./resources/images/CLAMP4/CHIP5_WIRE10_CLAMP_4.png\n",
      "./resources/images/CLAMP4/CHIP5_WIRE11_CLAMP_4.png\n",
      "./resources/images/CLAMP4/CHIP5_WIRE12_CLAMP_4.png\n",
      "./resources/images/CLAMP4/CHIP5_WIRE13_CLAMP_4.png\n",
      "./resources/images/CLAMP4/CHIP5_WIRE14_CLAMP_4.png\n",
      "./resources/images/CLAMP4/CHIP5_WIRE15_CLAMP_4.png\n",
      "./resources/images/CLAMP4/CHIP5_WIRE16_CLAMP_4.png\n",
      "./resources/images/CLAMP4/CHIP5_WIRE17_CLAMP_4.png\n",
      "./resources/images/CLAMP4/CHIP5_WIRE18_CLAMP_4.png\n",
      "./resources/images/CLAMP4/CHIP5_WIRE19_CLAMP_4.png\n",
      "./resources/images/CLAMP4/CHIP5_WIRE1_CLAMP_4.png\n",
      "./resources/images/CLAMP4/CHIP5_WIRE2_CLAMP_4.png\n",
      "./resources/images/CLAMP4/CHIP5_WIRE3_CLAMP_4.png\n",
      "./resources/images/CLAMP4/CHIP5_WIRE4_CLAMP_4.png\n",
      "./resources/images/CLAMP4/CHIP5_WIRE5_CLAMP_4.png\n",
      "./resources/images/CLAMP4/CHIP5_WIRE6_CLAMP_4.png\n",
      "./resources/images/CLAMP4/CHIP5_WIRE7_CLAMP_4.png\n",
      "./resources/images/CLAMP4/CHIP5_WIRE8_CLAMP_4.png\n",
      "./resources/images/CLAMP4/CHIP5_WIRE9_CLAMP_4.png\n",
      "./resources/images/CLAMP4/CHIP6_WIRE10_CLAMP_4.png\n",
      "./resources/images/CLAMP4/CHIP6_WIRE11_CLAMP_4.png\n",
      "./resources/images/CLAMP4/CHIP6_WIRE12_CLAMP_4.png\n",
      "./resources/images/CLAMP4/CHIP6_WIRE13_CLAMP_4.png\n",
      "./resources/images/CLAMP4/CHIP6_WIRE14_CLAMP_4.png\n",
      "./resources/images/CLAMP4/CHIP6_WIRE15_CLAMP_4.png\n",
      "./resources/images/CLAMP4/CHIP6_WIRE16_CLAMP_4.png\n",
      "./resources/images/CLAMP4/CHIP6_WIRE17_CLAMP_4.png\n",
      "./resources/images/CLAMP4/CHIP6_WIRE18_CLAMP_4.png\n",
      "./resources/images/CLAMP4/CHIP6_WIRE19_CLAMP_4.png\n",
      "./resources/images/CLAMP4/CHIP6_WIRE1_CLAMP_4.png\n",
      "./resources/images/CLAMP4/CHIP6_WIRE2_CLAMP_4.png\n",
      "./resources/images/CLAMP4/CHIP6_WIRE3_CLAMP_4.png\n",
      "./resources/images/CLAMP4/CHIP6_WIRE4_CLAMP_4.png\n",
      "./resources/images/CLAMP4/CHIP6_WIRE5_CLAMP_4.png\n",
      "./resources/images/CLAMP4/CHIP6_WIRE6_CLAMP_4.png\n",
      "./resources/images/CLAMP4/CHIP6_WIRE7_CLAMP_4.png\n",
      "./resources/images/CLAMP4/CHIP6_WIRE8_CLAMP_4.png\n",
      "./resources/images/CLAMP4/CHIP6_WIRE9_CLAMP_4.png\n",
      "./resources/images/CLAMP4/CHIP7_WIRE10_CLAMP_4.png\n",
      "./resources/images/CLAMP4/CHIP7_WIRE11_CLAMP_4.png\n",
      "./resources/images/CLAMP4/CHIP7_WIRE12_CLAMP_4.png\n",
      "./resources/images/CLAMP4/CHIP7_WIRE13_CLAMP_4.png\n",
      "./resources/images/CLAMP4/CHIP7_WIRE14_CLAMP_4.png\n",
      "./resources/images/CLAMP4/CHIP7_WIRE15_CLAMP_4.png\n",
      "./resources/images/CLAMP4/CHIP7_WIRE16_CLAMP_4.png\n",
      "./resources/images/CLAMP4/CHIP7_WIRE17_CLAMP_4.png\n",
      "./resources/images/CLAMP4/CHIP7_WIRE18_CLAMP_4.png\n",
      "./resources/images/CLAMP4/CHIP7_WIRE19_CLAMP_4.png\n",
      "./resources/images/CLAMP4/CHIP7_WIRE1_CLAMP_4.png\n",
      "./resources/images/CLAMP4/CHIP7_WIRE2_CLAMP_4.png\n",
      "./resources/images/CLAMP4/CHIP7_WIRE3_CLAMP_4.png\n",
      "./resources/images/CLAMP4/CHIP7_WIRE4_CLAMP_4.png\n",
      "./resources/images/CLAMP4/CHIP7_WIRE5_CLAMP_4.png\n",
      "./resources/images/CLAMP4/CHIP7_WIRE6_CLAMP_4.png\n",
      "./resources/images/CLAMP4/CHIP7_WIRE7_CLAMP_4.png\n",
      "./resources/images/CLAMP4/CHIP7_WIRE8_CLAMP_4.png\n",
      "./resources/images/CLAMP4/CHIP7_WIRE9_CLAMP_4.png\n",
      "./resources/images/CLAMP4/CHIP8_WIRE10_CLAMP_4.png\n",
      "./resources/images/CLAMP4/CHIP8_WIRE11_CLAMP_4.png\n",
      "./resources/images/CLAMP4/CHIP8_WIRE12_CLAMP_4.png\n",
      "./resources/images/CLAMP4/CHIP8_WIRE13_CLAMP_4.png\n",
      "./resources/images/CLAMP4/CHIP8_WIRE14_CLAMP_4.png\n",
      "./resources/images/CLAMP4/CHIP8_WIRE15_CLAMP_4.png\n",
      "./resources/images/CLAMP4/CHIP8_WIRE16_CLAMP_4.png\n",
      "./resources/images/CLAMP4/CHIP8_WIRE17_CLAMP_4.png\n",
      "./resources/images/CLAMP4/CHIP8_WIRE18_CLAMP_4.png\n",
      "./resources/images/CLAMP4/CHIP8_WIRE19_CLAMP_4.png\n",
      "./resources/images/CLAMP4/CHIP8_WIRE1_CLAMP_4.png\n",
      "./resources/images/CLAMP4/CHIP8_WIRE2_CLAMP_4.png\n",
      "./resources/images/CLAMP4/CHIP8_WIRE3_CLAMP_4.png\n",
      "./resources/images/CLAMP4/CHIP8_WIRE4_CLAMP_4.png\n",
      "./resources/images/CLAMP4/CHIP8_WIRE5_CLAMP_4.png\n",
      "./resources/images/CLAMP4/CHIP8_WIRE6_CLAMP_4.png\n",
      "./resources/images/CLAMP4/CHIP8_WIRE7_CLAMP_4.png\n",
      "./resources/images/CLAMP4/CHIP8_WIRE8_CLAMP_4.png\n",
      "./resources/images/CLAMP4/CHIP8_WIRE9_CLAMP_4.png\n",
      "./resources/images/CLAMP4/CHIP9_WIRE10_CLAMP_4.png\n",
      "./resources/images/CLAMP4/CHIP9_WIRE11_CLAMP_4.png\n",
      "./resources/images/CLAMP4/CHIP9_WIRE12_CLAMP_4.png\n",
      "./resources/images/CLAMP4/CHIP9_WIRE13_CLAMP_4.png\n",
      "./resources/images/CLAMP4/CHIP9_WIRE14_CLAMP_4.png\n",
      "./resources/images/CLAMP4/CHIP9_WIRE15_CLAMP_4.png\n",
      "./resources/images/CLAMP4/CHIP9_WIRE16_CLAMP_4.png\n",
      "./resources/images/CLAMP4/CHIP9_WIRE17_CLAMP_4.png\n",
      "./resources/images/CLAMP4/CHIP9_WIRE18_CLAMP_4.png\n",
      "./resources/images/CLAMP4/CHIP9_WIRE19_CLAMP_4.png\n",
      "./resources/images/CLAMP4/CHIP9_WIRE1_CLAMP_4.png\n",
      "./resources/images/CLAMP4/CHIP9_WIRE2_CLAMP_4.png\n",
      "./resources/images/CLAMP4/CHIP9_WIRE3_CLAMP_4.png\n",
      "./resources/images/CLAMP4/CHIP9_WIRE4_CLAMP_4.png\n",
      "./resources/images/CLAMP4/CHIP9_WIRE5_CLAMP_4.png\n",
      "./resources/images/CLAMP4/CHIP9_WIRE6_CLAMP_4.png\n",
      "./resources/images/CLAMP4/CHIP9_WIRE7_CLAMP_4.png\n",
      "./resources/images/CLAMP4/CHIP9_WIRE8_CLAMP_4.png\n",
      "./resources/images/CLAMP4/CHIP9_WIRE9_CLAMP_4.png\n",
      "./resources/images/CLAMP4\n",
      "CLAMP5\n",
      "./resources/images/CLAMP5/CHIP10_WIRE10_CLAMP_5.png\n",
      "./resources/images/CLAMP5/CHIP10_WIRE11_CLAMP_5.png\n",
      "./resources/images/CLAMP5/CHIP1_WIRE10_CLAMP_5.png\n",
      "./resources/images/CLAMP5/CHIP1_WIRE11_CLAMP_5.png\n",
      "./resources/images/CLAMP5/CHIP1_WIRE12_CLAMP_5.png\n",
      "./resources/images/CLAMP5/CHIP1_WIRE13_CLAMP_5.png\n",
      "./resources/images/CLAMP5/CHIP1_WIRE14_CLAMP_5.png\n",
      "./resources/images/CLAMP5/CHIP1_WIRE15_CLAMP_5.png\n",
      "./resources/images/CLAMP5/CHIP1_WIRE16_CLAMP_5.png\n",
      "./resources/images/CLAMP5/CHIP1_WIRE17_CLAMP_5.png\n",
      "./resources/images/CLAMP5/CHIP1_WIRE18_CLAMP_5.png\n",
      "./resources/images/CLAMP5/CHIP1_WIRE19_CLAMP_5.png\n",
      "./resources/images/CLAMP5/CHIP1_WIRE1_CLAMP_5.png\n",
      "./resources/images/CLAMP5/CHIP1_WIRE2_CLAMP_5.png\n",
      "./resources/images/CLAMP5/CHIP1_WIRE3_CLAMP_5.png\n",
      "./resources/images/CLAMP5/CHIP1_WIRE4_CLAMP_5.png\n",
      "./resources/images/CLAMP5/CHIP1_WIRE5_CLAMP_5.png\n",
      "./resources/images/CLAMP5/CHIP1_WIRE6_CLAMP_5.png\n",
      "./resources/images/CLAMP5/CHIP1_WIRE7_CLAMP_5.png\n",
      "./resources/images/CLAMP5/CHIP1_WIRE8_CLAMP_5.png\n",
      "./resources/images/CLAMP5/CHIP1_WIRE9_CLAMP_5.png\n",
      "./resources/images/CLAMP5/CHIP2_WIRE10_CLAMP_5.png\n",
      "./resources/images/CLAMP5/CHIP2_WIRE11_CLAMP_5.png\n",
      "./resources/images/CLAMP5/CHIP2_WIRE12_CLAMP_5.png\n",
      "./resources/images/CLAMP5/CHIP2_WIRE13_CLAMP_5.png\n",
      "./resources/images/CLAMP5/CHIP2_WIRE14_CLAMP_5.png\n",
      "./resources/images/CLAMP5/CHIP2_WIRE15_CLAMP_5.png\n",
      "./resources/images/CLAMP5/CHIP2_WIRE16_CLAMP_5.png\n",
      "./resources/images/CLAMP5/CHIP2_WIRE17_CLAMP_5.png\n",
      "./resources/images/CLAMP5/CHIP2_WIRE18_CLAMP_5.png\n",
      "./resources/images/CLAMP5/CHIP2_WIRE19_CLAMP_5.png\n",
      "./resources/images/CLAMP5/CHIP2_WIRE1_CLAMP_5.png\n",
      "./resources/images/CLAMP5/CHIP2_WIRE2_CLAMP_5.png\n",
      "./resources/images/CLAMP5/CHIP2_WIRE3_CLAMP_5.png\n",
      "./resources/images/CLAMP5/CHIP2_WIRE4_CLAMP_5.png\n",
      "./resources/images/CLAMP5/CHIP2_WIRE5_CLAMP_5.png\n",
      "./resources/images/CLAMP5/CHIP2_WIRE6_CLAMP_5.png\n",
      "./resources/images/CLAMP5/CHIP2_WIRE7_CLAMP_5.png\n",
      "./resources/images/CLAMP5/CHIP2_WIRE8_CLAMP_5.png\n",
      "./resources/images/CLAMP5/CHIP2_WIRE9_CLAMP_5.png\n",
      "./resources/images/CLAMP5/CHIP3_WIRE10_CLAMP_5.png\n",
      "./resources/images/CLAMP5/CHIP3_WIRE11_CLAMP_5.png\n",
      "./resources/images/CLAMP5/CHIP3_WIRE12_CLAMP_5.png\n",
      "./resources/images/CLAMP5/CHIP3_WIRE13_CLAMP_5.png\n",
      "./resources/images/CLAMP5/CHIP3_WIRE14_CLAMP_5.png\n",
      "./resources/images/CLAMP5/CHIP3_WIRE15_CLAMP_5.png\n",
      "./resources/images/CLAMP5/CHIP3_WIRE16_CLAMP_5.png\n",
      "./resources/images/CLAMP5/CHIP3_WIRE17_CLAMP_5.png\n",
      "./resources/images/CLAMP5/CHIP3_WIRE18_CLAMP_5.png\n",
      "./resources/images/CLAMP5/CHIP3_WIRE19_CLAMP_5.png\n",
      "./resources/images/CLAMP5/CHIP3_WIRE1_CLAMP_5.png\n",
      "./resources/images/CLAMP5/CHIP3_WIRE2_CLAMP_5.png\n",
      "./resources/images/CLAMP5/CHIP3_WIRE3_CLAMP_5.png\n",
      "./resources/images/CLAMP5/CHIP3_WIRE4_CLAMP_5.png\n",
      "./resources/images/CLAMP5/CHIP3_WIRE5_CLAMP_5.png\n",
      "./resources/images/CLAMP5/CHIP3_WIRE6_CLAMP_5.png\n",
      "./resources/images/CLAMP5/CHIP3_WIRE7_CLAMP_5.png\n",
      "./resources/images/CLAMP5/CHIP3_WIRE8_CLAMP_5.png\n",
      "./resources/images/CLAMP5/CHIP3_WIRE9_CLAMP_5.png\n",
      "./resources/images/CLAMP5/CHIP4_WIRE10_CLAMP_5.png\n",
      "./resources/images/CLAMP5/CHIP4_WIRE11_CLAMP_5.png\n",
      "./resources/images/CLAMP5/CHIP4_WIRE12_CLAMP_5.png\n",
      "./resources/images/CLAMP5/CHIP4_WIRE13_CLAMP_5.png\n",
      "./resources/images/CLAMP5/CHIP4_WIRE14_CLAMP_5.png\n",
      "./resources/images/CLAMP5/CHIP4_WIRE15_CLAMP_5.png\n",
      "./resources/images/CLAMP5/CHIP4_WIRE16_CLAMP_5.png\n",
      "./resources/images/CLAMP5/CHIP4_WIRE17_CLAMP_5.png\n",
      "./resources/images/CLAMP5/CHIP4_WIRE18_CLAMP_5.png\n",
      "./resources/images/CLAMP5/CHIP4_WIRE19_CLAMP_5.png\n",
      "./resources/images/CLAMP5/CHIP4_WIRE1_CLAMP_5.png\n",
      "./resources/images/CLAMP5/CHIP4_WIRE2_CLAMP_5.png\n",
      "./resources/images/CLAMP5/CHIP4_WIRE3_CLAMP_5.png\n",
      "./resources/images/CLAMP5/CHIP4_WIRE4_CLAMP_5.png\n",
      "./resources/images/CLAMP5/CHIP4_WIRE5_CLAMP_5.png\n",
      "./resources/images/CLAMP5/CHIP4_WIRE6_CLAMP_5.png\n",
      "./resources/images/CLAMP5/CHIP4_WIRE7_CLAMP_5.png\n",
      "./resources/images/CLAMP5/CHIP4_WIRE8_CLAMP_5.png\n",
      "./resources/images/CLAMP5/CHIP4_WIRE9_CLAMP_5.png\n",
      "./resources/images/CLAMP5/CHIP5_WIRE10_CLAMP_5.png\n",
      "./resources/images/CLAMP5/CHIP5_WIRE11_CLAMP_5.png\n",
      "./resources/images/CLAMP5/CHIP5_WIRE12_CLAMP_5.png\n",
      "./resources/images/CLAMP5/CHIP5_WIRE13_CLAMP_5.png\n",
      "./resources/images/CLAMP5/CHIP5_WIRE14_CLAMP_5.png\n",
      "./resources/images/CLAMP5/CHIP5_WIRE15_CLAMP_5.png\n",
      "./resources/images/CLAMP5/CHIP5_WIRE16_CLAMP_5.png\n",
      "./resources/images/CLAMP5/CHIP5_WIRE17_CLAMP_5.png\n",
      "./resources/images/CLAMP5/CHIP5_WIRE18_CLAMP_5.png\n",
      "./resources/images/CLAMP5/CHIP5_WIRE19_CLAMP_5.png\n",
      "./resources/images/CLAMP5/CHIP5_WIRE1_CLAMP_5.png\n",
      "./resources/images/CLAMP5/CHIP5_WIRE2_CLAMP_5.png\n",
      "./resources/images/CLAMP5/CHIP5_WIRE3_CLAMP_5.png\n",
      "./resources/images/CLAMP5/CHIP5_WIRE4_CLAMP_5.png\n",
      "./resources/images/CLAMP5/CHIP5_WIRE5_CLAMP_5.png\n",
      "./resources/images/CLAMP5/CHIP5_WIRE6_CLAMP_5.png\n",
      "./resources/images/CLAMP5/CHIP5_WIRE7_CLAMP_5.png\n",
      "./resources/images/CLAMP5/CHIP5_WIRE8_CLAMP_5.png\n",
      "./resources/images/CLAMP5/CHIP5_WIRE9_CLAMP_5.png\n",
      "./resources/images/CLAMP5/CHIP6_WIRE10_CLAMP_5.png\n",
      "./resources/images/CLAMP5/CHIP6_WIRE11_CLAMP_5.png\n",
      "./resources/images/CLAMP5/CHIP6_WIRE12_CLAMP_5.png\n",
      "./resources/images/CLAMP5/CHIP6_WIRE13_CLAMP_5.png\n",
      "./resources/images/CLAMP5/CHIP6_WIRE14_CLAMP_5.png\n",
      "./resources/images/CLAMP5/CHIP6_WIRE15_CLAMP_5.png\n",
      "./resources/images/CLAMP5/CHIP6_WIRE16_CLAMP_5.png\n",
      "./resources/images/CLAMP5/CHIP6_WIRE17_CLAMP_5.png\n",
      "./resources/images/CLAMP5/CHIP6_WIRE18_CLAMP_5.png\n",
      "./resources/images/CLAMP5/CHIP6_WIRE19_CLAMP_5.png\n",
      "./resources/images/CLAMP5/CHIP6_WIRE1_CLAMP_5.png\n",
      "./resources/images/CLAMP5/CHIP6_WIRE2_CLAMP_5.png\n",
      "./resources/images/CLAMP5/CHIP6_WIRE3_CLAMP_5.png\n",
      "./resources/images/CLAMP5/CHIP6_WIRE4_CLAMP_5.png\n",
      "./resources/images/CLAMP5/CHIP6_WIRE5_CLAMP_5.png\n",
      "./resources/images/CLAMP5/CHIP6_WIRE6_CLAMP_5.png\n",
      "./resources/images/CLAMP5/CHIP6_WIRE7_CLAMP_5.png\n",
      "./resources/images/CLAMP5/CHIP6_WIRE8_CLAMP_5.png\n",
      "./resources/images/CLAMP5/CHIP6_WIRE9_CLAMP_5.png\n",
      "./resources/images/CLAMP5/CHIP7_WIRE10_CLAMP_5.png\n",
      "./resources/images/CLAMP5/CHIP7_WIRE11_CLAMP_5.png\n",
      "./resources/images/CLAMP5/CHIP7_WIRE12_CLAMP_5.png\n",
      "./resources/images/CLAMP5/CHIP7_WIRE13_CLAMP_5.png\n",
      "./resources/images/CLAMP5/CHIP7_WIRE14_CLAMP_5.png\n",
      "./resources/images/CLAMP5/CHIP7_WIRE15_CLAMP_5.png\n",
      "./resources/images/CLAMP5/CHIP7_WIRE16_CLAMP_5.png\n",
      "./resources/images/CLAMP5/CHIP7_WIRE17_CLAMP_5.png\n",
      "./resources/images/CLAMP5/CHIP7_WIRE18_CLAMP_5.png\n",
      "./resources/images/CLAMP5/CHIP7_WIRE19_CLAMP_5.png\n",
      "./resources/images/CLAMP5/CHIP7_WIRE1_CLAMP_5.png\n",
      "./resources/images/CLAMP5/CHIP7_WIRE2_CLAMP_5.png\n",
      "./resources/images/CLAMP5/CHIP7_WIRE3_CLAMP_5.png\n",
      "./resources/images/CLAMP5/CHIP7_WIRE4_CLAMP_5.png\n",
      "./resources/images/CLAMP5/CHIP7_WIRE5_CLAMP_5.png\n",
      "./resources/images/CLAMP5/CHIP7_WIRE6_CLAMP_5.png\n",
      "./resources/images/CLAMP5/CHIP7_WIRE7_CLAMP_5.png\n",
      "./resources/images/CLAMP5/CHIP7_WIRE8_CLAMP_5.png\n",
      "./resources/images/CLAMP5/CHIP7_WIRE9_CLAMP_5.png\n",
      "./resources/images/CLAMP5/CHIP8_WIRE10_CLAMP_5.png\n",
      "./resources/images/CLAMP5/CHIP8_WIRE11_CLAMP_5.png\n",
      "./resources/images/CLAMP5/CHIP8_WIRE12_CLAMP_5.png\n",
      "./resources/images/CLAMP5/CHIP8_WIRE13_CLAMP_5.png\n",
      "./resources/images/CLAMP5/CHIP8_WIRE14_CLAMP_5.png\n",
      "./resources/images/CLAMP5/CHIP8_WIRE15_CLAMP_5.png\n",
      "./resources/images/CLAMP5/CHIP8_WIRE16_CLAMP_5.png\n",
      "./resources/images/CLAMP5/CHIP8_WIRE17_CLAMP_5.png\n",
      "./resources/images/CLAMP5/CHIP8_WIRE18_CLAMP_5.png\n",
      "./resources/images/CLAMP5/CHIP8_WIRE19_CLAMP_5.png\n",
      "./resources/images/CLAMP5/CHIP8_WIRE1_CLAMP_5.png\n",
      "./resources/images/CLAMP5/CHIP8_WIRE2_CLAMP_5.png\n",
      "./resources/images/CLAMP5/CHIP8_WIRE3_CLAMP_5.png\n",
      "./resources/images/CLAMP5/CHIP8_WIRE4_CLAMP_5.png\n",
      "./resources/images/CLAMP5/CHIP8_WIRE5_CLAMP_5.png\n",
      "./resources/images/CLAMP5/CHIP8_WIRE6_CLAMP_5.png\n",
      "./resources/images/CLAMP5/CHIP8_WIRE7_CLAMP_5.png\n",
      "./resources/images/CLAMP5/CHIP8_WIRE8_CLAMP_5.png\n",
      "./resources/images/CLAMP5/CHIP8_WIRE9_CLAMP_5.png\n",
      "./resources/images/CLAMP5/CHIP9_WIRE10_CLAMP_5.png\n",
      "./resources/images/CLAMP5/CHIP9_WIRE11_CLAMP_5.png\n",
      "./resources/images/CLAMP5/CHIP9_WIRE12_CLAMP_5.png\n",
      "./resources/images/CLAMP5/CHIP9_WIRE13_CLAMP_5.png\n",
      "./resources/images/CLAMP5/CHIP9_WIRE14_CLAMP_5.png\n",
      "./resources/images/CLAMP5/CHIP9_WIRE15_CLAMP_5.png\n",
      "./resources/images/CLAMP5/CHIP9_WIRE16_CLAMP_5.png\n",
      "./resources/images/CLAMP5/CHIP9_WIRE17_CLAMP_5.png\n",
      "./resources/images/CLAMP5/CHIP9_WIRE18_CLAMP_5.png\n",
      "./resources/images/CLAMP5/CHIP9_WIRE19_CLAMP_5.png\n",
      "./resources/images/CLAMP5/CHIP9_WIRE1_CLAMP_5.png\n",
      "./resources/images/CLAMP5/CHIP9_WIRE2_CLAMP_5.png\n",
      "./resources/images/CLAMP5/CHIP9_WIRE3_CLAMP_5.png\n",
      "./resources/images/CLAMP5/CHIP9_WIRE4_CLAMP_5.png\n",
      "./resources/images/CLAMP5/CHIP9_WIRE5_CLAMP_5.png\n",
      "./resources/images/CLAMP5/CHIP9_WIRE6_CLAMP_5.png\n",
      "./resources/images/CLAMP5/CHIP9_WIRE7_CLAMP_5.png\n",
      "./resources/images/CLAMP5/CHIP9_WIRE8_CLAMP_5.png\n",
      "./resources/images/CLAMP5/CHIP9_WIRE9_CLAMP_5.png\n",
      "./resources/images/CLAMP5\n",
      "CLAMP6\n",
      "./resources/images/CLAMP6/CHIP10_WIRE10_CLAMP_6.png\n",
      "./resources/images/CLAMP6/CHIP10_WIRE11_CLAMP_6.png\n",
      "./resources/images/CLAMP6/CHIP1_WIRE10_CLAMP_6.png\n",
      "./resources/images/CLAMP6/CHIP1_WIRE11_CLAMP_6.png\n",
      "./resources/images/CLAMP6/CHIP1_WIRE12_CLAMP_6.png\n",
      "./resources/images/CLAMP6/CHIP1_WIRE13_CLAMP_6.png\n",
      "./resources/images/CLAMP6/CHIP1_WIRE14_CLAMP_6.png\n",
      "./resources/images/CLAMP6/CHIP1_WIRE15_CLAMP_6.png\n",
      "./resources/images/CLAMP6/CHIP1_WIRE16_CLAMP_6.png\n",
      "./resources/images/CLAMP6/CHIP1_WIRE17_CLAMP_6.png\n",
      "./resources/images/CLAMP6/CHIP1_WIRE18_CLAMP_6.png\n",
      "./resources/images/CLAMP6/CHIP1_WIRE19_CLAMP_6.png\n",
      "./resources/images/CLAMP6/CHIP1_WIRE1_CLAMP_6.png\n",
      "./resources/images/CLAMP6/CHIP1_WIRE2_CLAMP_6.png\n",
      "./resources/images/CLAMP6/CHIP1_WIRE3_CLAMP_6.png\n",
      "./resources/images/CLAMP6/CHIP1_WIRE4_CLAMP_6.png\n",
      "./resources/images/CLAMP6/CHIP1_WIRE5_CLAMP_6.png\n",
      "./resources/images/CLAMP6/CHIP1_WIRE6_CLAMP_6.png\n",
      "./resources/images/CLAMP6/CHIP1_WIRE7_CLAMP_6.png\n",
      "./resources/images/CLAMP6/CHIP1_WIRE8_CLAMP_6.png\n",
      "./resources/images/CLAMP6/CHIP1_WIRE9_CLAMP_6.png\n",
      "./resources/images/CLAMP6/CHIP2_WIRE10_CLAMP_6.png\n",
      "./resources/images/CLAMP6/CHIP2_WIRE11_CLAMP_6.png\n",
      "./resources/images/CLAMP6/CHIP2_WIRE12_CLAMP_6.png\n",
      "./resources/images/CLAMP6/CHIP2_WIRE13_CLAMP_6.png\n",
      "./resources/images/CLAMP6/CHIP2_WIRE14_CLAMP_6.png\n",
      "./resources/images/CLAMP6/CHIP2_WIRE15_CLAMP_6.png\n",
      "./resources/images/CLAMP6/CHIP2_WIRE16_CLAMP_6.png\n",
      "./resources/images/CLAMP6/CHIP2_WIRE17_CLAMP_6.png\n",
      "./resources/images/CLAMP6/CHIP2_WIRE18_CLAMP_6.png\n",
      "./resources/images/CLAMP6/CHIP2_WIRE19_CLAMP_6.png\n",
      "./resources/images/CLAMP6/CHIP2_WIRE1_CLAMP_6.png\n",
      "./resources/images/CLAMP6/CHIP2_WIRE2_CLAMP_6.png\n",
      "./resources/images/CLAMP6/CHIP2_WIRE3_CLAMP_6.png\n",
      "./resources/images/CLAMP6/CHIP2_WIRE4_CLAMP_6.png\n",
      "./resources/images/CLAMP6/CHIP2_WIRE5_CLAMP_6.png\n",
      "./resources/images/CLAMP6/CHIP2_WIRE6_CLAMP_6.png\n",
      "./resources/images/CLAMP6/CHIP2_WIRE7_CLAMP_6.png\n",
      "./resources/images/CLAMP6/CHIP2_WIRE8_CLAMP_6.png\n",
      "./resources/images/CLAMP6/CHIP2_WIRE9_CLAMP_6.png\n",
      "./resources/images/CLAMP6/CHIP3_WIRE10_CLAMP_6.png\n",
      "./resources/images/CLAMP6/CHIP3_WIRE11_CLAMP_6.png\n",
      "./resources/images/CLAMP6/CHIP3_WIRE12_CLAMP_6.png\n",
      "./resources/images/CLAMP6/CHIP3_WIRE13_CLAMP_6.png\n",
      "./resources/images/CLAMP6/CHIP3_WIRE14_CLAMP_6.png\n",
      "./resources/images/CLAMP6/CHIP3_WIRE15_CLAMP_6.png\n",
      "./resources/images/CLAMP6/CHIP3_WIRE16_CLAMP_6.png\n",
      "./resources/images/CLAMP6/CHIP3_WIRE17_CLAMP_6.png\n",
      "./resources/images/CLAMP6/CHIP3_WIRE18_CLAMP_6.png\n",
      "./resources/images/CLAMP6/CHIP3_WIRE19_CLAMP_6.png\n",
      "./resources/images/CLAMP6/CHIP3_WIRE1_CLAMP_6.png\n",
      "./resources/images/CLAMP6/CHIP3_WIRE2_CLAMP_6.png\n",
      "./resources/images/CLAMP6/CHIP3_WIRE3_CLAMP_6.png\n",
      "./resources/images/CLAMP6/CHIP3_WIRE4_CLAMP_6.png\n",
      "./resources/images/CLAMP6/CHIP3_WIRE5_CLAMP_6.png\n",
      "./resources/images/CLAMP6/CHIP3_WIRE6_CLAMP_6.png\n",
      "./resources/images/CLAMP6/CHIP3_WIRE7_CLAMP_6.png\n",
      "./resources/images/CLAMP6/CHIP3_WIRE8_CLAMP_6.png\n",
      "./resources/images/CLAMP6/CHIP3_WIRE9_CLAMP_6.png\n",
      "./resources/images/CLAMP6/CHIP4_WIRE10_CLAMP_6.png\n",
      "./resources/images/CLAMP6/CHIP4_WIRE11_CLAMP_6.png\n",
      "./resources/images/CLAMP6/CHIP4_WIRE12_CLAMP_6.png\n",
      "./resources/images/CLAMP6/CHIP4_WIRE13_CLAMP_6.png\n",
      "./resources/images/CLAMP6/CHIP4_WIRE14_CLAMP_6.png\n",
      "./resources/images/CLAMP6/CHIP4_WIRE15_CLAMP_6.png\n",
      "./resources/images/CLAMP6/CHIP4_WIRE16_CLAMP_6.png\n",
      "./resources/images/CLAMP6/CHIP4_WIRE17_CLAMP_6.png\n",
      "./resources/images/CLAMP6/CHIP4_WIRE18_CLAMP_6.png\n",
      "./resources/images/CLAMP6/CHIP4_WIRE19_CLAMP_6.png\n",
      "./resources/images/CLAMP6/CHIP4_WIRE1_CLAMP_6.png\n",
      "./resources/images/CLAMP6/CHIP4_WIRE2_CLAMP_6.png\n",
      "./resources/images/CLAMP6/CHIP4_WIRE3_CLAMP_6.png\n",
      "./resources/images/CLAMP6/CHIP4_WIRE4_CLAMP_6.png\n",
      "./resources/images/CLAMP6/CHIP4_WIRE5_CLAMP_6.png\n",
      "./resources/images/CLAMP6/CHIP4_WIRE6_CLAMP_6.png\n",
      "./resources/images/CLAMP6/CHIP4_WIRE7_CLAMP_6.png\n",
      "./resources/images/CLAMP6/CHIP4_WIRE8_CLAMP_6.png\n",
      "./resources/images/CLAMP6/CHIP4_WIRE9_CLAMP_6.png\n",
      "./resources/images/CLAMP6/CHIP5_WIRE10_CLAMP_6.png\n",
      "./resources/images/CLAMP6/CHIP5_WIRE11_CLAMP_6.png\n",
      "./resources/images/CLAMP6/CHIP5_WIRE12_CLAMP_6.png\n",
      "./resources/images/CLAMP6/CHIP5_WIRE13_CLAMP_6.png\n",
      "./resources/images/CLAMP6/CHIP5_WIRE14_CLAMP_6.png\n",
      "./resources/images/CLAMP6/CHIP5_WIRE15_CLAMP_6.png\n",
      "./resources/images/CLAMP6/CHIP5_WIRE16_CLAMP_6.png\n",
      "./resources/images/CLAMP6/CHIP5_WIRE17_CLAMP_6.png\n",
      "./resources/images/CLAMP6/CHIP5_WIRE18_CLAMP_6.png\n",
      "./resources/images/CLAMP6/CHIP5_WIRE19_CLAMP_6.png\n",
      "./resources/images/CLAMP6/CHIP5_WIRE1_CLAMP_6.png\n",
      "./resources/images/CLAMP6/CHIP5_WIRE2_CLAMP_6.png\n",
      "./resources/images/CLAMP6/CHIP5_WIRE3_CLAMP_6.png\n",
      "./resources/images/CLAMP6/CHIP5_WIRE4_CLAMP_6.png\n",
      "./resources/images/CLAMP6/CHIP5_WIRE5_CLAMP_6.png\n",
      "./resources/images/CLAMP6/CHIP5_WIRE6_CLAMP_6.png\n",
      "./resources/images/CLAMP6/CHIP5_WIRE7_CLAMP_6.png\n",
      "./resources/images/CLAMP6/CHIP5_WIRE8_CLAMP_6.png\n",
      "./resources/images/CLAMP6/CHIP5_WIRE9_CLAMP_6.png\n",
      "./resources/images/CLAMP6/CHIP6_WIRE10_CLAMP_6.png\n",
      "./resources/images/CLAMP6/CHIP6_WIRE11_CLAMP_6.png\n",
      "./resources/images/CLAMP6/CHIP6_WIRE12_CLAMP_6.png\n",
      "./resources/images/CLAMP6/CHIP6_WIRE13_CLAMP_6.png\n",
      "./resources/images/CLAMP6/CHIP6_WIRE14_CLAMP_6.png\n",
      "./resources/images/CLAMP6/CHIP6_WIRE15_CLAMP_6.png\n",
      "./resources/images/CLAMP6/CHIP6_WIRE16_CLAMP_6.png\n",
      "./resources/images/CLAMP6/CHIP6_WIRE17_CLAMP_6.png\n",
      "./resources/images/CLAMP6/CHIP6_WIRE18_CLAMP_6.png\n",
      "./resources/images/CLAMP6/CHIP6_WIRE19_CLAMP_6.png\n",
      "./resources/images/CLAMP6/CHIP6_WIRE1_CLAMP_6.png\n",
      "./resources/images/CLAMP6/CHIP6_WIRE2_CLAMP_6.png\n",
      "./resources/images/CLAMP6/CHIP6_WIRE3_CLAMP_6.png\n",
      "./resources/images/CLAMP6/CHIP6_WIRE4_CLAMP_6.png\n",
      "./resources/images/CLAMP6/CHIP6_WIRE5_CLAMP_6.png\n",
      "./resources/images/CLAMP6/CHIP6_WIRE6_CLAMP_6.png\n",
      "./resources/images/CLAMP6/CHIP6_WIRE7_CLAMP_6.png\n",
      "./resources/images/CLAMP6/CHIP6_WIRE8_CLAMP_6.png\n",
      "./resources/images/CLAMP6/CHIP6_WIRE9_CLAMP_6.png\n",
      "./resources/images/CLAMP6/CHIP7_WIRE10_CLAMP_6.png\n",
      "./resources/images/CLAMP6/CHIP7_WIRE11_CLAMP_6.png\n",
      "./resources/images/CLAMP6/CHIP7_WIRE12_CLAMP_6.png\n",
      "./resources/images/CLAMP6/CHIP7_WIRE13_CLAMP_6.png\n",
      "./resources/images/CLAMP6/CHIP7_WIRE14_CLAMP_6.png\n",
      "./resources/images/CLAMP6/CHIP7_WIRE15_CLAMP_6.png\n",
      "./resources/images/CLAMP6/CHIP7_WIRE16_CLAMP_6.png\n",
      "./resources/images/CLAMP6/CHIP7_WIRE17_CLAMP_6.png\n",
      "./resources/images/CLAMP6/CHIP7_WIRE18_CLAMP_6.png\n",
      "./resources/images/CLAMP6/CHIP7_WIRE19_CLAMP_6.png\n",
      "./resources/images/CLAMP6/CHIP7_WIRE1_CLAMP_6.png\n",
      "./resources/images/CLAMP6/CHIP7_WIRE2_CLAMP_6.png\n",
      "./resources/images/CLAMP6/CHIP7_WIRE3_CLAMP_6.png\n",
      "./resources/images/CLAMP6/CHIP7_WIRE4_CLAMP_6.png\n",
      "./resources/images/CLAMP6/CHIP7_WIRE5_CLAMP_6.png\n",
      "./resources/images/CLAMP6/CHIP7_WIRE6_CLAMP_6.png\n",
      "./resources/images/CLAMP6/CHIP7_WIRE7_CLAMP_6.png\n",
      "./resources/images/CLAMP6/CHIP7_WIRE8_CLAMP_6.png\n",
      "./resources/images/CLAMP6/CHIP7_WIRE9_CLAMP_6.png\n",
      "./resources/images/CLAMP6/CHIP8_WIRE10_CLAMP_6.png\n",
      "./resources/images/CLAMP6/CHIP8_WIRE11_CLAMP_6.png\n",
      "./resources/images/CLAMP6/CHIP8_WIRE12_CLAMP_6.png\n",
      "./resources/images/CLAMP6/CHIP8_WIRE13_CLAMP_6.png\n",
      "./resources/images/CLAMP6/CHIP8_WIRE14_CLAMP_6.png\n",
      "./resources/images/CLAMP6/CHIP8_WIRE15_CLAMP_6.png\n",
      "./resources/images/CLAMP6/CHIP8_WIRE16_CLAMP_6.png\n",
      "./resources/images/CLAMP6/CHIP8_WIRE17_CLAMP_6.png\n",
      "./resources/images/CLAMP6/CHIP8_WIRE18_CLAMP_6.png\n",
      "./resources/images/CLAMP6/CHIP8_WIRE19_CLAMP_6.png\n",
      "./resources/images/CLAMP6/CHIP8_WIRE1_CLAMP_6.png\n",
      "./resources/images/CLAMP6/CHIP8_WIRE2_CLAMP_6.png\n",
      "./resources/images/CLAMP6/CHIP8_WIRE3_CLAMP_6.png\n",
      "./resources/images/CLAMP6/CHIP8_WIRE4_CLAMP_6.png\n",
      "./resources/images/CLAMP6/CHIP8_WIRE5_CLAMP_6.png\n",
      "./resources/images/CLAMP6/CHIP8_WIRE6_CLAMP_6.png\n",
      "./resources/images/CLAMP6/CHIP8_WIRE7_CLAMP_6.png\n",
      "./resources/images/CLAMP6/CHIP8_WIRE8_CLAMP_6.png\n",
      "./resources/images/CLAMP6/CHIP8_WIRE9_CLAMP_6.png\n",
      "./resources/images/CLAMP6/CHIP9_WIRE10_CLAMP_6.png\n",
      "./resources/images/CLAMP6/CHIP9_WIRE11_CLAMP_6.png\n",
      "./resources/images/CLAMP6/CHIP9_WIRE12_CLAMP_6.png\n",
      "./resources/images/CLAMP6/CHIP9_WIRE13_CLAMP_6.png\n",
      "./resources/images/CLAMP6/CHIP9_WIRE14_CLAMP_6.png\n",
      "./resources/images/CLAMP6/CHIP9_WIRE15_CLAMP_6.png\n",
      "./resources/images/CLAMP6/CHIP9_WIRE16_CLAMP_6.png\n",
      "./resources/images/CLAMP6/CHIP9_WIRE17_CLAMP_6.png\n",
      "./resources/images/CLAMP6/CHIP9_WIRE18_CLAMP_6.png\n",
      "./resources/images/CLAMP6/CHIP9_WIRE19_CLAMP_6.png\n",
      "./resources/images/CLAMP6/CHIP9_WIRE1_CLAMP_6.png\n",
      "./resources/images/CLAMP6/CHIP9_WIRE2_CLAMP_6.png\n",
      "./resources/images/CLAMP6/CHIP9_WIRE3_CLAMP_6.png\n",
      "./resources/images/CLAMP6/CHIP9_WIRE4_CLAMP_6.png\n",
      "./resources/images/CLAMP6/CHIP9_WIRE5_CLAMP_6.png\n",
      "./resources/images/CLAMP6/CHIP9_WIRE6_CLAMP_6.png\n",
      "./resources/images/CLAMP6/CHIP9_WIRE7_CLAMP_6.png\n",
      "./resources/images/CLAMP6/CHIP9_WIRE8_CLAMP_6.png\n",
      "./resources/images/CLAMP6/CHIP9_WIRE9_CLAMP_6.png\n",
      "./resources/images/CLAMP6\n"
     ]
    }
   ],
   "source": [
    "data_path = os.listdir(groups_folder_path)\n",
    "print(data_path)\n",
    "for filepath in data_path:\n",
    "    print(filepath)\n",
    "    filepath = groups_folder_path + filepath\n",
    "    file_path = os.listdir(filepath)\n",
    "    #print(file_path)\n",
    "    \n",
    "    for data in file_path:\n",
    "        path_file = filepath + '/' +data\n",
    "        print(path_file)\n",
    "        #print(data)\n",
    "        #img = img = image.load_img(path_file, target_size=(28, 28,1))\n",
    "        image = Image.open(path_file)\n",
    "        image = image.convert('L') #흑백으로 맹글기\n",
    "        image = image.resize((96,96))\n",
    "        img_data = np.array(image)\n",
    "        img_data = img_data.reshape((96,96,1))\n",
    "\n",
    "        ##img = cv2.resize(img, None, fx=image_w/img.shape[1], fy=image_h.shape[0])\n",
    "        #img_data = image.img_to_array(img)\n",
    "        #img_data = np.expand_dims(img_data, axis=0)\n",
    "        #img_data = preprocess_input(img_data)\n",
    "        X.append(np.array(img_data))\n",
    "\n",
    "        if '_CLAMP_1' in data:\n",
    "            Y.append(categories[0])\n",
    "        elif '_CLAMP_2' in data:\n",
    "            Y.append(categories[1])\n",
    "        elif '_CLAMP_3' in data:\n",
    "            Y.append(categories[2])\n",
    "        elif '_CLAMP_4' in data:\n",
    "            Y.append(categories[3])\n",
    "        elif '_CLAMP_5' in data:\n",
    "            Y.append(categories[4])\n",
    "        elif '_CLAMP_6' in data:\n",
    "            Y.append(categories[5])\n",
    "    print(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(X)\n",
    "Y = np.array(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1038, 96, 96, 1)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0' '0' '0' ... '5' '5' '5']\n"
     ]
    }
   ],
   "source": [
    "print(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\이원빈\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\numpy\\core\\_asarray.py:136: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  return array(a, dtype, copy=False, order=order, subok=True)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X,Y)\n",
    "xy = (X_train, X_test, Y_train, Y_test)\n",
    "\n",
    "np.save(\"./img_data.npy\", xy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dropout, Activation, Dense\n",
    "from keras.layers import Flatten, Convolution2D, MaxPooling2D\n",
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = np.load('./img_data.npy', allow_pickle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(260, 96, 96, 1)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#정규화\n",
    "X_train = X_train.astype('float32') / 255\n",
    "X_test = X_test.astype('float32') / 255\n",
    "\n",
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 96, 96, 16)        160       \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 96, 96, 16)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 48, 48, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 48, 48, 2)         290       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 48, 48, 2)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 24, 24, 2)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 24, 24, 2)         38        \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 24, 24, 2)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 12, 12, 2)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 12, 12, 2)         38        \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 12, 12, 2)         0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d (UpSampling2D) (None, 24, 24, 2)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 24, 24, 2)         38        \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 24, 24, 2)         0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2 (None, 48, 48, 2)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 48, 48, 16)        304       \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 48, 48, 16)        0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d_2 (UpSampling2 (None, 96, 96, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 96, 96, 1)         145       \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 96, 96, 1)         0         \n",
      "=================================================================\n",
      "Total params: 1,013\n",
      "Trainable params: 1,013\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.layers.convolutional import Conv2D, MaxPooling2D, UpSampling2D\n",
    "model = Sequential()\n",
    " \n",
    "#1st convolution layer\n",
    "model.add(Conv2D(16, (3, 3) #16 is number of filters and (3, 3) is the size of the filter.\n",
    ", padding='same', input_shape=(96,96,1)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2), padding='same'))\n",
    " \n",
    "#2nd convolution layer\n",
    "model.add(Conv2D(2,(3, 3), padding='same')) # apply 2 filters sized of (3x3)\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2), padding='same'))\n",
    "\n",
    "#3rd convolution layer\n",
    "model.add(Conv2D(2,(3, 3), padding='same')) # apply 2 filters sized of (3x3)\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2), padding='same'))\n",
    " \n",
    "#here compressed version\n",
    "\n",
    "#4th convolution layer\n",
    "model.add(Conv2D(2,(3, 3), padding='same')) # apply 2 filters sized of (3x3)\n",
    "model.add(Activation('relu'))\n",
    "model.add(UpSampling2D((2, 2)))\n",
    "\n",
    "#5th convolution layer\n",
    "model.add(Conv2D(2,(3, 3), padding='same')) # apply 2 filters sized of (3x3)\n",
    "model.add(Activation('relu'))\n",
    "model.add(UpSampling2D((2, 2)))\n",
    " \n",
    "#6th convolution layer\n",
    "model.add(Conv2D(16,(3, 3), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(UpSampling2D((2, 2)))\n",
    " \n",
    "model.add(Conv2D(1,(3, 3), padding='same'))\n",
    "model.add(Activation('sigmoid'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "25/25 [==============================] - 8s 274ms/step - loss: 0.6910 - val_loss: 0.6403\n",
      "Epoch 2/1000\n",
      "25/25 [==============================] - 6s 233ms/step - loss: 0.6102 - val_loss: 0.5043\n",
      "Epoch 3/1000\n",
      "25/25 [==============================] - 6s 248ms/step - loss: 0.4689 - val_loss: 0.3997\n",
      "Epoch 4/1000\n",
      "25/25 [==============================] - 6s 253ms/step - loss: 0.3953 - val_loss: 0.3967\n",
      "Epoch 5/1000\n",
      "25/25 [==============================] - 6s 260ms/step - loss: 0.3965 - val_loss: 0.3958\n",
      "Epoch 6/1000\n",
      "25/25 [==============================] - 6s 260ms/step - loss: 0.3947 - val_loss: 0.3958\n",
      "Epoch 7/1000\n",
      "25/25 [==============================] - 7s 266ms/step - loss: 0.3941 - val_loss: 0.3957\n",
      "Epoch 8/1000\n",
      "25/25 [==============================] - 7s 270ms/step - loss: 0.3943 - val_loss: 0.3956\n",
      "Epoch 9/1000\n",
      "25/25 [==============================] - 7s 268ms/step - loss: 0.3942 - val_loss: 0.3954\n",
      "Epoch 10/1000\n",
      "25/25 [==============================] - 7s 283ms/step - loss: 0.3931 - val_loss: 0.3953\n",
      "Epoch 11/1000\n",
      "25/25 [==============================] - 8s 322ms/step - loss: 0.3942 - val_loss: 0.3845\n",
      "Epoch 12/1000\n",
      "25/25 [==============================] - 8s 341ms/step - loss: 0.3725 - val_loss: 0.3489\n",
      "Epoch 13/1000\n",
      "25/25 [==============================] - 9s 372ms/step - loss: 0.3452 - val_loss: 0.3356\n",
      "Epoch 14/1000\n",
      "25/25 [==============================] - 10s 413ms/step - loss: 0.3319 - val_loss: 0.3201\n",
      "Epoch 15/1000\n",
      "25/25 [==============================] - 12s 492ms/step - loss: 0.3150 - val_loss: 0.3031\n",
      "Epoch 16/1000\n",
      "25/25 [==============================] - 18s 728ms/step - loss: 0.2988 - val_loss: 0.2883\n",
      "Epoch 17/1000\n",
      "25/25 [==============================] - 19s 770ms/step - loss: 0.2868 - val_loss: 0.2788\n",
      "Epoch 18/1000\n",
      "25/25 [==============================] - 11s 426ms/step - loss: 0.2770 - val_loss: 0.2713\n",
      "Epoch 19/1000\n",
      "25/25 [==============================] - 9s 345ms/step - loss: 0.2698 - val_loss: 0.2651\n",
      "Epoch 20/1000\n",
      "25/25 [==============================] - 8s 311ms/step - loss: 0.2637 - val_loss: 0.2557\n",
      "Epoch 21/1000\n",
      "25/25 [==============================] - 7s 296ms/step - loss: 0.2562 - val_loss: 0.2480\n",
      "Epoch 22/1000\n",
      "25/25 [==============================] - 7s 287ms/step - loss: 0.2461 - val_loss: 0.2408\n",
      "Epoch 23/1000\n",
      "25/25 [==============================] - 7s 295ms/step - loss: 0.2388 - val_loss: 0.2341\n",
      "Epoch 24/1000\n",
      "25/25 [==============================] - 8s 306ms/step - loss: 0.2321 - val_loss: 0.2282\n",
      "Epoch 25/1000\n",
      "25/25 [==============================] - 8s 324ms/step - loss: 0.2268 - val_loss: 0.2240\n",
      "Epoch 26/1000\n",
      "25/25 [==============================] - 9s 350ms/step - loss: 0.2227 - val_loss: 0.2200\n",
      "Epoch 27/1000\n",
      "25/25 [==============================] - 10s 390ms/step - loss: 0.2190 - val_loss: 0.2160\n",
      "Epoch 28/1000\n",
      "25/25 [==============================] - 11s 444ms/step - loss: 0.2153 - val_loss: 0.2130\n",
      "Epoch 29/1000\n",
      "25/25 [==============================] - 14s 575ms/step - loss: 0.2115 - val_loss: 0.2110\n",
      "Epoch 30/1000\n",
      "25/25 [==============================] - 17s 688ms/step - loss: 0.2095 - val_loss: 0.2082\n",
      "Epoch 31/1000\n",
      "25/25 [==============================] - 11s 433ms/step - loss: 0.2077 - val_loss: 0.2056\n",
      "Epoch 32/1000\n",
      "25/25 [==============================] - 9s 348ms/step - loss: 0.2045 - val_loss: 0.2037\n",
      "Epoch 33/1000\n",
      "25/25 [==============================] - 8s 307ms/step - loss: 0.2029 - val_loss: 0.2019\n",
      "Epoch 34/1000\n",
      "25/25 [==============================] - 7s 284ms/step - loss: 0.2015 - val_loss: 0.2002\n",
      "Epoch 35/1000\n",
      "25/25 [==============================] - 7s 275ms/step - loss: 0.2003 - val_loss: 0.1991\n",
      "Epoch 36/1000\n",
      "25/25 [==============================] - 7s 280ms/step - loss: 0.1984 - val_loss: 0.1974\n",
      "Epoch 37/1000\n",
      "25/25 [==============================] - 7s 290ms/step - loss: 0.1967 - val_loss: 0.1969\n",
      "Epoch 38/1000\n",
      "25/25 [==============================] - 7s 302ms/step - loss: 0.1955 - val_loss: 0.1948\n",
      "Epoch 39/1000\n",
      "25/25 [==============================] - 8s 330ms/step - loss: 0.1947 - val_loss: 0.1936\n",
      "Epoch 40/1000\n",
      "25/25 [==============================] - 9s 343ms/step - loss: 0.1935 - val_loss: 0.1928\n",
      "Epoch 41/1000\n",
      "25/25 [==============================] - 9s 371ms/step - loss: 0.1931 - val_loss: 0.1917\n",
      "Epoch 42/1000\n",
      "25/25 [==============================] - 10s 419ms/step - loss: 0.1912 - val_loss: 0.1908\n",
      "Epoch 43/1000\n",
      "25/25 [==============================] - 12s 497ms/step - loss: 0.1914 - val_loss: 0.1902\n",
      "Epoch 44/1000\n",
      "25/25 [==============================] - 17s 676ms/step - loss: 0.1903 - val_loss: 0.1891\n",
      "Epoch 45/1000\n",
      "25/25 [==============================] - 12s 469ms/step - loss: 0.1891 - val_loss: 0.1883\n",
      "Epoch 46/1000\n",
      "25/25 [==============================] - 9s 350ms/step - loss: 0.1879 - val_loss: 0.1876\n",
      "Epoch 47/1000\n",
      "25/25 [==============================] - 8s 310ms/step - loss: 0.1874 - val_loss: 0.1872\n",
      "Epoch 48/1000\n",
      "25/25 [==============================] - 7s 293ms/step - loss: 0.1869 - val_loss: 0.1877\n",
      "Epoch 49/1000\n",
      "25/25 [==============================] - 7s 277ms/step - loss: 0.1870 - val_loss: 0.1865\n",
      "Epoch 50/1000\n",
      "25/25 [==============================] - 7s 284ms/step - loss: 0.1860 - val_loss: 0.1853\n",
      "Epoch 51/1000\n",
      "25/25 [==============================] - 7s 294ms/step - loss: 0.1852 - val_loss: 0.1847\n",
      "Epoch 52/1000\n",
      "25/25 [==============================] - 8s 305ms/step - loss: 0.1848 - val_loss: 0.1843\n",
      "Epoch 53/1000\n",
      "25/25 [==============================] - 8s 326ms/step - loss: 0.1837 - val_loss: 0.1839\n",
      "Epoch 54/1000\n",
      "25/25 [==============================] - 9s 353ms/step - loss: 0.1835 - val_loss: 0.1833\n",
      "Epoch 55/1000\n",
      "25/25 [==============================] - 10s 392ms/step - loss: 0.1837 - val_loss: 0.1832\n",
      "Epoch 56/1000\n",
      "25/25 [==============================] - 11s 446ms/step - loss: 0.1835 - val_loss: 0.1828\n",
      "Epoch 57/1000\n",
      "25/25 [==============================] - 14s 567ms/step - loss: 0.1822 - val_loss: 0.1820\n",
      "Epoch 58/1000\n",
      "25/25 [==============================] - 14s 539ms/step - loss: 0.1820 - val_loss: 0.1826\n",
      "Epoch 59/1000\n",
      "25/25 [==============================] - 10s 385ms/step - loss: 0.1817 - val_loss: 0.1812\n",
      "Epoch 60/1000\n",
      "25/25 [==============================] - 8s 318ms/step - loss: 0.1813 - val_loss: 0.1810\n",
      "Epoch 61/1000\n",
      "25/25 [==============================] - 7s 289ms/step - loss: 0.1807 - val_loss: 0.1813\n",
      "Epoch 62/1000\n",
      "25/25 [==============================] - 7s 272ms/step - loss: 0.1812 - val_loss: 0.1802\n",
      "Epoch 63/1000\n",
      "25/25 [==============================] - 7s 275ms/step - loss: 0.1799 - val_loss: 0.1798\n",
      "Epoch 64/1000\n",
      "25/25 [==============================] - 7s 285ms/step - loss: 0.1798 - val_loss: 0.1796\n",
      "Epoch 65/1000\n",
      "25/25 [==============================] - 7s 295ms/step - loss: 0.1792 - val_loss: 0.1791\n",
      "Epoch 66/1000\n",
      "25/25 [==============================] - 8s 310ms/step - loss: 0.1783 - val_loss: 0.1789\n",
      "Epoch 67/1000\n",
      "25/25 [==============================] - 8s 325ms/step - loss: 0.1790 - val_loss: 0.1790\n",
      "Epoch 68/1000\n",
      "25/25 [==============================] - 9s 355ms/step - loss: 0.1787 - val_loss: 0.1785\n",
      "Epoch 69/1000\n",
      "25/25 [==============================] - 10s 392ms/step - loss: 0.1778 - val_loss: 0.1779\n",
      "Epoch 70/1000\n",
      "25/25 [==============================] - 11s 449ms/step - loss: 0.1778 - val_loss: 0.1775\n",
      "Epoch 71/1000\n",
      "25/25 [==============================] - 14s 556ms/step - loss: 0.1778 - val_loss: 0.1773\n",
      "Epoch 72/1000\n",
      "25/25 [==============================] - 16s 621ms/step - loss: 0.1764 - val_loss: 0.1770\n",
      "Epoch 73/1000\n",
      "25/25 [==============================] - 10s 396ms/step - loss: 0.1779 - val_loss: 0.1769\n",
      "Epoch 74/1000\n",
      "25/25 [==============================] - 8s 330ms/step - loss: 0.1760 - val_loss: 0.1765\n",
      "Epoch 75/1000\n",
      "25/25 [==============================] - 7s 294ms/step - loss: 0.1764 - val_loss: 0.1761\n",
      "Epoch 76/1000\n",
      "25/25 [==============================] - 7s 277ms/step - loss: 0.1765 - val_loss: 0.1761\n",
      "Epoch 77/1000\n",
      "25/25 [==============================] - 7s 278ms/step - loss: 0.1764 - val_loss: 0.1757\n",
      "Epoch 78/1000\n",
      "25/25 [==============================] - 7s 287ms/step - loss: 0.1759 - val_loss: 0.1759\n",
      "Epoch 79/1000\n",
      "25/25 [==============================] - 8s 307ms/step - loss: 0.1756 - val_loss: 0.1752\n",
      "Epoch 80/1000\n",
      "25/25 [==============================] - 8s 310ms/step - loss: 0.1755 - val_loss: 0.1749\n",
      "Epoch 81/1000\n",
      "25/25 [==============================] - 8s 333ms/step - loss: 0.1748 - val_loss: 0.1747\n",
      "Epoch 82/1000\n",
      "25/25 [==============================] - 9s 369ms/step - loss: 0.1745 - val_loss: 0.1753\n",
      "Epoch 83/1000\n",
      "25/25 [==============================] - 10s 403ms/step - loss: 0.1747 - val_loss: 0.1742\n",
      "Epoch 84/1000\n",
      "25/25 [==============================] - 12s 483ms/step - loss: 0.1743 - val_loss: 0.1749\n",
      "Epoch 85/1000\n",
      "25/25 [==============================] - 16s 642ms/step - loss: 0.1741 - val_loss: 0.1740\n",
      "Epoch 86/1000\n",
      "25/25 [==============================] - 13s 506ms/step - loss: 0.1739 - val_loss: 0.1753\n",
      "Epoch 87/1000\n",
      "25/25 [==============================] - 9s 366ms/step - loss: 0.1749 - val_loss: 0.1733\n",
      "Epoch 88/1000\n",
      "25/25 [==============================] - 8s 310ms/step - loss: 0.1734 - val_loss: 0.1734\n",
      "Epoch 89/1000\n",
      "25/25 [==============================] - 7s 287ms/step - loss: 0.1721 - val_loss: 0.1732\n",
      "Epoch 90/1000\n",
      "25/25 [==============================] - 7s 286ms/step - loss: 0.1732 - val_loss: 0.1726\n",
      "Epoch 91/1000\n",
      "25/25 [==============================] - 8s 322ms/step - loss: 0.1721 - val_loss: 0.1744\n",
      "Epoch 92/1000\n",
      "25/25 [==============================] - 10s 420ms/step - loss: 0.1727 - val_loss: 0.1741\n",
      "Epoch 93/1000\n",
      "25/25 [==============================] - 11s 424ms/step - loss: 0.1732 - val_loss: 0.1721\n",
      "Epoch 94/1000\n",
      "25/25 [==============================] - 12s 491ms/step - loss: 0.1718 - val_loss: 0.1718\n",
      "Epoch 95/1000\n",
      "25/25 [==============================] - 15s 590ms/step - loss: 0.1721 - val_loss: 0.1719\n",
      "Epoch 96/1000\n",
      "25/25 [==============================] - 17s 701ms/step - loss: 0.1720 - val_loss: 0.1718\n",
      "Epoch 97/1000\n",
      "25/25 [==============================] - 11s 455ms/step - loss: 0.1719 - val_loss: 0.1715\n",
      "Epoch 98/1000\n",
      "25/25 [==============================] - 9s 355ms/step - loss: 0.1706 - val_loss: 0.1710\n",
      "Epoch 99/1000\n",
      "25/25 [==============================] - 8s 309ms/step - loss: 0.1708 - val_loss: 0.1708\n",
      "Epoch 100/1000\n",
      "25/25 [==============================] - 8s 304ms/step - loss: 0.1706 - val_loss: 0.1711\n",
      "Epoch 101/1000\n",
      "25/25 [==============================] - 8s 327ms/step - loss: 0.1704 - val_loss: 0.1704\n",
      "Epoch 102/1000\n",
      "25/25 [==============================] - 8s 338ms/step - loss: 0.1700 - val_loss: 0.1711\n",
      "Epoch 103/1000\n",
      "25/25 [==============================] - 9s 365ms/step - loss: 0.1707 - val_loss: 0.1700\n",
      "Epoch 104/1000\n",
      "25/25 [==============================] - 10s 400ms/step - loss: 0.1702 - val_loss: 0.1699\n",
      "Epoch 105/1000\n",
      "25/25 [==============================] - 11s 461ms/step - loss: 0.1697 - val_loss: 0.1701\n",
      "Epoch 106/1000\n",
      "25/25 [==============================] - 14s 577ms/step - loss: 0.1694 - val_loss: 0.1695\n",
      "Epoch 107/1000\n",
      "25/25 [==============================] - 19s 746ms/step - loss: 0.1695 - val_loss: 0.1692\n",
      "Epoch 108/1000\n",
      "25/25 [==============================] - 12s 498ms/step - loss: 0.1699 - val_loss: 0.1691\n",
      "Epoch 109/1000\n",
      "25/25 [==============================] - 10s 387ms/step - loss: 0.1698 - val_loss: 0.1689\n",
      "Epoch 110/1000\n",
      "25/25 [==============================] - 8s 336ms/step - loss: 0.1694 - val_loss: 0.1687\n",
      "Epoch 111/1000\n",
      "25/25 [==============================] - 7s 276ms/step - loss: 0.1682 - val_loss: 0.1686\n",
      "Epoch 112/1000\n",
      "25/25 [==============================] - 7s 283ms/step - loss: 0.1684 - val_loss: 0.1682\n",
      "Epoch 113/1000\n",
      "25/25 [==============================] - 7s 295ms/step - loss: 0.1684 - val_loss: 0.1686\n",
      "Epoch 114/1000\n",
      "25/25 [==============================] - 8s 306ms/step - loss: 0.1681 - val_loss: 0.1685\n",
      "Epoch 115/1000\n",
      "25/25 [==============================] - 8s 324ms/step - loss: 0.1675 - val_loss: 0.1678\n",
      "Epoch 116/1000\n",
      "25/25 [==============================] - 9s 352ms/step - loss: 0.1678 - val_loss: 0.1677\n",
      "Epoch 117/1000\n",
      "25/25 [==============================] - 10s 392ms/step - loss: 0.1671 - val_loss: 0.1674\n",
      "Epoch 118/1000\n",
      "25/25 [==============================] - 11s 443ms/step - loss: 0.1670 - val_loss: 0.1671\n",
      "Epoch 119/1000\n",
      "25/25 [==============================] - 14s 557ms/step - loss: 0.1667 - val_loss: 0.1671\n",
      "Epoch 120/1000\n",
      "25/25 [==============================] - 17s 703ms/step - loss: 0.1666 - val_loss: 0.1670\n",
      "Epoch 121/1000\n",
      "25/25 [==============================] - 11s 430ms/step - loss: 0.1666 - val_loss: 0.1667\n",
      "Epoch 122/1000\n",
      "25/25 [==============================] - 9s 347ms/step - loss: 0.1654 - val_loss: 0.1663\n",
      "Epoch 123/1000\n",
      "25/25 [==============================] - 8s 302ms/step - loss: 0.1661 - val_loss: 0.1661\n",
      "Epoch 124/1000\n",
      "25/25 [==============================] - 7s 282ms/step - loss: 0.1663 - val_loss: 0.1661\n",
      "Epoch 125/1000\n",
      "25/25 [==============================] - 7s 281ms/step - loss: 0.1654 - val_loss: 0.1655\n",
      "Epoch 126/1000\n",
      "25/25 [==============================] - 7s 292ms/step - loss: 0.1656 - val_loss: 0.1653\n",
      "Epoch 127/1000\n",
      "25/25 [==============================] - 8s 303ms/step - loss: 0.1655 - val_loss: 0.1653\n",
      "Epoch 128/1000\n",
      "25/25 [==============================] - 8s 319ms/step - loss: 0.1653 - val_loss: 0.1649\n",
      "Epoch 129/1000\n",
      "25/25 [==============================] - 9s 348ms/step - loss: 0.1648 - val_loss: 0.1649\n",
      "Epoch 130/1000\n",
      "25/25 [==============================] - 11s 424ms/step - loss: 0.1649 - val_loss: 0.1653\n",
      "Epoch 131/1000\n",
      "25/25 [==============================] - 11s 435ms/step - loss: 0.1644 - val_loss: 0.1643\n",
      "Epoch 132/1000\n",
      "25/25 [==============================] - 13s 535ms/step - loss: 0.1639 - val_loss: 0.1642\n",
      "Epoch 133/1000\n",
      "25/25 [==============================] - 18s 745ms/step - loss: 0.1639 - val_loss: 0.1638\n",
      "Epoch 134/1000\n",
      "25/25 [==============================] - 11s 439ms/step - loss: 0.1642 - val_loss: 0.1644\n",
      "Epoch 135/1000\n",
      "25/25 [==============================] - 9s 347ms/step - loss: 0.1639 - val_loss: 0.1634\n",
      "Epoch 136/1000\n",
      "25/25 [==============================] - 8s 305ms/step - loss: 0.1627 - val_loss: 0.1631\n",
      "Epoch 137/1000\n",
      "25/25 [==============================] - 7s 282ms/step - loss: 0.1629 - val_loss: 0.1634\n",
      "Epoch 138/1000\n",
      "25/25 [==============================] - 7s 280ms/step - loss: 0.1633 - val_loss: 0.1628\n",
      "Epoch 139/1000\n",
      "25/25 [==============================] - 7s 292ms/step - loss: 0.1624 - val_loss: 0.1624\n",
      "Epoch 140/1000\n",
      "25/25 [==============================] - 8s 304ms/step - loss: 0.1619 - val_loss: 0.1622\n",
      "Epoch 141/1000\n",
      "25/25 [==============================] - 8s 320ms/step - loss: 0.1623 - val_loss: 0.1623\n",
      "Epoch 142/1000\n",
      "25/25 [==============================] - 9s 353ms/step - loss: 0.1624 - val_loss: 0.1619\n",
      "Epoch 143/1000\n",
      "25/25 [==============================] - 10s 387ms/step - loss: 0.1626 - val_loss: 0.1616\n",
      "Epoch 144/1000\n",
      "25/25 [==============================] - 11s 429ms/step - loss: 0.1616 - val_loss: 0.1614\n",
      "Epoch 145/1000\n",
      "25/25 [==============================] - 13s 536ms/step - loss: 0.1618 - val_loss: 0.1613\n",
      "Epoch 146/1000\n",
      "25/25 [==============================] - 19s 781ms/step - loss: 0.1614 - val_loss: 0.1611\n",
      "Epoch 147/1000\n",
      "25/25 [==============================] - 13s 504ms/step - loss: 0.1617 - val_loss: 0.1608\n",
      "Epoch 148/1000\n",
      "25/25 [==============================] - 9s 354ms/step - loss: 0.1610 - val_loss: 0.1606\n",
      "Epoch 149/1000\n",
      "25/25 [==============================] - 8s 309ms/step - loss: 0.1605 - val_loss: 0.1606\n",
      "Epoch 150/1000\n",
      "25/25 [==============================] - 7s 287ms/step - loss: 0.1605 - val_loss: 0.1608\n",
      "Epoch 151/1000\n",
      "25/25 [==============================] - 7s 293ms/step - loss: 0.1604 - val_loss: 0.1600\n",
      "Epoch 152/1000\n",
      "25/25 [==============================] - 8s 306ms/step - loss: 0.1594 - val_loss: 0.1599\n",
      "Epoch 153/1000\n",
      "25/25 [==============================] - 8s 324ms/step - loss: 0.1601 - val_loss: 0.1602\n",
      "Epoch 154/1000\n",
      "25/25 [==============================] - 9s 349ms/step - loss: 0.1592 - val_loss: 0.1595\n",
      "Epoch 155/1000\n",
      "25/25 [==============================] - 10s 388ms/step - loss: 0.1602 - val_loss: 0.1594\n",
      "Epoch 156/1000\n",
      "25/25 [==============================] - 11s 438ms/step - loss: 0.1600 - val_loss: 0.1596\n",
      "Epoch 157/1000\n",
      "25/25 [==============================] - 14s 559ms/step - loss: 0.1590 - val_loss: 0.1592\n",
      "Epoch 158/1000\n",
      "25/25 [==============================] - 18s 740ms/step - loss: 0.1593 - val_loss: 0.1594\n",
      "Epoch 159/1000\n",
      "25/25 [==============================] - 12s 470ms/step - loss: 0.1588 - val_loss: 0.1591\n",
      "Epoch 160/1000\n",
      "25/25 [==============================] - 9s 355ms/step - loss: 0.1584 - val_loss: 0.1587\n",
      "Epoch 161/1000\n",
      "25/25 [==============================] - 8s 317ms/step - loss: 0.1585 - val_loss: 0.1590\n",
      "Epoch 162/1000\n",
      "25/25 [==============================] - 7s 293ms/step - loss: 0.1587 - val_loss: 0.1590\n",
      "Epoch 163/1000\n",
      "25/25 [==============================] - 7s 284ms/step - loss: 0.1590 - val_loss: 0.1583\n",
      "Epoch 164/1000\n",
      "25/25 [==============================] - 7s 289ms/step - loss: 0.1584 - val_loss: 0.1588\n",
      "Epoch 165/1000\n",
      "25/25 [==============================] - 8s 307ms/step - loss: 0.1583 - val_loss: 0.1581\n",
      "Epoch 166/1000\n",
      "25/25 [==============================] - 8s 326ms/step - loss: 0.1577 - val_loss: 0.1579\n",
      "Epoch 167/1000\n",
      "25/25 [==============================] - 9s 348ms/step - loss: 0.1581 - val_loss: 0.1580\n",
      "Epoch 168/1000\n",
      "25/25 [==============================] - 9s 371ms/step - loss: 0.1578 - val_loss: 0.1578\n",
      "Epoch 169/1000\n",
      "25/25 [==============================] - 10s 417ms/step - loss: 0.1579 - val_loss: 0.1576\n",
      "Epoch 170/1000\n",
      "25/25 [==============================] - 13s 513ms/step - loss: 0.1571 - val_loss: 0.1576\n",
      "Epoch 171/1000\n",
      "25/25 [==============================] - 17s 698ms/step - loss: 0.1578 - val_loss: 0.1574\n",
      "Epoch 172/1000\n",
      "25/25 [==============================] - 11s 443ms/step - loss: 0.1575 - val_loss: 0.1584\n",
      "Epoch 173/1000\n",
      "25/25 [==============================] - 9s 341ms/step - loss: 0.1574 - val_loss: 0.1572\n",
      "Epoch 174/1000\n",
      "25/25 [==============================] - 8s 301ms/step - loss: 0.1569 - val_loss: 0.1571\n",
      "Epoch 175/1000\n",
      "25/25 [==============================] - 7s 281ms/step - loss: 0.1570 - val_loss: 0.1585\n",
      "Epoch 176/1000\n",
      "25/25 [==============================] - 7s 288ms/step - loss: 0.1571 - val_loss: 0.1571\n",
      "Epoch 177/1000\n",
      "25/25 [==============================] - 8s 305ms/step - loss: 0.1568 - val_loss: 0.1569\n",
      "Epoch 178/1000\n",
      "25/25 [==============================] - 8s 311ms/step - loss: 0.1563 - val_loss: 0.1567\n",
      "Epoch 179/1000\n",
      "25/25 [==============================] - 8s 331ms/step - loss: 0.1560 - val_loss: 0.1566\n",
      "Epoch 180/1000\n",
      "25/25 [==============================] - 9s 364ms/step - loss: 0.1561 - val_loss: 0.1568\n",
      "Epoch 181/1000\n",
      "25/25 [==============================] - 10s 403ms/step - loss: 0.1563 - val_loss: 0.1565\n",
      "Epoch 182/1000\n",
      "25/25 [==============================] - 14s 550ms/step - loss: 0.1559 - val_loss: 0.1563\n",
      "Epoch 183/1000\n",
      "25/25 [==============================] - 16s 646ms/step - loss: 0.1559 - val_loss: 0.1564\n",
      "Epoch 184/1000\n",
      "25/25 [==============================] - 12s 483ms/step - loss: 0.1566 - val_loss: 0.1562\n",
      "Epoch 185/1000\n",
      "25/25 [==============================] - 9s 362ms/step - loss: 0.1558 - val_loss: 0.1563\n",
      "Epoch 186/1000\n",
      "25/25 [==============================] - 8s 309ms/step - loss: 0.1566 - val_loss: 0.1562\n",
      "Epoch 187/1000\n",
      "25/25 [==============================] - 7s 297ms/step - loss: 0.1552 - val_loss: 0.1562\n",
      "Epoch 188/1000\n",
      "25/25 [==============================] - 7s 285ms/step - loss: 0.1559 - val_loss: 0.1561\n",
      "Epoch 189/1000\n",
      "25/25 [==============================] - 7s 288ms/step - loss: 0.1561 - val_loss: 0.1558\n",
      "Epoch 190/1000\n",
      "25/25 [==============================] - 7s 293ms/step - loss: 0.1557 - val_loss: 0.1562\n",
      "Epoch 191/1000\n",
      "25/25 [==============================] - 8s 305ms/step - loss: 0.1554 - val_loss: 0.1567\n",
      "Epoch 192/1000\n",
      "25/25 [==============================] - 8s 325ms/step - loss: 0.1559 - val_loss: 0.1566\n",
      "Epoch 193/1000\n",
      "25/25 [==============================] - 9s 353ms/step - loss: 0.1562 - val_loss: 0.1556\n",
      "Epoch 194/1000\n",
      "25/25 [==============================] - 10s 386ms/step - loss: 0.1556 - val_loss: 0.1566\n",
      "Epoch 195/1000\n",
      "25/25 [==============================] - 11s 452ms/step - loss: 0.1551 - val_loss: 0.1554\n",
      "Epoch 196/1000\n",
      "25/25 [==============================] - 14s 549ms/step - loss: 0.1556 - val_loss: 0.1554\n",
      "Epoch 197/1000\n",
      "25/25 [==============================] - 15s 623ms/step - loss: 0.1550 - val_loss: 0.1553\n",
      "Epoch 198/1000\n",
      "25/25 [==============================] - 10s 413ms/step - loss: 0.1546 - val_loss: 0.1556\n",
      "Epoch 199/1000\n",
      "25/25 [==============================] - 8s 334ms/step - loss: 0.1553 - val_loss: 0.1555\n",
      "Epoch 200/1000\n",
      "25/25 [==============================] - 7s 296ms/step - loss: 0.1552 - val_loss: 0.1550\n",
      "Epoch 201/1000\n",
      "25/25 [==============================] - 7s 277ms/step - loss: 0.1546 - val_loss: 0.1552\n",
      "Epoch 202/1000\n",
      "25/25 [==============================] - 7s 278ms/step - loss: 0.1547 - val_loss: 0.1553\n",
      "Epoch 203/1000\n",
      "25/25 [==============================] - 7s 288ms/step - loss: 0.1550 - val_loss: 0.1563\n",
      "Epoch 204/1000\n",
      "25/25 [==============================] - 8s 304ms/step - loss: 0.1551 - val_loss: 0.1549\n",
      "Epoch 205/1000\n",
      "25/25 [==============================] - 8s 312ms/step - loss: 0.1549 - val_loss: 0.1547\n",
      "Epoch 206/1000\n",
      "25/25 [==============================] - 8s 334ms/step - loss: 0.1542 - val_loss: 0.1546\n",
      "Epoch 207/1000\n",
      "25/25 [==============================] - 9s 362ms/step - loss: 0.1544 - val_loss: 0.1546\n",
      "Epoch 208/1000\n",
      "25/25 [==============================] - 10s 414ms/step - loss: 0.1547 - val_loss: 0.1545\n",
      "Epoch 209/1000\n",
      "25/25 [==============================] - 12s 476ms/step - loss: 0.1544 - val_loss: 0.1550\n",
      "Epoch 210/1000\n",
      "25/25 [==============================] - 16s 629ms/step - loss: 0.1545 - val_loss: 0.1557\n",
      "Epoch 211/1000\n",
      "25/25 [==============================] - 13s 516ms/step - loss: 0.1550 - val_loss: 0.1544\n",
      "Epoch 212/1000\n",
      "25/25 [==============================] - 9s 371ms/step - loss: 0.1536 - val_loss: 0.1542\n",
      "Epoch 213/1000\n",
      "25/25 [==============================] - 8s 316ms/step - loss: 0.1547 - val_loss: 0.1547\n",
      "Epoch 214/1000\n",
      "25/25 [==============================] - 7s 290ms/step - loss: 0.1545 - val_loss: 0.1543\n",
      "Epoch 215/1000\n",
      "25/25 [==============================] - 7s 284ms/step - loss: 0.1543 - val_loss: 0.1545\n",
      "Epoch 216/1000\n",
      "25/25 [==============================] - 7s 301ms/step - loss: 0.1550 - val_loss: 0.1542\n",
      "Epoch 217/1000\n",
      "25/25 [==============================] - 8s 319ms/step - loss: 0.1537 - val_loss: 0.1540\n",
      "Epoch 218/1000\n",
      "25/25 [==============================] - 8s 333ms/step - loss: 0.1544 - val_loss: 0.1539\n",
      "Epoch 219/1000\n",
      "25/25 [==============================] - 9s 362ms/step - loss: 0.1539 - val_loss: 0.1539\n",
      "Epoch 220/1000\n",
      "25/25 [==============================] - 10s 393ms/step - loss: 0.1535 - val_loss: 0.1543\n",
      "Epoch 221/1000\n",
      "25/25 [==============================] - 12s 465ms/step - loss: 0.1536 - val_loss: 0.1538\n",
      "Epoch 222/1000\n",
      "25/25 [==============================] - 14s 581ms/step - loss: 0.1537 - val_loss: 0.1538\n",
      "Epoch 223/1000\n",
      "25/25 [==============================] - 15s 599ms/step - loss: 0.1529 - val_loss: 0.1538\n",
      "Epoch 224/1000\n",
      "25/25 [==============================] - 11s 444ms/step - loss: 0.1536 - val_loss: 0.1536\n",
      "Epoch 225/1000\n",
      "25/25 [==============================] - 10s 394ms/step - loss: 0.1528 - val_loss: 0.1536\n",
      "Epoch 226/1000\n",
      "25/25 [==============================] - 8s 303ms/step - loss: 0.1535 - val_loss: 0.1536\n",
      "Epoch 227/1000\n",
      "25/25 [==============================] - 7s 275ms/step - loss: 0.1531 - val_loss: 0.1539\n",
      "Epoch 228/1000\n",
      "25/25 [==============================] - 8s 301ms/step - loss: 0.1534 - val_loss: 0.1546\n",
      "Epoch 229/1000\n",
      "25/25 [==============================] - 7s 296ms/step - loss: 0.1537 - val_loss: 0.1544\n",
      "Epoch 230/1000\n",
      "25/25 [==============================] - 8s 303ms/step - loss: 0.1540 - val_loss: 0.1538\n",
      "Epoch 231/1000\n",
      "25/25 [==============================] - 8s 323ms/step - loss: 0.1534 - val_loss: 0.1533\n",
      "Epoch 232/1000\n",
      "25/25 [==============================] - 10s 405ms/step - loss: 0.1527 - val_loss: 0.1533\n",
      "Epoch 233/1000\n",
      "25/25 [==============================] - 11s 461ms/step - loss: 0.1533 - val_loss: 0.1531\n",
      "Epoch 234/1000\n",
      "25/25 [==============================] - 11s 462ms/step - loss: 0.1534 - val_loss: 0.1530\n",
      "Epoch 235/1000\n",
      "25/25 [==============================] - 17s 702ms/step - loss: 0.1526 - val_loss: 0.1529\n",
      "Epoch 236/1000\n",
      "25/25 [==============================] - 12s 488ms/step - loss: 0.1537 - val_loss: 0.1530\n",
      "Epoch 237/1000\n",
      "25/25 [==============================] - 9s 361ms/step - loss: 0.1530 - val_loss: 0.1529\n",
      "Epoch 238/1000\n",
      "25/25 [==============================] - 8s 307ms/step - loss: 0.1526 - val_loss: 0.1530\n",
      "Epoch 239/1000\n",
      "25/25 [==============================] - 7s 284ms/step - loss: 0.1526 - val_loss: 0.1529\n",
      "Epoch 240/1000\n",
      "25/25 [==============================] - 7s 296ms/step - loss: 0.1532 - val_loss: 0.1529\n",
      "Epoch 241/1000\n",
      "25/25 [==============================] - 8s 316ms/step - loss: 0.1525 - val_loss: 0.1527\n",
      "Epoch 242/1000\n",
      "25/25 [==============================] - 8s 335ms/step - loss: 0.1525 - val_loss: 0.1526\n",
      "Epoch 243/1000\n",
      "25/25 [==============================] - 11s 453ms/step - loss: 0.1525 - val_loss: 0.1525\n",
      "Epoch 244/1000\n",
      "25/25 [==============================] - 10s 381ms/step - loss: 0.1527 - val_loss: 0.1525\n",
      "Epoch 245/1000\n",
      "25/25 [==============================] - 14s 578ms/step - loss: 0.1522 - val_loss: 0.1531\n",
      "Epoch 246/1000\n",
      "25/25 [==============================] - 23s 949ms/step - loss: 0.1523 - val_loss: 0.1529\n",
      "Epoch 247/1000\n",
      "25/25 [==============================] - 16s 629ms/step - loss: 0.1522 - val_loss: 0.1524\n",
      "Epoch 248/1000\n",
      "25/25 [==============================] - 10s 404ms/step - loss: 0.1525 - val_loss: 0.1527\n",
      "Epoch 249/1000\n",
      "25/25 [==============================] - 9s 376ms/step - loss: 0.1522 - val_loss: 0.1522\n",
      "Epoch 250/1000\n",
      "25/25 [==============================] - 8s 312ms/step - loss: 0.1514 - val_loss: 0.1522\n",
      "Epoch 251/1000\n",
      "25/25 [==============================] - 8s 300ms/step - loss: 0.1525 - val_loss: 0.1529\n",
      "Epoch 252/1000\n",
      "25/25 [==============================] - 8s 319ms/step - loss: 0.1522 - val_loss: 0.1522\n",
      "Epoch 253/1000\n",
      "25/25 [==============================] - 8s 321ms/step - loss: 0.1517 - val_loss: 0.1521\n",
      "Epoch 254/1000\n",
      "25/25 [==============================] - 9s 350ms/step - loss: 0.1520 - val_loss: 0.1528\n",
      "Epoch 255/1000\n",
      "25/25 [==============================] - 10s 388ms/step - loss: 0.1524 - val_loss: 0.1520\n",
      "Epoch 256/1000\n",
      "25/25 [==============================] - 11s 442ms/step - loss: 0.1517 - val_loss: 0.1520\n",
      "Epoch 257/1000\n",
      "25/25 [==============================] - 13s 536ms/step - loss: 0.1517 - val_loss: 0.1522\n",
      "Epoch 258/1000\n",
      "25/25 [==============================] - 26s 1s/step - loss: 0.1516 - val_loss: 0.1525\n",
      "Epoch 259/1000\n",
      "25/25 [==============================] - 14s 557ms/step - loss: 0.1522 - val_loss: 0.1523\n",
      "Epoch 260/1000\n",
      "25/25 [==============================] - 10s 379ms/step - loss: 0.1517 - val_loss: 0.1523\n",
      "Epoch 261/1000\n",
      "25/25 [==============================] - 7s 297ms/step - loss: 0.1521 - val_loss: 0.1518\n",
      "Epoch 262/1000\n",
      "25/25 [==============================] - 7s 281ms/step - loss: 0.1515 - val_loss: 0.1527\n",
      "Epoch 263/1000\n",
      "25/25 [==============================] - 7s 283ms/step - loss: 0.1521 - val_loss: 0.1515\n",
      "Epoch 264/1000\n",
      "25/25 [==============================] - 7s 292ms/step - loss: 0.1520 - val_loss: 0.1515\n",
      "Epoch 265/1000\n",
      "25/25 [==============================] - 8s 304ms/step - loss: 0.1509 - val_loss: 0.1515\n",
      "Epoch 266/1000\n",
      "25/25 [==============================] - 8s 325ms/step - loss: 0.1515 - val_loss: 0.1514\n",
      "Epoch 267/1000\n",
      "25/25 [==============================] - 9s 356ms/step - loss: 0.1515 - val_loss: 0.1516\n",
      "Epoch 268/1000\n",
      "25/25 [==============================] - 10s 400ms/step - loss: 0.1514 - val_loss: 0.1523\n",
      "Epoch 269/1000\n",
      "25/25 [==============================] - 11s 441ms/step - loss: 0.1509 - val_loss: 0.1518\n",
      "Epoch 270/1000\n",
      "25/25 [==============================] - 9s 371ms/step - loss: 0.1516 - val_loss: 0.1512\n",
      "Epoch 271/1000\n",
      "25/25 [==============================] - 8s 306ms/step - loss: 0.1509 - val_loss: 0.1511\n",
      "Epoch 272/1000\n",
      "25/25 [==============================] - 7s 285ms/step - loss: 0.1506 - val_loss: 0.1512\n",
      "Epoch 273/1000\n",
      "25/25 [==============================] - 7s 269ms/step - loss: 0.1505 - val_loss: 0.1510\n",
      "Epoch 274/1000\n",
      "25/25 [==============================] - 7s 273ms/step - loss: 0.1512 - val_loss: 0.1515\n",
      "Epoch 275/1000\n",
      "25/25 [==============================] - 7s 279ms/step - loss: 0.1508 - val_loss: 0.1515\n",
      "Epoch 276/1000\n",
      "25/25 [==============================] - 7s 288ms/step - loss: 0.1512 - val_loss: 0.1509\n",
      "Epoch 277/1000\n",
      "25/25 [==============================] - 8s 305ms/step - loss: 0.1512 - val_loss: 0.1508\n",
      "Epoch 278/1000\n",
      "25/25 [==============================] - 8s 318ms/step - loss: 0.1515 - val_loss: 0.1509\n",
      "Epoch 279/1000\n",
      "25/25 [==============================] - 8s 342ms/step - loss: 0.1507 - val_loss: 0.1507\n",
      "Epoch 280/1000\n",
      "25/25 [==============================] - 9s 376ms/step - loss: 0.1506 - val_loss: 0.1507\n",
      "Epoch 281/1000\n",
      "25/25 [==============================] - 11s 432ms/step - loss: 0.1502 - val_loss: 0.1506\n",
      "Epoch 282/1000\n",
      "25/25 [==============================] - 9s 351ms/step - loss: 0.1508 - val_loss: 0.1511\n",
      "Epoch 283/1000\n",
      "25/25 [==============================] - 8s 305ms/step - loss: 0.1507 - val_loss: 0.1505\n",
      "Epoch 284/1000\n",
      "25/25 [==============================] - 7s 281ms/step - loss: 0.1502 - val_loss: 0.1507\n",
      "Epoch 285/1000\n",
      "25/25 [==============================] - 7s 272ms/step - loss: 0.1511 - val_loss: 0.1507\n",
      "Epoch 286/1000\n",
      "25/25 [==============================] - 7s 277ms/step - loss: 0.1504 - val_loss: 0.1504\n",
      "Epoch 287/1000\n",
      "25/25 [==============================] - 7s 300ms/step - loss: 0.1505 - val_loss: 0.1511\n",
      "Epoch 288/1000\n",
      "25/25 [==============================] - 8s 302ms/step - loss: 0.1509 - val_loss: 0.1504\n",
      "Epoch 289/1000\n",
      "25/25 [==============================] - 8s 317ms/step - loss: 0.1499 - val_loss: 0.1505\n",
      "Epoch 290/1000\n",
      "25/25 [==============================] - 9s 368ms/step - loss: 0.1502 - val_loss: 0.1503\n",
      "Epoch 291/1000\n",
      "25/25 [==============================] - 10s 383ms/step - loss: 0.1499 - val_loss: 0.1512\n",
      "Epoch 292/1000\n",
      "25/25 [==============================] - 9s 340ms/step - loss: 0.1511 - val_loss: 0.1502\n",
      "Epoch 293/1000\n",
      "25/25 [==============================] - 7s 298ms/step - loss: 0.1496 - val_loss: 0.1502\n",
      "Epoch 294/1000\n",
      "25/25 [==============================] - 7s 279ms/step - loss: 0.1504 - val_loss: 0.1501\n",
      "Epoch 295/1000\n",
      "25/25 [==============================] - 7s 265ms/step - loss: 0.1495 - val_loss: 0.1502\n",
      "Epoch 296/1000\n",
      "25/25 [==============================] - 7s 276ms/step - loss: 0.1493 - val_loss: 0.1500\n",
      "Epoch 297/1000\n",
      "25/25 [==============================] - 7s 287ms/step - loss: 0.1494 - val_loss: 0.1510\n",
      "Epoch 298/1000\n",
      "25/25 [==============================] - 7s 296ms/step - loss: 0.1509 - val_loss: 0.1499\n",
      "Epoch 299/1000\n",
      "25/25 [==============================] - 8s 306ms/step - loss: 0.1506 - val_loss: 0.1498\n",
      "Epoch 300/1000\n",
      "25/25 [==============================] - 9s 343ms/step - loss: 0.1501 - val_loss: 0.1499\n",
      "Epoch 301/1000\n",
      "25/25 [==============================] - 9s 353ms/step - loss: 0.1488 - val_loss: 0.1500\n",
      "Epoch 302/1000\n",
      "25/25 [==============================] - 10s 387ms/step - loss: 0.1501 - val_loss: 0.1500\n",
      "Epoch 303/1000\n",
      "25/25 [==============================] - 8s 340ms/step - loss: 0.1501 - val_loss: 0.1497\n",
      "Epoch 304/1000\n",
      "25/25 [==============================] - 7s 301ms/step - loss: 0.1491 - val_loss: 0.1497\n",
      "Epoch 305/1000\n",
      "25/25 [==============================] - 7s 278ms/step - loss: 0.1497 - val_loss: 0.1497\n",
      "Epoch 306/1000\n",
      "25/25 [==============================] - 7s 270ms/step - loss: 0.1489 - val_loss: 0.1496\n",
      "Epoch 307/1000\n",
      "25/25 [==============================] - 7s 280ms/step - loss: 0.1494 - val_loss: 0.1496\n",
      "Epoch 308/1000\n",
      "25/25 [==============================] - 7s 288ms/step - loss: 0.1496 - val_loss: 0.1498\n",
      "Epoch 309/1000\n",
      "25/25 [==============================] - 7s 299ms/step - loss: 0.1495 - val_loss: 0.1499\n",
      "Epoch 310/1000\n",
      "25/25 [==============================] - 8s 313ms/step - loss: 0.1488 - val_loss: 0.1500\n",
      "Epoch 311/1000\n",
      "25/25 [==============================] - 8s 341ms/step - loss: 0.1497 - val_loss: 0.1496\n",
      "Epoch 312/1000\n",
      "25/25 [==============================] - 10s 383ms/step - loss: 0.1507 - val_loss: 0.1494\n",
      "Epoch 313/1000\n",
      "25/25 [==============================] - 8s 336ms/step - loss: 0.1493 - val_loss: 0.1494\n",
      "Epoch 314/1000\n",
      "25/25 [==============================] - 7s 297ms/step - loss: 0.1487 - val_loss: 0.1494\n",
      "Epoch 315/1000\n",
      "25/25 [==============================] - 7s 278ms/step - loss: 0.1493 - val_loss: 0.1494\n",
      "Epoch 316/1000\n",
      "25/25 [==============================] - 7s 276ms/step - loss: 0.1489 - val_loss: 0.1492\n",
      "Epoch 317/1000\n",
      "25/25 [==============================] - 7s 286ms/step - loss: 0.1489 - val_loss: 0.1500\n",
      "Epoch 318/1000\n",
      "25/25 [==============================] - 7s 295ms/step - loss: 0.1495 - val_loss: 0.1491\n",
      "Epoch 319/1000\n",
      "25/25 [==============================] - 8s 311ms/step - loss: 0.1485 - val_loss: 0.1502\n",
      "Epoch 320/1000\n",
      "25/25 [==============================] - 8s 335ms/step - loss: 0.1486 - val_loss: 0.1490\n",
      "Epoch 321/1000\n",
      "25/25 [==============================] - 9s 362ms/step - loss: 0.1496 - val_loss: 0.1492\n",
      "Epoch 322/1000\n",
      "25/25 [==============================] - 10s 383ms/step - loss: 0.1489 - val_loss: 0.1495\n",
      "Epoch 323/1000\n",
      "25/25 [==============================] - 8s 304ms/step - loss: 0.1497 - val_loss: 0.1509\n",
      "Epoch 324/1000\n",
      "25/25 [==============================] - 7s 281ms/step - loss: 0.1495 - val_loss: 0.1490\n",
      "Epoch 325/1000\n",
      "25/25 [==============================] - 7s 273ms/step - loss: 0.1487 - val_loss: 0.1489\n",
      "Epoch 326/1000\n",
      "25/25 [==============================] - 7s 284ms/step - loss: 0.1489 - val_loss: 0.1506\n",
      "Epoch 327/1000\n",
      "25/25 [==============================] - 7s 300ms/step - loss: 0.1488 - val_loss: 0.1488\n",
      "Epoch 328/1000\n",
      "25/25 [==============================] - 8s 317ms/step - loss: 0.1484 - val_loss: 0.1492\n",
      "Epoch 329/1000\n",
      "25/25 [==============================] - 8s 329ms/step - loss: 0.1480 - val_loss: 0.1487\n",
      "Epoch 330/1000\n",
      "25/25 [==============================] - 9s 357ms/step - loss: 0.1489 - val_loss: 0.1490\n",
      "Epoch 331/1000\n",
      "25/25 [==============================] - 10s 395ms/step - loss: 0.1482 - val_loss: 0.1487\n",
      "Epoch 332/1000\n",
      "25/25 [==============================] - 9s 345ms/step - loss: 0.1485 - val_loss: 0.1486\n",
      "Epoch 333/1000\n",
      "25/25 [==============================] - 8s 301ms/step - loss: 0.1488 - val_loss: 0.1485\n",
      "Epoch 334/1000\n",
      "25/25 [==============================] - 7s 266ms/step - loss: 0.1480 - val_loss: 0.1486\n",
      "Epoch 335/1000\n",
      "25/25 [==============================] - 7s 275ms/step - loss: 0.1480 - val_loss: 0.1487\n",
      "Epoch 336/1000\n",
      "25/25 [==============================] - 7s 280ms/step - loss: 0.1481 - val_loss: 0.1485\n",
      "Epoch 337/1000\n",
      "25/25 [==============================] - 7s 291ms/step - loss: 0.1478 - val_loss: 0.1492\n",
      "Epoch 338/1000\n",
      "25/25 [==============================] - 8s 311ms/step - loss: 0.1488 - val_loss: 0.1503\n",
      "Epoch 339/1000\n",
      "25/25 [==============================] - 8s 324ms/step - loss: 0.1487 - val_loss: 0.1487\n",
      "Epoch 340/1000\n",
      "25/25 [==============================] - 9s 346ms/step - loss: 0.1489 - val_loss: 0.1483\n",
      "Epoch 341/1000\n",
      "25/25 [==============================] - 9s 381ms/step - loss: 0.1478 - val_loss: 0.1484\n",
      "Epoch 342/1000\n",
      "25/25 [==============================] - 9s 353ms/step - loss: 0.1482 - val_loss: 0.1494\n",
      "Epoch 343/1000\n",
      "25/25 [==============================] - 8s 311ms/step - loss: 0.1480 - val_loss: 0.1485\n",
      "Epoch 344/1000\n",
      "25/25 [==============================] - 7s 281ms/step - loss: 0.1482 - val_loss: 0.1491\n",
      "Epoch 345/1000\n",
      "25/25 [==============================] - 7s 270ms/step - loss: 0.1488 - val_loss: 0.1487\n",
      "Epoch 346/1000\n",
      "25/25 [==============================] - 7s 278ms/step - loss: 0.1483 - val_loss: 0.1482\n",
      "Epoch 347/1000\n",
      "25/25 [==============================] - 7s 288ms/step - loss: 0.1481 - val_loss: 0.1481\n",
      "Epoch 348/1000\n",
      "25/25 [==============================] - 7s 298ms/step - loss: 0.1478 - val_loss: 0.1483\n",
      "Epoch 349/1000\n",
      "25/25 [==============================] - 8s 312ms/step - loss: 0.1474 - val_loss: 0.1481\n",
      "Epoch 350/1000\n",
      "25/25 [==============================] - 8s 333ms/step - loss: 0.1483 - val_loss: 0.1480\n",
      "Epoch 351/1000\n",
      "25/25 [==============================] - 9s 381ms/step - loss: 0.1474 - val_loss: 0.1482\n",
      "Epoch 352/1000\n",
      "25/25 [==============================] - 9s 375ms/step - loss: 0.1480 - val_loss: 0.1479\n",
      "Epoch 353/1000\n",
      "25/25 [==============================] - 8s 316ms/step - loss: 0.1475 - val_loss: 0.1479\n",
      "Epoch 354/1000\n",
      "25/25 [==============================] - 7s 289ms/step - loss: 0.1480 - val_loss: 0.1483\n",
      "Epoch 355/1000\n",
      "25/25 [==============================] - 7s 273ms/step - loss: 0.1475 - val_loss: 0.1481\n",
      "Epoch 356/1000\n",
      "25/25 [==============================] - 7s 275ms/step - loss: 0.1475 - val_loss: 0.1478\n",
      "Epoch 357/1000\n",
      "25/25 [==============================] - 7s 283ms/step - loss: 0.1477 - val_loss: 0.1478\n",
      "Epoch 358/1000\n",
      "25/25 [==============================] - 7s 296ms/step - loss: 0.1477 - val_loss: 0.1485\n",
      "Epoch 359/1000\n",
      "25/25 [==============================] - 8s 309ms/step - loss: 0.1478 - val_loss: 0.1477\n",
      "Epoch 360/1000\n",
      "25/25 [==============================] - 8s 326ms/step - loss: 0.1472 - val_loss: 0.1480\n",
      "Epoch 361/1000\n",
      "25/25 [==============================] - 9s 352ms/step - loss: 0.1482 - val_loss: 0.1476\n",
      "Epoch 362/1000\n",
      "25/25 [==============================] - 9s 370ms/step - loss: 0.1474 - val_loss: 0.1476\n",
      "Epoch 363/1000\n",
      "25/25 [==============================] - 8s 315ms/step - loss: 0.1472 - val_loss: 0.1481\n",
      "Epoch 364/1000\n",
      "25/25 [==============================] - 7s 288ms/step - loss: 0.1476 - val_loss: 0.1486\n",
      "Epoch 365/1000\n",
      "25/25 [==============================] - 7s 275ms/step - loss: 0.1470 - val_loss: 0.1475\n",
      "Epoch 366/1000\n",
      "25/25 [==============================] - 7s 281ms/step - loss: 0.1473 - val_loss: 0.1475\n",
      "Epoch 367/1000\n",
      "25/25 [==============================] - 7s 292ms/step - loss: 0.1470 - val_loss: 0.1475\n",
      "Epoch 368/1000\n",
      "25/25 [==============================] - 8s 302ms/step - loss: 0.1469 - val_loss: 0.1478\n",
      "Epoch 369/1000\n",
      "25/25 [==============================] - 8s 317ms/step - loss: 0.1469 - val_loss: 0.1474\n",
      "Epoch 370/1000\n",
      "25/25 [==============================] - 9s 344ms/step - loss: 0.1473 - val_loss: 0.1474\n",
      "Epoch 371/1000\n",
      "25/25 [==============================] - 9s 372ms/step - loss: 0.1473 - val_loss: 0.1474\n",
      "Epoch 372/1000\n",
      "25/25 [==============================] - 8s 329ms/step - loss: 0.1476 - val_loss: 0.1473\n",
      "Epoch 373/1000\n",
      "25/25 [==============================] - 7s 295ms/step - loss: 0.1469 - val_loss: 0.1473\n",
      "Epoch 374/1000\n",
      "25/25 [==============================] - 7s 281ms/step - loss: 0.1466 - val_loss: 0.1472\n",
      "Epoch 375/1000\n",
      "25/25 [==============================] - 7s 278ms/step - loss: 0.1472 - val_loss: 0.1473\n",
      "Epoch 376/1000\n",
      "25/25 [==============================] - 7s 286ms/step - loss: 0.1469 - val_loss: 0.1482\n",
      "Epoch 377/1000\n",
      "25/25 [==============================] - 8s 305ms/step - loss: 0.1476 - val_loss: 0.1472\n",
      "Epoch 378/1000\n",
      "25/25 [==============================] - 8s 314ms/step - loss: 0.1474 - val_loss: 0.1472\n",
      "Epoch 379/1000\n",
      "25/25 [==============================] - 8s 334ms/step - loss: 0.1468 - val_loss: 0.1472\n",
      "Epoch 380/1000\n",
      "25/25 [==============================] - 9s 367ms/step - loss: 0.1473 - val_loss: 0.1475\n",
      "Epoch 381/1000\n",
      "25/25 [==============================] - 9s 376ms/step - loss: 0.1473 - val_loss: 0.1471\n",
      "Epoch 382/1000\n",
      "25/25 [==============================] - 8s 321ms/step - loss: 0.1466 - val_loss: 0.1476\n",
      "Epoch 383/1000\n",
      "25/25 [==============================] - 7s 292ms/step - loss: 0.1472 - val_loss: 0.1472\n",
      "Epoch 384/1000\n",
      "25/25 [==============================] - 7s 272ms/step - loss: 0.1476 - val_loss: 0.1470\n",
      "Epoch 385/1000\n",
      "25/25 [==============================] - 7s 274ms/step - loss: 0.1475 - val_loss: 0.1470\n",
      "Epoch 386/1000\n",
      "25/25 [==============================] - 7s 283ms/step - loss: 0.1472 - val_loss: 0.1474\n",
      "Epoch 387/1000\n",
      "25/25 [==============================] - 7s 293ms/step - loss: 0.1471 - val_loss: 0.1469\n",
      "Epoch 388/1000\n",
      "25/25 [==============================] - 8s 306ms/step - loss: 0.1470 - val_loss: 0.1469\n",
      "Epoch 389/1000\n",
      "25/25 [==============================] - 8s 333ms/step - loss: 0.1463 - val_loss: 0.1468\n",
      "Epoch 390/1000\n",
      "25/25 [==============================] - 9s 358ms/step - loss: 0.1461 - val_loss: 0.1473\n",
      "Epoch 391/1000\n",
      "25/25 [==============================] - 10s 394ms/step - loss: 0.1471 - val_loss: 0.1468\n",
      "Epoch 392/1000\n",
      "25/25 [==============================] - 9s 364ms/step - loss: 0.1466 - val_loss: 0.1468\n",
      "Epoch 393/1000\n",
      "25/25 [==============================] - 8s 310ms/step - loss: 0.1467 - val_loss: 0.1468\n",
      "Epoch 394/1000\n",
      "25/25 [==============================] - 7s 291ms/step - loss: 0.1464 - val_loss: 0.1502\n",
      "Epoch 395/1000\n",
      "25/25 [==============================] - 7s 268ms/step - loss: 0.1483 - val_loss: 0.1467\n",
      "Epoch 396/1000\n",
      "25/25 [==============================] - 7s 270ms/step - loss: 0.1466 - val_loss: 0.1469\n",
      "Epoch 397/1000\n",
      "25/25 [==============================] - 7s 279ms/step - loss: 0.1468 - val_loss: 0.1466\n",
      "Epoch 398/1000\n",
      "25/25 [==============================] - 7s 290ms/step - loss: 0.1462 - val_loss: 0.1466\n",
      "Epoch 399/1000\n",
      "25/25 [==============================] - 7s 300ms/step - loss: 0.1461 - val_loss: 0.1471\n",
      "Epoch 400/1000\n",
      "25/25 [==============================] - 8s 315ms/step - loss: 0.1467 - val_loss: 0.1466\n",
      "Epoch 401/1000\n",
      "25/25 [==============================] - 8s 338ms/step - loss: 0.1466 - val_loss: 0.1466\n",
      "Epoch 402/1000\n",
      "25/25 [==============================] - 9s 373ms/step - loss: 0.1459 - val_loss: 0.1465\n",
      "Epoch 403/1000\n",
      "25/25 [==============================] - 10s 396ms/step - loss: 0.1456 - val_loss: 0.1466\n",
      "Epoch 404/1000\n",
      "25/25 [==============================] - 9s 341ms/step - loss: 0.1463 - val_loss: 0.1468\n",
      "Epoch 405/1000\n",
      "25/25 [==============================] - 7s 298ms/step - loss: 0.1466 - val_loss: 0.1465\n",
      "Epoch 406/1000\n",
      "25/25 [==============================] - 7s 277ms/step - loss: 0.1463 - val_loss: 0.1464\n",
      "Epoch 407/1000\n",
      "25/25 [==============================] - 7s 267ms/step - loss: 0.1471 - val_loss: 0.1472\n",
      "Epoch 408/1000\n",
      "25/25 [==============================] - 7s 275ms/step - loss: 0.1468 - val_loss: 0.1467\n",
      "Epoch 409/1000\n",
      "25/25 [==============================] - 7s 283ms/step - loss: 0.1459 - val_loss: 0.1463\n",
      "Epoch 410/1000\n",
      "25/25 [==============================] - 7s 293ms/step - loss: 0.1463 - val_loss: 0.1466\n",
      "Epoch 411/1000\n",
      "25/25 [==============================] - 8s 305ms/step - loss: 0.1458 - val_loss: 0.1480\n",
      "Epoch 412/1000\n",
      "25/25 [==============================] - 8s 324ms/step - loss: 0.1473 - val_loss: 0.1463\n",
      "Epoch 413/1000\n",
      "25/25 [==============================] - 9s 354ms/step - loss: 0.1461 - val_loss: 0.1462\n",
      "Epoch 414/1000\n",
      "25/25 [==============================] - 10s 392ms/step - loss: 0.1469 - val_loss: 0.1463\n",
      "Epoch 415/1000\n",
      "25/25 [==============================] - 10s 381ms/step - loss: 0.1462 - val_loss: 0.1464\n",
      "Epoch 416/1000\n",
      "25/25 [==============================] - 8s 311ms/step - loss: 0.1463 - val_loss: 0.1463\n",
      "Epoch 417/1000\n",
      "25/25 [==============================] - 7s 285ms/step - loss: 0.1459 - val_loss: 0.1465\n",
      "Epoch 418/1000\n",
      "25/25 [==============================] - 7s 273ms/step - loss: 0.1462 - val_loss: 0.1471\n",
      "Epoch 419/1000\n",
      "25/25 [==============================] - 7s 282ms/step - loss: 0.1460 - val_loss: 0.1469\n",
      "Epoch 420/1000\n",
      "25/25 [==============================] - 7s 294ms/step - loss: 0.1468 - val_loss: 0.1461\n",
      "Epoch 421/1000\n",
      "25/25 [==============================] - 8s 304ms/step - loss: 0.1457 - val_loss: 0.1467\n",
      "Epoch 422/1000\n",
      "25/25 [==============================] - 8s 322ms/step - loss: 0.1465 - val_loss: 0.1462\n",
      "Epoch 423/1000\n",
      "25/25 [==============================] - 9s 349ms/step - loss: 0.1456 - val_loss: 0.1460\n",
      "Epoch 424/1000\n",
      "25/25 [==============================] - 10s 382ms/step - loss: 0.1461 - val_loss: 0.1493\n",
      "Epoch 425/1000\n",
      "25/25 [==============================] - 9s 347ms/step - loss: 0.1473 - val_loss: 0.1462\n",
      "Epoch 426/1000\n",
      "25/25 [==============================] - 8s 303ms/step - loss: 0.1457 - val_loss: 0.1460\n",
      "Epoch 427/1000\n",
      "25/25 [==============================] - 7s 281ms/step - loss: 0.1461 - val_loss: 0.1461\n",
      "Epoch 428/1000\n",
      "25/25 [==============================] - 7s 268ms/step - loss: 0.1460 - val_loss: 0.1459\n",
      "Epoch 429/1000\n",
      "25/25 [==============================] - 7s 278ms/step - loss: 0.1456 - val_loss: 0.1459\n",
      "Epoch 430/1000\n",
      "25/25 [==============================] - 7s 288ms/step - loss: 0.1458 - val_loss: 0.1460\n",
      "Epoch 431/1000\n",
      "25/25 [==============================] - 7s 297ms/step - loss: 0.1460 - val_loss: 0.1468\n",
      "Epoch 432/1000\n",
      "25/25 [==============================] - 8s 312ms/step - loss: 0.1460 - val_loss: 0.1460\n",
      "Epoch 433/1000\n",
      "25/25 [==============================] - 8s 334ms/step - loss: 0.1455 - val_loss: 0.1465\n",
      "Epoch 434/1000\n",
      "25/25 [==============================] - 9s 365ms/step - loss: 0.1459 - val_loss: 0.1458\n",
      "Epoch 435/1000\n",
      "25/25 [==============================] - 10s 409ms/step - loss: 0.1454 - val_loss: 0.1461\n",
      "Epoch 436/1000\n",
      "25/25 [==============================] - 9s 342ms/step - loss: 0.1459 - val_loss: 0.1460\n",
      "Epoch 437/1000\n",
      "25/25 [==============================] - 7s 299ms/step - loss: 0.1455 - val_loss: 0.1457\n",
      "Epoch 438/1000\n",
      "25/25 [==============================] - 7s 278ms/step - loss: 0.1461 - val_loss: 0.1460\n",
      "Epoch 439/1000\n",
      "25/25 [==============================] - 7s 275ms/step - loss: 0.1460 - val_loss: 0.1459\n",
      "Epoch 440/1000\n",
      "25/25 [==============================] - 7s 285ms/step - loss: 0.1455 - val_loss: 0.1457\n",
      "Epoch 441/1000\n",
      "25/25 [==============================] - 7s 295ms/step - loss: 0.1455 - val_loss: 0.1457\n",
      "Epoch 442/1000\n",
      "25/25 [==============================] - 8s 308ms/step - loss: 0.1453 - val_loss: 0.1457\n",
      "Epoch 443/1000\n",
      "25/25 [==============================] - 9s 344ms/step - loss: 0.1449 - val_loss: 0.1456\n",
      "Epoch 444/1000\n",
      "25/25 [==============================] - 9s 363ms/step - loss: 0.1459 - val_loss: 0.1465\n",
      "Epoch 445/1000\n",
      "25/25 [==============================] - 9s 358ms/step - loss: 0.1452 - val_loss: 0.1469\n",
      "Epoch 446/1000\n",
      "25/25 [==============================] - 8s 307ms/step - loss: 0.1457 - val_loss: 0.1456\n",
      "Epoch 447/1000\n",
      "25/25 [==============================] - 7s 284ms/step - loss: 0.1456 - val_loss: 0.1468\n",
      "Epoch 448/1000\n",
      "25/25 [==============================] - 7s 272ms/step - loss: 0.1455 - val_loss: 0.1455\n",
      "Epoch 449/1000\n",
      "25/25 [==============================] - 7s 281ms/step - loss: 0.1454 - val_loss: 0.1455\n",
      "Epoch 450/1000\n",
      "25/25 [==============================] - 7s 296ms/step - loss: 0.1449 - val_loss: 0.1456\n",
      "Epoch 451/1000\n",
      "25/25 [==============================] - 8s 304ms/step - loss: 0.1449 - val_loss: 0.1455\n",
      "Epoch 452/1000\n",
      "25/25 [==============================] - 8s 328ms/step - loss: 0.1450 - val_loss: 0.1460\n",
      "Epoch 453/1000\n",
      "25/25 [==============================] - 9s 364ms/step - loss: 0.1456 - val_loss: 0.1458\n",
      "Epoch 454/1000\n",
      "25/25 [==============================] - 10s 404ms/step - loss: 0.1456 - val_loss: 0.1454\n",
      "Epoch 455/1000\n",
      "25/25 [==============================] - 9s 369ms/step - loss: 0.1446 - val_loss: 0.1455\n",
      "Epoch 456/1000\n",
      "25/25 [==============================] - 8s 311ms/step - loss: 0.1452 - val_loss: 0.1458\n",
      "Epoch 457/1000\n",
      "25/25 [==============================] - 7s 287ms/step - loss: 0.1448 - val_loss: 0.1453\n",
      "Epoch 458/1000\n",
      "25/25 [==============================] - 7s 274ms/step - loss: 0.1448 - val_loss: 0.1456\n",
      "Epoch 459/1000\n",
      "25/25 [==============================] - 7s 269ms/step - loss: 0.1448 - val_loss: 0.1453\n",
      "Epoch 460/1000\n",
      "25/25 [==============================] - 7s 282ms/step - loss: 0.1453 - val_loss: 0.1453\n",
      "Epoch 461/1000\n",
      "25/25 [==============================] - 7s 287ms/step - loss: 0.1452 - val_loss: 0.1457\n",
      "Epoch 462/1000\n",
      "25/25 [==============================] - 7s 299ms/step - loss: 0.1456 - val_loss: 0.1454\n",
      "Epoch 463/1000\n",
      "25/25 [==============================] - 8s 314ms/step - loss: 0.1446 - val_loss: 0.1452\n",
      "Epoch 464/1000\n",
      "25/25 [==============================] - 8s 336ms/step - loss: 0.1448 - val_loss: 0.1452\n",
      "Epoch 465/1000\n",
      "25/25 [==============================] - 9s 372ms/step - loss: 0.1444 - val_loss: 0.1457\n",
      "Epoch 466/1000\n",
      "25/25 [==============================] - 10s 419ms/step - loss: 0.1452 - val_loss: 0.1454\n",
      "Epoch 467/1000\n",
      "25/25 [==============================] - 9s 367ms/step - loss: 0.1458 - val_loss: 0.1452\n",
      "Epoch 468/1000\n",
      "25/25 [==============================] - 8s 309ms/step - loss: 0.1446 - val_loss: 0.1455\n",
      "Epoch 469/1000\n",
      "25/25 [==============================] - 7s 284ms/step - loss: 0.1456 - val_loss: 0.1451\n",
      "Epoch 470/1000\n",
      "25/25 [==============================] - 7s 270ms/step - loss: 0.1446 - val_loss: 0.1459\n",
      "Epoch 471/1000\n",
      "25/25 [==============================] - 7s 276ms/step - loss: 0.1454 - val_loss: 0.1452\n",
      "Epoch 472/1000\n",
      "25/25 [==============================] - 7s 285ms/step - loss: 0.1448 - val_loss: 0.1451\n",
      "Epoch 473/1000\n",
      "25/25 [==============================] - 7s 296ms/step - loss: 0.1446 - val_loss: 0.1460\n",
      "Epoch 474/1000\n",
      "25/25 [==============================] - 8s 307ms/step - loss: 0.1451 - val_loss: 0.1459\n",
      "Epoch 475/1000\n",
      "25/25 [==============================] - 8s 333ms/step - loss: 0.1453 - val_loss: 0.1451\n",
      "Epoch 476/1000\n",
      "25/25 [==============================] - 9s 359ms/step - loss: 0.1451 - val_loss: 0.1449\n",
      "Epoch 477/1000\n",
      "25/25 [==============================] - 10s 398ms/step - loss: 0.1444 - val_loss: 0.1452\n",
      "Epoch 478/1000\n",
      "25/25 [==============================] - 9s 356ms/step - loss: 0.1453 - val_loss: 0.1468\n",
      "Epoch 479/1000\n",
      "25/25 [==============================] - 8s 303ms/step - loss: 0.1452 - val_loss: 0.1455\n",
      "Epoch 480/1000\n",
      "25/25 [==============================] - 7s 286ms/step - loss: 0.1453 - val_loss: 0.1449\n",
      "Epoch 481/1000\n",
      "25/25 [==============================] - 7s 279ms/step - loss: 0.1449 - val_loss: 0.1453\n",
      "Epoch 482/1000\n",
      "25/25 [==============================] - 7s 293ms/step - loss: 0.1451 - val_loss: 0.1450\n",
      "Epoch 483/1000\n",
      "25/25 [==============================] - 8s 304ms/step - loss: 0.1442 - val_loss: 0.1449\n",
      "Epoch 484/1000\n",
      "25/25 [==============================] - 8s 311ms/step - loss: 0.1449 - val_loss: 0.1452\n",
      "Epoch 485/1000\n",
      "25/25 [==============================] - 8s 331ms/step - loss: 0.1447 - val_loss: 0.1449\n",
      "Epoch 486/1000\n",
      "25/25 [==============================] - 9s 353ms/step - loss: 0.1446 - val_loss: 0.1454\n",
      "Epoch 487/1000\n",
      "25/25 [==============================] - 10s 385ms/step - loss: 0.1452 - val_loss: 0.1450\n",
      "Epoch 488/1000\n",
      "25/25 [==============================] - 8s 332ms/step - loss: 0.1442 - val_loss: 0.1448\n",
      "Epoch 489/1000\n",
      "25/25 [==============================] - 7s 297ms/step - loss: 0.1444 - val_loss: 0.1468\n",
      "Epoch 490/1000\n",
      "25/25 [==============================] - 7s 278ms/step - loss: 0.1452 - val_loss: 0.1448\n",
      "Epoch 491/1000\n",
      "25/25 [==============================] - 7s 276ms/step - loss: 0.1442 - val_loss: 0.1449\n",
      "Epoch 492/1000\n",
      "25/25 [==============================] - 7s 281ms/step - loss: 0.1441 - val_loss: 0.1450\n",
      "Epoch 493/1000\n",
      "25/25 [==============================] - 7s 290ms/step - loss: 0.1444 - val_loss: 0.1451\n",
      "Epoch 494/1000\n",
      "25/25 [==============================] - 7s 301ms/step - loss: 0.1452 - val_loss: 0.1454\n",
      "Epoch 495/1000\n",
      "25/25 [==============================] - 8s 319ms/step - loss: 0.1445 - val_loss: 0.1450\n",
      "Epoch 496/1000\n",
      "25/25 [==============================] - 9s 350ms/step - loss: 0.1443 - val_loss: 0.1447\n",
      "Epoch 497/1000\n",
      "25/25 [==============================] - 10s 400ms/step - loss: 0.1446 - val_loss: 0.1447\n",
      "Epoch 498/1000\n",
      "25/25 [==============================] - 11s 425ms/step - loss: 0.1444 - val_loss: 0.1450\n",
      "Epoch 499/1000\n",
      "25/25 [==============================] - 9s 344ms/step - loss: 0.1442 - val_loss: 0.1448\n",
      "Epoch 500/1000\n",
      "25/25 [==============================] - 7s 300ms/step - loss: 0.1445 - val_loss: 0.1446\n",
      "Epoch 501/1000\n",
      "25/25 [==============================] - 7s 279ms/step - loss: 0.1450 - val_loss: 0.1446\n",
      "Epoch 502/1000\n",
      "25/25 [==============================] - 7s 269ms/step - loss: 0.1440 - val_loss: 0.1447\n",
      "Epoch 503/1000\n",
      "25/25 [==============================] - 7s 279ms/step - loss: 0.1441 - val_loss: 0.1446\n",
      "Epoch 504/1000\n",
      "25/25 [==============================] - 7s 288ms/step - loss: 0.1447 - val_loss: 0.1447\n",
      "Epoch 505/1000\n",
      "25/25 [==============================] - 7s 299ms/step - loss: 0.1451 - val_loss: 0.1460\n",
      "Epoch 506/1000\n",
      "25/25 [==============================] - 8s 317ms/step - loss: 0.1452 - val_loss: 0.1447\n",
      "Epoch 507/1000\n",
      "25/25 [==============================] - 8s 337ms/step - loss: 0.1443 - val_loss: 0.1446\n",
      "Epoch 508/1000\n",
      "25/25 [==============================] - 9s 371ms/step - loss: 0.1444 - val_loss: 0.1445\n",
      "Epoch 509/1000\n",
      "25/25 [==============================] - 10s 415ms/step - loss: 0.1437 - val_loss: 0.1448\n",
      "Epoch 510/1000\n",
      "25/25 [==============================] - 9s 370ms/step - loss: 0.1449 - val_loss: 0.1447\n",
      "Epoch 511/1000\n",
      "25/25 [==============================] - 8s 311ms/step - loss: 0.1443 - val_loss: 0.1446\n",
      "Epoch 512/1000\n",
      "25/25 [==============================] - 7s 286ms/step - loss: 0.1445 - val_loss: 0.1451\n",
      "Epoch 513/1000\n",
      "25/25 [==============================] - 7s 272ms/step - loss: 0.1443 - val_loss: 0.1444\n",
      "Epoch 514/1000\n",
      "25/25 [==============================] - 7s 277ms/step - loss: 0.1440 - val_loss: 0.1445\n",
      "Epoch 515/1000\n",
      "25/25 [==============================] - 8s 328ms/step - loss: 0.1440 - val_loss: 0.1446\n",
      "Epoch 516/1000\n",
      "25/25 [==============================] - 8s 329ms/step - loss: 0.1443 - val_loss: 0.1443\n",
      "Epoch 517/1000\n",
      "25/25 [==============================] - 8s 337ms/step - loss: 0.1439 - val_loss: 0.1446\n",
      "Epoch 518/1000\n",
      "25/25 [==============================] - 10s 405ms/step - loss: 0.1445 - val_loss: 0.1443\n",
      "Epoch 519/1000\n",
      "25/25 [==============================] - 9s 380ms/step - loss: 0.1436 - val_loss: 0.1447\n",
      "Epoch 520/1000\n",
      "25/25 [==============================] - 10s 395ms/step - loss: 0.1442 - val_loss: 0.1443\n",
      "Epoch 521/1000\n",
      "25/25 [==============================] - 8s 323ms/step - loss: 0.1437 - val_loss: 0.1450\n",
      "Epoch 522/1000\n",
      "25/25 [==============================] - 7s 292ms/step - loss: 0.1443 - val_loss: 0.1443\n",
      "Epoch 523/1000\n",
      "25/25 [==============================] - 7s 275ms/step - loss: 0.1442 - val_loss: 0.1443\n",
      "Epoch 524/1000\n",
      "25/25 [==============================] - 7s 266ms/step - loss: 0.1442 - val_loss: 0.1442\n",
      "Epoch 525/1000\n",
      "25/25 [==============================] - 7s 279ms/step - loss: 0.1434 - val_loss: 0.1449\n",
      "Epoch 526/1000\n",
      "25/25 [==============================] - 7s 285ms/step - loss: 0.1438 - val_loss: 0.1444\n",
      "Epoch 527/1000\n",
      "25/25 [==============================] - 7s 296ms/step - loss: 0.1436 - val_loss: 0.1451\n",
      "Epoch 528/1000\n",
      "25/25 [==============================] - 8s 314ms/step - loss: 0.1447 - val_loss: 0.1450\n",
      "Epoch 529/1000\n",
      "25/25 [==============================] - 8s 339ms/step - loss: 0.1441 - val_loss: 0.1451\n",
      "Epoch 530/1000\n",
      "25/25 [==============================] - 9s 368ms/step - loss: 0.1440 - val_loss: 0.1454\n",
      "Epoch 531/1000\n",
      "25/25 [==============================] - 10s 401ms/step - loss: 0.1438 - val_loss: 0.1448\n",
      "Epoch 532/1000\n",
      "25/25 [==============================] - 9s 351ms/step - loss: 0.1439 - val_loss: 0.1445\n",
      "Epoch 533/1000\n",
      "25/25 [==============================] - 8s 303ms/step - loss: 0.1443 - val_loss: 0.1442\n",
      "Epoch 534/1000\n",
      "25/25 [==============================] - 7s 282ms/step - loss: 0.1440 - val_loss: 0.1442\n",
      "Epoch 535/1000\n",
      "25/25 [==============================] - 7s 274ms/step - loss: 0.1441 - val_loss: 0.1441\n",
      "Epoch 536/1000\n",
      "25/25 [==============================] - 7s 285ms/step - loss: 0.1438 - val_loss: 0.1440\n",
      "Epoch 537/1000\n",
      "25/25 [==============================] - 7s 293ms/step - loss: 0.1442 - val_loss: 0.1442\n",
      "Epoch 538/1000\n",
      "25/25 [==============================] - 8s 305ms/step - loss: 0.1437 - val_loss: 0.1455\n",
      "Epoch 539/1000\n",
      "25/25 [==============================] - 8s 326ms/step - loss: 0.1445 - val_loss: 0.1443\n",
      "Epoch 540/1000\n",
      "25/25 [==============================] - 9s 354ms/step - loss: 0.1440 - val_loss: 0.1442\n",
      "Epoch 541/1000\n",
      "25/25 [==============================] - 9s 371ms/step - loss: 0.1442 - val_loss: 0.1441\n",
      "Epoch 542/1000\n",
      "25/25 [==============================] - 8s 314ms/step - loss: 0.1439 - val_loss: 0.1441\n",
      "Epoch 543/1000\n",
      "25/25 [==============================] - 7s 289ms/step - loss: 0.1438 - val_loss: 0.1441\n",
      "Epoch 544/1000\n",
      "25/25 [==============================] - 7s 274ms/step - loss: 0.1438 - val_loss: 0.1441\n",
      "Epoch 545/1000\n",
      "25/25 [==============================] - 7s 280ms/step - loss: 0.1441 - val_loss: 0.1440\n",
      "Epoch 546/1000\n",
      "25/25 [==============================] - 7s 290ms/step - loss: 0.1430 - val_loss: 0.1442\n",
      "Epoch 547/1000\n",
      "25/25 [==============================] - 7s 301ms/step - loss: 0.1439 - val_loss: 0.1442\n",
      "Epoch 548/1000\n",
      "25/25 [==============================] - 8s 322ms/step - loss: 0.1440 - val_loss: 0.1445\n",
      "Epoch 549/1000\n",
      "25/25 [==============================] - 9s 357ms/step - loss: 0.1438 - val_loss: 0.1446\n",
      "Epoch 550/1000\n",
      "25/25 [==============================] - 10s 383ms/step - loss: 0.1439 - val_loss: 0.1439\n",
      "Epoch 551/1000\n",
      "25/25 [==============================] - 9s 357ms/step - loss: 0.1436 - val_loss: 0.1445\n",
      "Epoch 552/1000\n",
      "25/25 [==============================] - 8s 306ms/step - loss: 0.1446 - val_loss: 0.1450\n",
      "Epoch 553/1000\n",
      "25/25 [==============================] - 7s 282ms/step - loss: 0.1443 - val_loss: 0.1439\n",
      "Epoch 554/1000\n",
      "25/25 [==============================] - 7s 269ms/step - loss: 0.1431 - val_loss: 0.1447\n",
      "Epoch 555/1000\n",
      "25/25 [==============================] - 7s 278ms/step - loss: 0.1435 - val_loss: 0.1438\n",
      "Epoch 556/1000\n",
      "25/25 [==============================] - 7s 291ms/step - loss: 0.1446 - val_loss: 0.1439\n",
      "Epoch 557/1000\n",
      "25/25 [==============================] - 8s 306ms/step - loss: 0.1436 - val_loss: 0.1439\n",
      "Epoch 558/1000\n",
      "25/25 [==============================] - 8s 313ms/step - loss: 0.1438 - val_loss: 0.1444\n",
      "Epoch 559/1000\n",
      "25/25 [==============================] - 8s 339ms/step - loss: 0.1436 - val_loss: 0.1439\n",
      "Epoch 560/1000\n",
      "25/25 [==============================] - 9s 368ms/step - loss: 0.1439 - val_loss: 0.1446\n",
      "Epoch 561/1000\n",
      "25/25 [==============================] - 9s 378ms/step - loss: 0.1444 - val_loss: 0.1438\n",
      "Epoch 562/1000\n",
      "25/25 [==============================] - 8s 316ms/step - loss: 0.1432 - val_loss: 0.1438\n",
      "Epoch 563/1000\n",
      "25/25 [==============================] - 7s 289ms/step - loss: 0.1434 - val_loss: 0.1437\n",
      "Epoch 564/1000\n",
      "25/25 [==============================] - 7s 279ms/step - loss: 0.1434 - val_loss: 0.1437\n",
      "Epoch 565/1000\n",
      "25/25 [==============================] - 7s 275ms/step - loss: 0.1429 - val_loss: 0.1439\n",
      "Epoch 566/1000\n",
      "25/25 [==============================] - 7s 284ms/step - loss: 0.1443 - val_loss: 0.1438\n",
      "Epoch 567/1000\n",
      "25/25 [==============================] - 8s 304ms/step - loss: 0.1433 - val_loss: 0.1437\n",
      "Epoch 568/1000\n",
      "25/25 [==============================] - 8s 316ms/step - loss: 0.1434 - val_loss: 0.1441\n",
      "Epoch 569/1000\n",
      "25/25 [==============================] - 9s 345ms/step - loss: 0.1435 - val_loss: 0.1438\n",
      "Epoch 570/1000\n",
      "25/25 [==============================] - 10s 384ms/step - loss: 0.1433 - val_loss: 0.1437\n",
      "Epoch 571/1000\n",
      "25/25 [==============================] - 11s 436ms/step - loss: 0.1436 - val_loss: 0.1436\n",
      "Epoch 572/1000\n",
      "25/25 [==============================] - 9s 361ms/step - loss: 0.1434 - val_loss: 0.1436\n",
      "Epoch 573/1000\n",
      "25/25 [==============================] - 8s 301ms/step - loss: 0.1430 - val_loss: 0.1436\n",
      "Epoch 574/1000\n",
      "25/25 [==============================] - 7s 283ms/step - loss: 0.1432 - val_loss: 0.1437\n",
      "Epoch 575/1000\n",
      "25/25 [==============================] - 7s 268ms/step - loss: 0.1433 - val_loss: 0.1436\n",
      "Epoch 576/1000\n",
      "25/25 [==============================] - 7s 272ms/step - loss: 0.1434 - val_loss: 0.1436\n",
      "Epoch 577/1000\n",
      "25/25 [==============================] - 7s 281ms/step - loss: 0.1437 - val_loss: 0.1440\n",
      "Epoch 578/1000\n",
      "25/25 [==============================] - 7s 290ms/step - loss: 0.1431 - val_loss: 0.1439\n",
      "Epoch 579/1000\n",
      "25/25 [==============================] - 8s 303ms/step - loss: 0.1432 - val_loss: 0.1440\n",
      "Epoch 580/1000\n",
      "25/25 [==============================] - 8s 320ms/step - loss: 0.1435 - val_loss: 0.1436\n",
      "Epoch 581/1000\n",
      "25/25 [==============================] - 9s 345ms/step - loss: 0.1431 - val_loss: 0.1445\n",
      "Epoch 582/1000\n",
      "25/25 [==============================] - 10s 386ms/step - loss: 0.1441 - val_loss: 0.1437\n",
      "Epoch 583/1000\n",
      "25/25 [==============================] - 10s 385ms/step - loss: 0.1434 - val_loss: 0.1442\n",
      "Epoch 584/1000\n",
      "25/25 [==============================] - 8s 320ms/step - loss: 0.1438 - val_loss: 0.1435\n",
      "Epoch 585/1000\n",
      "25/25 [==============================] - 7s 291ms/step - loss: 0.1438 - val_loss: 0.1434\n",
      "Epoch 586/1000\n",
      "25/25 [==============================] - 7s 276ms/step - loss: 0.1426 - val_loss: 0.1441\n",
      "Epoch 587/1000\n",
      "25/25 [==============================] - 7s 267ms/step - loss: 0.1430 - val_loss: 0.1434\n",
      "Epoch 588/1000\n",
      "25/25 [==============================] - 7s 276ms/step - loss: 0.1431 - val_loss: 0.1434\n",
      "Epoch 589/1000\n",
      "25/25 [==============================] - 7s 287ms/step - loss: 0.1439 - val_loss: 0.1437\n",
      "Epoch 590/1000\n",
      "25/25 [==============================] - 7s 300ms/step - loss: 0.1437 - val_loss: 0.1453\n",
      "Epoch 591/1000\n",
      "25/25 [==============================] - 8s 309ms/step - loss: 0.1436 - val_loss: 0.1435\n",
      "Epoch 592/1000\n",
      "25/25 [==============================] - 8s 330ms/step - loss: 0.1428 - val_loss: 0.1433\n",
      "Epoch 593/1000\n",
      "25/25 [==============================] - 9s 361ms/step - loss: 0.1429 - val_loss: 0.1440\n",
      "Epoch 594/1000\n",
      "25/25 [==============================] - 10s 399ms/step - loss: 0.1429 - val_loss: 0.1435\n",
      "Epoch 595/1000\n",
      "25/25 [==============================] - 9s 351ms/step - loss: 0.1427 - val_loss: 0.1434\n",
      "Epoch 596/1000\n",
      "25/25 [==============================] - 8s 304ms/step - loss: 0.1434 - val_loss: 0.1436\n",
      "Epoch 597/1000\n",
      "25/25 [==============================] - 7s 284ms/step - loss: 0.1431 - val_loss: 0.1444\n",
      "Epoch 598/1000\n",
      "25/25 [==============================] - 7s 267ms/step - loss: 0.1436 - val_loss: 0.1434\n",
      "Epoch 599/1000\n",
      "25/25 [==============================] - 7s 271ms/step - loss: 0.1434 - val_loss: 0.1436\n",
      "Epoch 600/1000\n",
      "25/25 [==============================] - 7s 279ms/step - loss: 0.1432 - val_loss: 0.1440\n",
      "Epoch 601/1000\n",
      "25/25 [==============================] - 7s 290ms/step - loss: 0.1436 - val_loss: 0.1437\n",
      "Epoch 602/1000\n",
      "25/25 [==============================] - 8s 306ms/step - loss: 0.1434 - val_loss: 0.1432\n",
      "Epoch 603/1000\n",
      "25/25 [==============================] - 8s 320ms/step - loss: 0.1427 - val_loss: 0.1432\n",
      "Epoch 604/1000\n",
      "25/25 [==============================] - 9s 342ms/step - loss: 0.1431 - val_loss: 0.1432\n",
      "Epoch 605/1000\n",
      "25/25 [==============================] - 10s 409ms/step - loss: 0.1432 - val_loss: 0.1431\n",
      "Epoch 606/1000\n",
      "25/25 [==============================] - 10s 386ms/step - loss: 0.1427 - val_loss: 0.1432\n",
      "Epoch 607/1000\n",
      "25/25 [==============================] - 8s 320ms/step - loss: 0.1435 - val_loss: 0.1435\n",
      "Epoch 608/1000\n",
      "25/25 [==============================] - 7s 292ms/step - loss: 0.1431 - val_loss: 0.1434\n",
      "Epoch 609/1000\n",
      "25/25 [==============================] - 7s 274ms/step - loss: 0.1427 - val_loss: 0.1435\n",
      "Epoch 610/1000\n",
      "25/25 [==============================] - 7s 268ms/step - loss: 0.1432 - val_loss: 0.1431\n",
      "Epoch 611/1000\n",
      "25/25 [==============================] - 7s 285ms/step - loss: 0.1424 - val_loss: 0.1432\n",
      "Epoch 612/1000\n",
      "25/25 [==============================] - 7s 289ms/step - loss: 0.1430 - val_loss: 0.1434\n",
      "Epoch 613/1000\n",
      "25/25 [==============================] - 8s 303ms/step - loss: 0.1428 - val_loss: 0.1438\n",
      "Epoch 614/1000\n",
      "25/25 [==============================] - 8s 312ms/step - loss: 0.1427 - val_loss: 0.1430\n",
      "Epoch 615/1000\n",
      "25/25 [==============================] - 8s 333ms/step - loss: 0.1427 - val_loss: 0.1432\n",
      "Epoch 616/1000\n",
      "25/25 [==============================] - 9s 361ms/step - loss: 0.1424 - val_loss: 0.1434\n",
      "Epoch 617/1000\n",
      "25/25 [==============================] - 10s 410ms/step - loss: 0.1427 - val_loss: 0.1433\n",
      "Epoch 618/1000\n",
      "25/25 [==============================] - 9s 357ms/step - loss: 0.1434 - val_loss: 0.1431\n",
      "Epoch 619/1000\n",
      "25/25 [==============================] - 8s 315ms/step - loss: 0.1440 - val_loss: 0.1432\n",
      "Epoch 620/1000\n",
      "25/25 [==============================] - 7s 289ms/step - loss: 0.1423 - val_loss: 0.1437\n",
      "Epoch 621/1000\n",
      "25/25 [==============================] - 7s 266ms/step - loss: 0.1432 - val_loss: 0.1430\n",
      "Epoch 622/1000\n",
      "25/25 [==============================] - 7s 275ms/step - loss: 0.1424 - val_loss: 0.1430\n",
      "Epoch 623/1000\n",
      "25/25 [==============================] - 7s 283ms/step - loss: 0.1426 - val_loss: 0.1430\n",
      "Epoch 624/1000\n",
      "25/25 [==============================] - 7s 291ms/step - loss: 0.1428 - val_loss: 0.1431\n",
      "Epoch 625/1000\n",
      "25/25 [==============================] - 8s 304ms/step - loss: 0.1429 - val_loss: 0.1430\n",
      "Epoch 626/1000\n",
      "25/25 [==============================] - 8s 321ms/step - loss: 0.1426 - val_loss: 0.1429\n",
      "Epoch 627/1000\n",
      "25/25 [==============================] - 9s 349ms/step - loss: 0.1427 - val_loss: 0.1429\n",
      "Epoch 628/1000\n",
      "25/25 [==============================] - 10s 391ms/step - loss: 0.1429 - val_loss: 0.1443\n",
      "Epoch 629/1000\n",
      "25/25 [==============================] - 9s 380ms/step - loss: 0.1438 - val_loss: 0.1450\n",
      "Epoch 630/1000\n",
      "25/25 [==============================] - 8s 317ms/step - loss: 0.1435 - val_loss: 0.1429\n",
      "Epoch 631/1000\n",
      "25/25 [==============================] - 7s 288ms/step - loss: 0.1427 - val_loss: 0.1431\n",
      "Epoch 632/1000\n",
      "25/25 [==============================] - 7s 274ms/step - loss: 0.1423 - val_loss: 0.1429\n",
      "Epoch 633/1000\n",
      "25/25 [==============================] - 7s 269ms/step - loss: 0.1427 - val_loss: 0.1432\n",
      "Epoch 634/1000\n",
      "25/25 [==============================] - 7s 277ms/step - loss: 0.1433 - val_loss: 0.1429\n",
      "Epoch 635/1000\n",
      "25/25 [==============================] - 7s 286ms/step - loss: 0.1417 - val_loss: 0.1428\n",
      "Epoch 636/1000\n",
      "25/25 [==============================] - 8s 302ms/step - loss: 0.1425 - val_loss: 0.1428\n",
      "Epoch 637/1000\n",
      "25/25 [==============================] - 8s 312ms/step - loss: 0.1427 - val_loss: 0.1444\n",
      "Epoch 638/1000\n",
      "25/25 [==============================] - 8s 332ms/step - loss: 0.1440 - val_loss: 0.1436\n",
      "Epoch 639/1000\n",
      "25/25 [==============================] - 9s 363ms/step - loss: 0.1428 - val_loss: 0.1435\n",
      "Epoch 640/1000\n",
      "25/25 [==============================] - 10s 400ms/step - loss: 0.1429 - val_loss: 0.1429\n",
      "Epoch 641/1000\n",
      "25/25 [==============================] - 9s 344ms/step - loss: 0.1418 - val_loss: 0.1429\n",
      "Epoch 642/1000\n",
      "25/25 [==============================] - 8s 307ms/step - loss: 0.1423 - val_loss: 0.1427\n",
      "Epoch 643/1000\n",
      "25/25 [==============================] - 7s 280ms/step - loss: 0.1431 - val_loss: 0.1430\n",
      "Epoch 644/1000\n",
      "25/25 [==============================] - 7s 270ms/step - loss: 0.1422 - val_loss: 0.1427\n",
      "Epoch 645/1000\n",
      "25/25 [==============================] - 7s 272ms/step - loss: 0.1426 - val_loss: 0.1431\n",
      "Epoch 646/1000\n",
      "25/25 [==============================] - 7s 281ms/step - loss: 0.1419 - val_loss: 0.1431\n",
      "Epoch 647/1000\n",
      "25/25 [==============================] - 7s 292ms/step - loss: 0.1431 - val_loss: 0.1440\n",
      "Epoch 648/1000\n",
      "25/25 [==============================] - 8s 308ms/step - loss: 0.1428 - val_loss: 0.1435\n",
      "Epoch 649/1000\n",
      "25/25 [==============================] - 8s 322ms/step - loss: 0.1432 - val_loss: 0.1428\n",
      "Epoch 650/1000\n",
      "25/25 [==============================] - 9s 349ms/step - loss: 0.1427 - val_loss: 0.1427\n",
      "Epoch 651/1000\n",
      "25/25 [==============================] - 10s 415ms/step - loss: 0.1422 - val_loss: 0.1427\n",
      "Epoch 652/1000\n",
      "25/25 [==============================] - 10s 398ms/step - loss: 0.1427 - val_loss: 0.1428\n",
      "Epoch 653/1000\n",
      "25/25 [==============================] - 8s 313ms/step - loss: 0.1423 - val_loss: 0.1428\n",
      "Epoch 654/1000\n",
      "25/25 [==============================] - 7s 287ms/step - loss: 0.1420 - val_loss: 0.1431\n",
      "Epoch 655/1000\n",
      "25/25 [==============================] - 7s 270ms/step - loss: 0.1431 - val_loss: 0.1427\n",
      "Epoch 656/1000\n",
      "25/25 [==============================] - 7s 270ms/step - loss: 0.1421 - val_loss: 0.1426\n",
      "Epoch 657/1000\n",
      "25/25 [==============================] - 7s 277ms/step - loss: 0.1423 - val_loss: 0.1426\n",
      "Epoch 658/1000\n",
      "25/25 [==============================] - 7s 289ms/step - loss: 0.1418 - val_loss: 0.1427\n",
      "Epoch 659/1000\n",
      "25/25 [==============================] - 7s 299ms/step - loss: 0.1416 - val_loss: 0.1438\n",
      "Epoch 660/1000\n",
      "25/25 [==============================] - 8s 314ms/step - loss: 0.1426 - val_loss: 0.1439\n",
      "Epoch 661/1000\n",
      "25/25 [==============================] - 8s 333ms/step - loss: 0.1429 - val_loss: 0.1432\n",
      "Epoch 662/1000\n",
      "25/25 [==============================] - 9s 368ms/step - loss: 0.1428 - val_loss: 0.1426\n",
      "Epoch 663/1000\n",
      "25/25 [==============================] - 10s 404ms/step - loss: 0.1424 - val_loss: 0.1425\n",
      "Epoch 664/1000\n",
      "25/25 [==============================] - 9s 339ms/step - loss: 0.1423 - val_loss: 0.1428\n",
      "Epoch 665/1000\n",
      "25/25 [==============================] - 7s 299ms/step - loss: 0.1419 - val_loss: 0.1426\n",
      "Epoch 666/1000\n",
      "25/25 [==============================] - 7s 278ms/step - loss: 0.1422 - val_loss: 0.1432\n",
      "Epoch 667/1000\n",
      "25/25 [==============================] - 7s 277ms/step - loss: 0.1421 - val_loss: 0.1436\n",
      "Epoch 668/1000\n",
      "25/25 [==============================] - 7s 285ms/step - loss: 0.1428 - val_loss: 0.1428\n",
      "Epoch 669/1000\n",
      "25/25 [==============================] - 7s 295ms/step - loss: 0.1424 - val_loss: 0.1425\n",
      "Epoch 670/1000\n",
      "25/25 [==============================] - 8s 307ms/step - loss: 0.1417 - val_loss: 0.1436\n",
      "Epoch 671/1000\n",
      "25/25 [==============================] - 9s 361ms/step - loss: 0.1426 - val_loss: 0.1425\n",
      "Epoch 672/1000\n",
      "25/25 [==============================] - 9s 364ms/step - loss: 0.1425 - val_loss: 0.1429\n",
      "Epoch 673/1000\n",
      "25/25 [==============================] - 9s 355ms/step - loss: 0.1426 - val_loss: 0.1424\n",
      "Epoch 674/1000\n",
      "25/25 [==============================] - 8s 304ms/step - loss: 0.1422 - val_loss: 0.1425\n",
      "Epoch 675/1000\n",
      "25/25 [==============================] - 7s 285ms/step - loss: 0.1423 - val_loss: 0.1425\n",
      "Epoch 676/1000\n",
      "25/25 [==============================] - 7s 272ms/step - loss: 0.1422 - val_loss: 0.1428\n",
      "Epoch 677/1000\n",
      "25/25 [==============================] - 7s 282ms/step - loss: 0.1423 - val_loss: 0.1424\n",
      "Epoch 678/1000\n",
      "25/25 [==============================] - 7s 297ms/step - loss: 0.1421 - val_loss: 0.1431\n",
      "Epoch 679/1000\n",
      "25/25 [==============================] - 8s 306ms/step - loss: 0.1432 - val_loss: 0.1428\n",
      "Epoch 680/1000\n",
      "25/25 [==============================] - 8s 327ms/step - loss: 0.1416 - val_loss: 0.1424\n",
      "Epoch 681/1000\n",
      "25/25 [==============================] - 9s 364ms/step - loss: 0.1434 - val_loss: 0.1462\n",
      "Epoch 682/1000\n",
      "25/25 [==============================] - 10s 392ms/step - loss: 0.1430 - val_loss: 0.1427\n",
      "Epoch 683/1000\n",
      "25/25 [==============================] - 8s 338ms/step - loss: 0.1418 - val_loss: 0.1426\n",
      "Epoch 684/1000\n",
      "25/25 [==============================] - 8s 309ms/step - loss: 0.1424 - val_loss: 0.1426\n",
      "Epoch 685/1000\n",
      "25/25 [==============================] - 7s 290ms/step - loss: 0.1423 - val_loss: 0.1425\n",
      "Epoch 686/1000\n",
      "25/25 [==============================] - 7s 293ms/step - loss: 0.1426 - val_loss: 0.1432\n",
      "Epoch 687/1000\n",
      "25/25 [==============================] - 7s 300ms/step - loss: 0.1422 - val_loss: 0.1424\n",
      "Epoch 688/1000\n",
      "25/25 [==============================] - 8s 318ms/step - loss: 0.1418 - val_loss: 0.1427\n",
      "Epoch 689/1000\n",
      "25/25 [==============================] - 8s 317ms/step - loss: 0.1419 - val_loss: 0.1436\n",
      "Epoch 690/1000\n",
      "25/25 [==============================] - 8s 329ms/step - loss: 0.1431 - val_loss: 0.1423\n",
      "Epoch 691/1000\n",
      "25/25 [==============================] - 9s 352ms/step - loss: 0.1416 - val_loss: 0.1431\n",
      "Epoch 692/1000\n",
      "25/25 [==============================] - 10s 390ms/step - loss: 0.1424 - val_loss: 0.1431\n",
      "Epoch 693/1000\n",
      "25/25 [==============================] - 11s 438ms/step - loss: 0.1432 - val_loss: 0.1423\n",
      "Epoch 694/1000\n",
      "25/25 [==============================] - 9s 356ms/step - loss: 0.1418 - val_loss: 0.1423\n",
      "Epoch 695/1000\n",
      "25/25 [==============================] - 8s 304ms/step - loss: 0.1425 - val_loss: 0.1425\n",
      "Epoch 696/1000\n",
      "25/25 [==============================] - 7s 284ms/step - loss: 0.1423 - val_loss: 0.1422\n",
      "Epoch 697/1000\n",
      "25/25 [==============================] - 7s 268ms/step - loss: 0.1421 - val_loss: 0.1423\n",
      "Epoch 698/1000\n",
      "25/25 [==============================] - 7s 270ms/step - loss: 0.1421 - val_loss: 0.1425\n",
      "Epoch 699/1000\n",
      "25/25 [==============================] - 7s 278ms/step - loss: 0.1423 - val_loss: 0.1422\n",
      "Epoch 700/1000\n",
      "25/25 [==============================] - 7s 288ms/step - loss: 0.1422 - val_loss: 0.1423\n",
      "Epoch 701/1000\n",
      "25/25 [==============================] - 7s 300ms/step - loss: 0.1420 - val_loss: 0.1425\n",
      "Epoch 702/1000\n",
      "25/25 [==============================] - 8s 316ms/step - loss: 0.1420 - val_loss: 0.1430\n",
      "Epoch 703/1000\n",
      "25/25 [==============================] - 8s 340ms/step - loss: 0.1424 - val_loss: 0.1423\n",
      "Epoch 704/1000\n",
      "25/25 [==============================] - 9s 373ms/step - loss: 0.1424 - val_loss: 0.1424\n",
      "Epoch 705/1000\n",
      "25/25 [==============================] - 10s 396ms/step - loss: 0.1415 - val_loss: 0.1424\n",
      "Epoch 706/1000\n",
      "25/25 [==============================] - 8s 328ms/step - loss: 0.1424 - val_loss: 0.1426\n",
      "Epoch 707/1000\n",
      "25/25 [==============================] - 7s 293ms/step - loss: 0.1419 - val_loss: 0.1421\n",
      "Epoch 708/1000\n",
      "25/25 [==============================] - 7s 277ms/step - loss: 0.1417 - val_loss: 0.1431\n",
      "Epoch 709/1000\n",
      "25/25 [==============================] - 7s 277ms/step - loss: 0.1426 - val_loss: 0.1425\n",
      "Epoch 710/1000\n",
      "25/25 [==============================] - 7s 286ms/step - loss: 0.1426 - val_loss: 0.1423\n",
      "Epoch 711/1000\n",
      "25/25 [==============================] - 7s 296ms/step - loss: 0.1417 - val_loss: 0.1421\n",
      "Epoch 712/1000\n",
      "25/25 [==============================] - 9s 366ms/step - loss: 0.1412 - val_loss: 0.1422\n",
      "Epoch 713/1000\n",
      "25/25 [==============================] - 12s 504ms/step - loss: 0.1414 - val_loss: 0.1425\n",
      "Epoch 714/1000\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 0.1416 - val_loss: 0.1421\n",
      "Epoch 715/1000\n",
      "25/25 [==============================] - 14s 552ms/step - loss: 0.1419 - val_loss: 0.1421\n",
      "Epoch 716/1000\n",
      "25/25 [==============================] - 11s 450ms/step - loss: 0.1421 - val_loss: 0.1437\n",
      "Epoch 717/1000\n",
      "25/25 [==============================] - 9s 375ms/step - loss: 0.1433 - val_loss: 0.1421\n",
      "Epoch 718/1000\n",
      "25/25 [==============================] - 8s 318ms/step - loss: 0.1421 - val_loss: 0.1420\n",
      "Epoch 719/1000\n",
      "25/25 [==============================] - 8s 308ms/step - loss: 0.1412 - val_loss: 0.1420\n",
      "Epoch 720/1000\n",
      "25/25 [==============================] - 8s 309ms/step - loss: 0.1421 - val_loss: 0.1423\n",
      "Epoch 721/1000\n",
      "25/25 [==============================] - 8s 329ms/step - loss: 0.1415 - val_loss: 0.1423\n",
      "Epoch 722/1000\n",
      "25/25 [==============================] - 9s 375ms/step - loss: 0.1419 - val_loss: 0.1420\n",
      "Epoch 723/1000\n",
      "25/25 [==============================] - 10s 412ms/step - loss: 0.1410 - val_loss: 0.1420\n",
      "Epoch 724/1000\n",
      "25/25 [==============================] - 12s 477ms/step - loss: 0.1419 - val_loss: 0.1420\n",
      "Epoch 725/1000\n",
      "25/25 [==============================] - 13s 536ms/step - loss: 0.1410 - val_loss: 0.1420\n",
      "Epoch 726/1000\n",
      "25/25 [==============================] - 21s 846ms/step - loss: 0.1415 - val_loss: 0.1423\n",
      "Epoch 727/1000\n",
      "25/25 [==============================] - 12s 480ms/step - loss: 0.1415 - val_loss: 0.1421\n",
      "Epoch 728/1000\n",
      "25/25 [==============================] - 9s 355ms/step - loss: 0.1415 - val_loss: 0.1420\n",
      "Epoch 729/1000\n",
      "25/25 [==============================] - 8s 323ms/step - loss: 0.1414 - val_loss: 0.1419\n",
      "Epoch 730/1000\n",
      "25/25 [==============================] - 7s 300ms/step - loss: 0.1418 - val_loss: 0.1424\n",
      "Epoch 731/1000\n",
      "25/25 [==============================] - 7s 300ms/step - loss: 0.1421 - val_loss: 0.1422\n",
      "Epoch 732/1000\n",
      "25/25 [==============================] - 8s 329ms/step - loss: 0.1414 - val_loss: 0.1428\n",
      "Epoch 733/1000\n",
      "25/25 [==============================] - 8s 341ms/step - loss: 0.1421 - val_loss: 0.1421\n",
      "Epoch 734/1000\n",
      "25/25 [==============================] - 9s 357ms/step - loss: 0.1417 - val_loss: 0.1420\n",
      "Epoch 735/1000\n",
      "25/25 [==============================] - 11s 431ms/step - loss: 0.1413 - val_loss: 0.1420\n",
      "Epoch 736/1000\n",
      "25/25 [==============================] - 13s 508ms/step - loss: 0.1418 - val_loss: 0.1419\n",
      "Epoch 737/1000\n",
      "25/25 [==============================] - 15s 621ms/step - loss: 0.1411 - val_loss: 0.1420\n",
      "Epoch 738/1000\n",
      "25/25 [==============================] - 13s 502ms/step - loss: 0.1419 - val_loss: 0.1427\n",
      "Epoch 739/1000\n",
      "25/25 [==============================] - 10s 381ms/step - loss: 0.1425 - val_loss: 0.1419\n",
      "Epoch 740/1000\n",
      "25/25 [==============================] - 8s 330ms/step - loss: 0.1418 - val_loss: 0.1418\n",
      "Epoch 741/1000\n",
      "25/25 [==============================] - 9s 358ms/step - loss: 0.1415 - val_loss: 0.1419\n",
      "Epoch 742/1000\n",
      "25/25 [==============================] - 8s 317ms/step - loss: 0.1420 - val_loss: 0.1421\n",
      "Epoch 743/1000\n",
      "25/25 [==============================] - 8s 320ms/step - loss: 0.1414 - val_loss: 0.1423\n",
      "Epoch 744/1000\n",
      "25/25 [==============================] - 8s 320ms/step - loss: 0.1420 - val_loss: 0.1418\n",
      "Epoch 745/1000\n",
      "25/25 [==============================] - 8s 328ms/step - loss: 0.1414 - val_loss: 0.1419\n",
      "Epoch 746/1000\n",
      "25/25 [==============================] - 9s 350ms/step - loss: 0.1419 - val_loss: 0.1443\n",
      "Epoch 747/1000\n",
      "25/25 [==============================] - 10s 394ms/step - loss: 0.1421 - val_loss: 0.1418\n",
      "Epoch 748/1000\n",
      "25/25 [==============================] - 13s 520ms/step - loss: 0.1415 - val_loss: 0.1418\n",
      "Epoch 749/1000\n",
      "25/25 [==============================] - 30s 1s/step - loss: 0.1410 - val_loss: 0.1419\n",
      "Epoch 750/1000\n",
      "25/25 [==============================] - 14s 537ms/step - loss: 0.1415 - val_loss: 0.1419\n",
      "Epoch 751/1000\n",
      "25/25 [==============================] - 10s 386ms/step - loss: 0.1423 - val_loss: 0.1427\n",
      "Epoch 752/1000\n",
      "25/25 [==============================] - 8s 340ms/step - loss: 0.1420 - val_loss: 0.1429\n",
      "Epoch 753/1000\n",
      "25/25 [==============================] - 9s 373ms/step - loss: 0.1418 - val_loss: 0.1420\n",
      "Epoch 754/1000\n",
      "25/25 [==============================] - 11s 430ms/step - loss: 0.1417 - val_loss: 0.1418\n",
      "Epoch 755/1000\n",
      "25/25 [==============================] - 12s 497ms/step - loss: 0.1417 - val_loss: 0.1428\n",
      "Epoch 756/1000\n",
      "25/25 [==============================] - 19s 780ms/step - loss: 0.1421 - val_loss: 0.1420\n",
      "Epoch 757/1000\n",
      "25/25 [==============================] - 14s 555ms/step - loss: 0.1413 - val_loss: 0.1419\n",
      "Epoch 758/1000\n",
      "25/25 [==============================] - 10s 399ms/step - loss: 0.1415 - val_loss: 0.1423\n",
      "Epoch 759/1000\n",
      "25/25 [==============================] - 8s 326ms/step - loss: 0.1420 - val_loss: 0.1424\n",
      "Epoch 760/1000\n",
      "25/25 [==============================] - 7s 285ms/step - loss: 0.1416 - val_loss: 0.1422\n",
      "Epoch 761/1000\n",
      "25/25 [==============================] - 7s 296ms/step - loss: 0.1416 - val_loss: 0.1417\n",
      "Epoch 762/1000\n",
      "25/25 [==============================] - 7s 299ms/step - loss: 0.1408 - val_loss: 0.1421\n",
      "Epoch 763/1000\n",
      "25/25 [==============================] - 8s 314ms/step - loss: 0.1409 - val_loss: 0.1423\n",
      "Epoch 764/1000\n",
      "25/25 [==============================] - 8s 322ms/step - loss: 0.1421 - val_loss: 0.1418\n",
      "Epoch 765/1000\n",
      "25/25 [==============================] - 9s 342ms/step - loss: 0.1412 - val_loss: 0.1416\n",
      "Epoch 766/1000\n",
      "25/25 [==============================] - 10s 395ms/step - loss: 0.1411 - val_loss: 0.1429\n",
      "Epoch 767/1000\n",
      "25/25 [==============================] - 11s 450ms/step - loss: 0.1419 - val_loss: 0.1417\n",
      "Epoch 768/1000\n",
      "25/25 [==============================] - 14s 578ms/step - loss: 0.1411 - val_loss: 0.1418\n",
      "Epoch 769/1000\n",
      "25/25 [==============================] - 17s 676ms/step - loss: 0.1421 - val_loss: 0.1418\n",
      "Epoch 770/1000\n",
      "25/25 [==============================] - 12s 478ms/step - loss: 0.1419 - val_loss: 0.1418\n",
      "Epoch 771/1000\n",
      "25/25 [==============================] - 9s 362ms/step - loss: 0.1415 - val_loss: 0.1444\n",
      "Epoch 772/1000\n",
      "25/25 [==============================] - 8s 314ms/step - loss: 0.1434 - val_loss: 0.1433\n",
      "Epoch 773/1000\n",
      "25/25 [==============================] - 8s 310ms/step - loss: 0.1419 - val_loss: 0.1427\n",
      "Epoch 774/1000\n",
      "25/25 [==============================] - 8s 303ms/step - loss: 0.1413 - val_loss: 0.1420\n",
      "Epoch 775/1000\n",
      "25/25 [==============================] - 8s 324ms/step - loss: 0.1412 - val_loss: 0.1416\n",
      "Epoch 776/1000\n",
      "25/25 [==============================] - 8s 321ms/step - loss: 0.1416 - val_loss: 0.1425\n",
      "Epoch 777/1000\n",
      "25/25 [==============================] - 9s 362ms/step - loss: 0.1418 - val_loss: 0.1418\n",
      "Epoch 778/1000\n",
      "25/25 [==============================] - 10s 395ms/step - loss: 0.1412 - val_loss: 0.1416\n",
      "Epoch 779/1000\n",
      "25/25 [==============================] - 10s 422ms/step - loss: 0.1409 - val_loss: 0.1415\n",
      "Epoch 780/1000\n",
      "25/25 [==============================] - 13s 542ms/step - loss: 0.1418 - val_loss: 0.1417\n",
      "Epoch 781/1000\n",
      "25/25 [==============================] - 20s 793ms/step - loss: 0.1411 - val_loss: 0.1421\n",
      "Epoch 782/1000\n",
      "25/25 [==============================] - 16s 613ms/step - loss: 0.1412 - val_loss: 0.1416\n",
      "Epoch 783/1000\n",
      "25/25 [==============================] - 10s 389ms/step - loss: 0.1417 - val_loss: 0.1415\n",
      "Epoch 784/1000\n",
      "25/25 [==============================] - 8s 341ms/step - loss: 0.1413 - val_loss: 0.1415\n",
      "Epoch 785/1000\n",
      "25/25 [==============================] - 8s 313ms/step - loss: 0.1412 - val_loss: 0.1415\n",
      "Epoch 786/1000\n",
      "25/25 [==============================] - 7s 288ms/step - loss: 0.1411 - val_loss: 0.1424\n",
      "Epoch 787/1000\n",
      "25/25 [==============================] - 8s 322ms/step - loss: 0.1419 - val_loss: 0.1430\n",
      "Epoch 788/1000\n",
      "25/25 [==============================] - 8s 318ms/step - loss: 0.1413 - val_loss: 0.1415\n",
      "Epoch 789/1000\n",
      "25/25 [==============================] - 8s 336ms/step - loss: 0.1412 - val_loss: 0.1415\n",
      "Epoch 790/1000\n",
      "25/25 [==============================] - 9s 364ms/step - loss: 0.1412 - val_loss: 0.1421\n",
      "Epoch 791/1000\n",
      "25/25 [==============================] - 11s 441ms/step - loss: 0.1416 - val_loss: 0.1418\n",
      "Epoch 792/1000\n",
      "25/25 [==============================] - 15s 625ms/step - loss: 0.1411 - val_loss: 0.1415\n",
      "Epoch 793/1000\n",
      "25/25 [==============================] - 24s 924ms/step - loss: 0.1409 - val_loss: 0.1414\n",
      "Epoch 794/1000\n",
      "25/25 [==============================] - 12s 488ms/step - loss: 0.1406 - val_loss: 0.1416\n",
      "Epoch 795/1000\n",
      "25/25 [==============================] - 9s 376ms/step - loss: 0.1410 - val_loss: 0.1423\n",
      "Epoch 796/1000\n",
      "25/25 [==============================] - 8s 329ms/step - loss: 0.1418 - val_loss: 0.1419\n",
      "Epoch 797/1000\n",
      "25/25 [==============================] - 7s 297ms/step - loss: 0.1414 - val_loss: 0.1431\n",
      "Epoch 798/1000\n",
      "25/25 [==============================] - 8s 306ms/step - loss: 0.1412 - val_loss: 0.1419\n",
      "Epoch 799/1000\n",
      "25/25 [==============================] - 8s 333ms/step - loss: 0.1416 - val_loss: 0.1414\n",
      "Epoch 800/1000\n",
      "25/25 [==============================] - 8s 336ms/step - loss: 0.1411 - val_loss: 0.1414\n",
      "Epoch 801/1000\n",
      "25/25 [==============================] - 9s 368ms/step - loss: 0.1410 - val_loss: 0.1415\n",
      "Epoch 802/1000\n",
      "25/25 [==============================] - 11s 438ms/step - loss: 0.1408 - val_loss: 0.1415\n",
      "Epoch 803/1000\n",
      "25/25 [==============================] - 14s 556ms/step - loss: 0.1410 - val_loss: 0.1417\n",
      "Epoch 804/1000\n",
      "25/25 [==============================] - 16s 635ms/step - loss: 0.1412 - val_loss: 0.1417\n",
      "Epoch 805/1000\n",
      "25/25 [==============================] - 20s 781ms/step - loss: 0.1417 - val_loss: 0.1414\n",
      "Epoch 806/1000\n",
      "25/25 [==============================] - 11s 444ms/step - loss: 0.1409 - val_loss: 0.1414\n",
      "Epoch 807/1000\n",
      "25/25 [==============================] - 8s 337ms/step - loss: 0.1411 - val_loss: 0.1414\n",
      "Epoch 808/1000\n",
      "25/25 [==============================] - 8s 302ms/step - loss: 0.1412 - val_loss: 0.1423\n",
      "Epoch 809/1000\n",
      "25/25 [==============================] - 8s 323ms/step - loss: 0.1418 - val_loss: 0.1414\n",
      "Epoch 810/1000\n",
      "25/25 [==============================] - 8s 316ms/step - loss: 0.1409 - val_loss: 0.1416\n",
      "Epoch 811/1000\n",
      "25/25 [==============================] - 8s 326ms/step - loss: 0.1413 - val_loss: 0.1416\n",
      "Epoch 812/1000\n",
      "25/25 [==============================] - 8s 340ms/step - loss: 0.1406 - val_loss: 0.1413\n",
      "Epoch 813/1000\n",
      "25/25 [==============================] - 9s 362ms/step - loss: 0.1408 - val_loss: 0.1413\n",
      "Epoch 814/1000\n",
      "25/25 [==============================] - 10s 406ms/step - loss: 0.1411 - val_loss: 0.1413\n",
      "Epoch 815/1000\n",
      "25/25 [==============================] - 12s 478ms/step - loss: 0.1407 - val_loss: 0.1415\n",
      "Epoch 816/1000\n",
      "25/25 [==============================] - 16s 643ms/step - loss: 0.1412 - val_loss: 0.1415\n",
      "Epoch 817/1000\n",
      "25/25 [==============================] - 18s 738ms/step - loss: 0.1414 - val_loss: 0.1420\n",
      "Epoch 818/1000\n",
      "25/25 [==============================] - 11s 435ms/step - loss: 0.1414 - val_loss: 0.1413\n",
      "Epoch 819/1000\n",
      "25/25 [==============================] - 9s 342ms/step - loss: 0.1402 - val_loss: 0.1414\n",
      "Epoch 820/1000\n",
      "25/25 [==============================] - 8s 312ms/step - loss: 0.1416 - val_loss: 0.1413\n",
      "Epoch 821/1000\n",
      "25/25 [==============================] - 7s 300ms/step - loss: 0.1409 - val_loss: 0.1414\n",
      "Epoch 822/1000\n",
      "25/25 [==============================] - 8s 302ms/step - loss: 0.1414 - val_loss: 0.1415\n",
      "Epoch 823/1000\n",
      "25/25 [==============================] - 8s 341ms/step - loss: 0.1407 - val_loss: 0.1414\n",
      "Epoch 824/1000\n",
      "25/25 [==============================] - 8s 331ms/step - loss: 0.1413 - val_loss: 0.1417\n",
      "Epoch 825/1000\n",
      "25/25 [==============================] - 9s 351ms/step - loss: 0.1404 - val_loss: 0.1413\n",
      "Epoch 826/1000\n",
      "25/25 [==============================] - 9s 381ms/step - loss: 0.1406 - val_loss: 0.1419\n",
      "Epoch 827/1000\n",
      "25/25 [==============================] - 12s 493ms/step - loss: 0.1408 - val_loss: 0.1431\n",
      "Epoch 828/1000\n",
      "25/25 [==============================] - 14s 552ms/step - loss: 0.1412 - val_loss: 0.1414\n",
      "Epoch 829/1000\n",
      "25/25 [==============================] - 26s 1s/step - loss: 0.1407 - val_loss: 0.1416\n",
      "Epoch 830/1000\n",
      "25/25 [==============================] - 14s 540ms/step - loss: 0.1409 - val_loss: 0.1413\n",
      "Epoch 831/1000\n",
      "25/25 [==============================] - 9s 341ms/step - loss: 0.1412 - val_loss: 0.1412\n",
      "Epoch 832/1000\n",
      "25/25 [==============================] - 8s 307ms/step - loss: 0.1408 - val_loss: 0.1412\n",
      "Epoch 833/1000\n",
      "25/25 [==============================] - 7s 295ms/step - loss: 0.1405 - val_loss: 0.1413\n",
      "Epoch 834/1000\n",
      "25/25 [==============================] - 7s 290ms/step - loss: 0.1409 - val_loss: 0.1412\n",
      "Epoch 835/1000\n",
      "25/25 [==============================] - 8s 312ms/step - loss: 0.1407 - val_loss: 0.1418\n",
      "Epoch 836/1000\n",
      "25/25 [==============================] - 8s 315ms/step - loss: 0.1416 - val_loss: 0.1413\n",
      "Epoch 837/1000\n",
      "25/25 [==============================] - 8s 332ms/step - loss: 0.1413 - val_loss: 0.1413\n",
      "Epoch 838/1000\n",
      "25/25 [==============================] - 10s 390ms/step - loss: 0.1415 - val_loss: 0.1419\n",
      "Epoch 839/1000\n",
      "25/25 [==============================] - 11s 444ms/step - loss: 0.1411 - val_loss: 0.1412\n",
      "Epoch 840/1000\n",
      "25/25 [==============================] - 14s 572ms/step - loss: 0.1417 - val_loss: 0.1415\n",
      "Epoch 841/1000\n",
      "25/25 [==============================] - 19s 750ms/step - loss: 0.1411 - val_loss: 0.1425\n",
      "Epoch 842/1000\n",
      "25/25 [==============================] - 18s 705ms/step - loss: 0.1411 - val_loss: 0.1412\n",
      "Epoch 843/1000\n",
      "25/25 [==============================] - 10s 406ms/step - loss: 0.1414 - val_loss: 0.1412\n",
      "Epoch 844/1000\n",
      "25/25 [==============================] - 9s 344ms/step - loss: 0.1407 - val_loss: 0.1411\n",
      "Epoch 845/1000\n",
      "25/25 [==============================] - 8s 302ms/step - loss: 0.1406 - val_loss: 0.1411\n",
      "Epoch 846/1000\n",
      "25/25 [==============================] - 8s 316ms/step - loss: 0.1410 - val_loss: 0.1411\n",
      "Epoch 847/1000\n",
      "25/25 [==============================] - 8s 309ms/step - loss: 0.1404 - val_loss: 0.1416\n",
      "Epoch 848/1000\n",
      "25/25 [==============================] - 9s 356ms/step - loss: 0.1417 - val_loss: 0.1411\n",
      "Epoch 849/1000\n",
      "25/25 [==============================] - 10s 400ms/step - loss: 0.1408 - val_loss: 0.1420\n",
      "Epoch 850/1000\n",
      "25/25 [==============================] - 12s 485ms/step - loss: 0.1408 - val_loss: 0.1412\n",
      "Epoch 851/1000\n",
      "25/25 [==============================] - 13s 515ms/step - loss: 0.1408 - val_loss: 0.1412\n",
      "Epoch 852/1000\n",
      "25/25 [==============================] - 17s 690ms/step - loss: 0.1411 - val_loss: 0.1411\n",
      "Epoch 853/1000\n",
      "25/25 [==============================] - 19s 766ms/step - loss: 0.1400 - val_loss: 0.1410\n",
      "Epoch 854/1000\n",
      "25/25 [==============================] - 10s 410ms/step - loss: 0.1402 - val_loss: 0.1413\n",
      "Epoch 855/1000\n",
      "25/25 [==============================] - 9s 362ms/step - loss: 0.1414 - val_loss: 0.1415\n",
      "Epoch 856/1000\n",
      "25/25 [==============================] - 8s 303ms/step - loss: 0.1414 - val_loss: 0.1432\n",
      "Epoch 857/1000\n",
      "25/25 [==============================] - 8s 318ms/step - loss: 0.1406 - val_loss: 0.1420\n",
      "Epoch 858/1000\n",
      "25/25 [==============================] - 8s 315ms/step - loss: 0.1420 - val_loss: 0.1412\n",
      "Epoch 859/1000\n",
      "25/25 [==============================] - 9s 346ms/step - loss: 0.1408 - val_loss: 0.1429\n",
      "Epoch 860/1000\n",
      "25/25 [==============================] - 9s 351ms/step - loss: 0.1414 - val_loss: 0.1410\n",
      "Epoch 861/1000\n",
      "25/25 [==============================] - 10s 388ms/step - loss: 0.1402 - val_loss: 0.1410\n",
      "Epoch 862/1000\n",
      "25/25 [==============================] - 11s 431ms/step - loss: 0.1402 - val_loss: 0.1410\n",
      "Epoch 863/1000\n",
      "25/25 [==============================] - 13s 525ms/step - loss: 0.1406 - val_loss: 0.1410\n",
      "Epoch 864/1000\n",
      "25/25 [==============================] - 20s 827ms/step - loss: 0.1413 - val_loss: 0.1411\n",
      "Epoch 865/1000\n",
      "25/25 [==============================] - 18s 693ms/step - loss: 0.1412 - val_loss: 0.1419\n",
      "Epoch 866/1000\n",
      "25/25 [==============================] - 12s 461ms/step - loss: 0.1408 - val_loss: 0.1414\n",
      "Epoch 867/1000\n",
      "25/25 [==============================] - 9s 343ms/step - loss: 0.1407 - val_loss: 0.1411\n",
      "Epoch 868/1000\n",
      "25/25 [==============================] - 8s 332ms/step - loss: 0.1407 - val_loss: 0.1411\n",
      "Epoch 869/1000\n",
      "25/25 [==============================] - 7s 297ms/step - loss: 0.1409 - val_loss: 0.1410\n",
      "Epoch 870/1000\n",
      "25/25 [==============================] - 7s 298ms/step - loss: 0.1407 - val_loss: 0.1431\n",
      "Epoch 871/1000\n",
      "25/25 [==============================] - 8s 308ms/step - loss: 0.1419 - val_loss: 0.1412\n",
      "Epoch 872/1000\n",
      "25/25 [==============================] - 8s 313ms/step - loss: 0.1410 - val_loss: 0.1412\n",
      "Epoch 873/1000\n",
      "25/25 [==============================] - 9s 358ms/step - loss: 0.1411 - val_loss: 0.1410\n",
      "Epoch 874/1000\n",
      "25/25 [==============================] - 10s 396ms/step - loss: 0.1400 - val_loss: 0.1416\n",
      "Epoch 875/1000\n",
      "25/25 [==============================] - 12s 487ms/step - loss: 0.1408 - val_loss: 0.1409\n",
      "Epoch 876/1000\n",
      "25/25 [==============================] - 17s 663ms/step - loss: 0.1407 - val_loss: 0.1409\n",
      "Epoch 877/1000\n",
      "25/25 [==============================] - 24s 969ms/step - loss: 0.1401 - val_loss: 0.1409\n",
      "Epoch 878/1000\n",
      "25/25 [==============================] - 12s 483ms/step - loss: 0.1415 - val_loss: 0.1418\n",
      "Epoch 879/1000\n",
      "25/25 [==============================] - 9s 379ms/step - loss: 0.1406 - val_loss: 0.1412\n",
      "Epoch 880/1000\n",
      "25/25 [==============================] - 8s 320ms/step - loss: 0.1414 - val_loss: 0.1409\n",
      "Epoch 881/1000\n",
      "25/25 [==============================] - 7s 291ms/step - loss: 0.1399 - val_loss: 0.1413\n",
      "Epoch 882/1000\n",
      "25/25 [==============================] - 8s 312ms/step - loss: 0.1404 - val_loss: 0.1421\n",
      "Epoch 883/1000\n",
      "25/25 [==============================] - 8s 321ms/step - loss: 0.1421 - val_loss: 0.1413\n",
      "Epoch 884/1000\n",
      "25/25 [==============================] - 8s 322ms/step - loss: 0.1416 - val_loss: 0.1417\n",
      "Epoch 885/1000\n",
      "25/25 [==============================] - 9s 361ms/step - loss: 0.1410 - val_loss: 0.1408\n",
      "Epoch 886/1000\n",
      "25/25 [==============================] - 10s 391ms/step - loss: 0.1404 - val_loss: 0.1418\n",
      "Epoch 887/1000\n",
      "25/25 [==============================] - 11s 443ms/step - loss: 0.1406 - val_loss: 0.1409\n",
      "Epoch 888/1000\n",
      "25/25 [==============================] - 15s 591ms/step - loss: 0.1409 - val_loss: 0.1408\n",
      "Epoch 889/1000\n",
      "25/25 [==============================] - 23s 957ms/step - loss: 0.1398 - val_loss: 0.1411\n",
      "Epoch 890/1000\n",
      "25/25 [==============================] - 12s 474ms/step - loss: 0.1413 - val_loss: 0.1408\n",
      "Epoch 891/1000\n",
      "25/25 [==============================] - 9s 351ms/step - loss: 0.1402 - val_loss: 0.1409\n",
      "Epoch 892/1000\n",
      "25/25 [==============================] - 8s 324ms/step - loss: 0.1406 - val_loss: 0.1415\n",
      "Epoch 893/1000\n",
      "25/25 [==============================] - 8s 302ms/step - loss: 0.1409 - val_loss: 0.1410\n",
      "Epoch 894/1000\n",
      "25/25 [==============================] - 8s 314ms/step - loss: 0.1406 - val_loss: 0.1413\n",
      "Epoch 895/1000\n",
      "25/25 [==============================] - 9s 350ms/step - loss: 0.1414 - val_loss: 0.1408\n",
      "Epoch 896/1000\n",
      "25/25 [==============================] - 10s 383ms/step - loss: 0.1409 - val_loss: 0.1415\n",
      "Epoch 897/1000\n",
      "25/25 [==============================] - 11s 450ms/step - loss: 0.1416 - val_loss: 0.1416\n",
      "Epoch 898/1000\n",
      "25/25 [==============================] - 13s 518ms/step - loss: 0.1404 - val_loss: 0.1408\n",
      "Epoch 899/1000\n",
      "25/25 [==============================] - 18s 724ms/step - loss: 0.1407 - val_loss: 0.1408\n",
      "Epoch 900/1000\n",
      "25/25 [==============================] - 24s 974ms/step - loss: 0.1402 - val_loss: 0.1408\n",
      "Epoch 901/1000\n",
      "25/25 [==============================] - 12s 494ms/step - loss: 0.1406 - val_loss: 0.1413\n",
      "Epoch 902/1000\n",
      "25/25 [==============================] - 9s 357ms/step - loss: 0.1407 - val_loss: 0.1408\n",
      "Epoch 903/1000\n",
      "25/25 [==============================] - 8s 318ms/step - loss: 0.1399 - val_loss: 0.1416\n",
      "Epoch 904/1000\n",
      "25/25 [==============================] - 8s 303ms/step - loss: 0.1401 - val_loss: 0.1409\n",
      "Epoch 905/1000\n",
      "25/25 [==============================] - 9s 367ms/step - loss: 0.1405 - val_loss: 0.1408\n",
      "Epoch 906/1000\n",
      "25/25 [==============================] - 9s 362ms/step - loss: 0.1404 - val_loss: 0.1415\n",
      "Epoch 907/1000\n",
      "25/25 [==============================] - 9s 381ms/step - loss: 0.1407 - val_loss: 0.1412\n",
      "Epoch 908/1000\n",
      "25/25 [==============================] - 10s 416ms/step - loss: 0.1404 - val_loss: 0.1410\n",
      "Epoch 909/1000\n",
      "25/25 [==============================] - 11s 443ms/step - loss: 0.1401 - val_loss: 0.1410\n",
      "Epoch 910/1000\n",
      "25/25 [==============================] - 16s 665ms/step - loss: 0.1407 - val_loss: 0.1407\n",
      "Epoch 911/1000\n",
      "25/25 [==============================] - 23s 930ms/step - loss: 0.1406 - val_loss: 0.1411\n",
      "Epoch 912/1000\n",
      "25/25 [==============================] - 11s 429ms/step - loss: 0.1412 - val_loss: 0.1410\n",
      "Epoch 913/1000\n",
      "25/25 [==============================] - 9s 351ms/step - loss: 0.1408 - val_loss: 0.1407\n",
      "Epoch 914/1000\n",
      "25/25 [==============================] - 8s 325ms/step - loss: 0.1406 - val_loss: 0.1411\n",
      "Epoch 915/1000\n",
      "25/25 [==============================] - 8s 327ms/step - loss: 0.1412 - val_loss: 0.1410\n",
      "Epoch 916/1000\n",
      "25/25 [==============================] - 7s 295ms/step - loss: 0.1405 - val_loss: 0.1412\n",
      "Epoch 917/1000\n",
      "25/25 [==============================] - 8s 305ms/step - loss: 0.1403 - val_loss: 0.1407\n",
      "Epoch 918/1000\n",
      "25/25 [==============================] - 8s 316ms/step - loss: 0.1392 - val_loss: 0.1418\n",
      "Epoch 919/1000\n",
      "25/25 [==============================] - 8s 332ms/step - loss: 0.1405 - val_loss: 0.1444\n",
      "Epoch 920/1000\n",
      "25/25 [==============================] - 9s 369ms/step - loss: 0.1420 - val_loss: 0.1411\n",
      "Epoch 921/1000\n",
      "25/25 [==============================] - 10s 408ms/step - loss: 0.1406 - val_loss: 0.1408\n",
      "Epoch 922/1000\n",
      "25/25 [==============================] - 12s 489ms/step - loss: 0.1404 - val_loss: 0.1406\n",
      "Epoch 923/1000\n",
      "25/25 [==============================] - 17s 668ms/step - loss: 0.1400 - val_loss: 0.1411\n",
      "Epoch 924/1000\n",
      "25/25 [==============================] - 21s 842ms/step - loss: 0.1406 - val_loss: 0.1409\n",
      "Epoch 925/1000\n",
      "25/25 [==============================] - 11s 437ms/step - loss: 0.1401 - val_loss: 0.1410\n",
      "Epoch 926/1000\n",
      "25/25 [==============================] - 8s 339ms/step - loss: 0.1407 - val_loss: 0.1408\n",
      "Epoch 927/1000\n",
      "25/25 [==============================] - 8s 328ms/step - loss: 0.1409 - val_loss: 0.1420\n",
      "Epoch 928/1000\n",
      "25/25 [==============================] - 8s 314ms/step - loss: 0.1406 - val_loss: 0.1406\n",
      "Epoch 929/1000\n",
      "25/25 [==============================] - 8s 307ms/step - loss: 0.1403 - val_loss: 0.1411\n",
      "Epoch 930/1000\n",
      "25/25 [==============================] - 8s 320ms/step - loss: 0.1400 - val_loss: 0.1407\n",
      "Epoch 931/1000\n",
      "25/25 [==============================] - 8s 340ms/step - loss: 0.1398 - val_loss: 0.1406\n",
      "Epoch 932/1000\n",
      "25/25 [==============================] - 10s 382ms/step - loss: 0.1402 - val_loss: 0.1411\n",
      "Epoch 933/1000\n",
      "25/25 [==============================] - 12s 474ms/step - loss: 0.1401 - val_loss: 0.1418\n",
      "Epoch 934/1000\n",
      "25/25 [==============================] - 12s 493ms/step - loss: 0.1408 - val_loss: 0.1406\n",
      "Epoch 935/1000\n",
      "25/25 [==============================] - 25s 1s/step - loss: 0.1405 - val_loss: 0.1418\n",
      "Epoch 936/1000\n",
      "25/25 [==============================] - 15s 597ms/step - loss: 0.1408 - val_loss: 0.1412\n",
      "Epoch 937/1000\n",
      "25/25 [==============================] - 10s 388ms/step - loss: 0.1407 - val_loss: 0.1414\n",
      "Epoch 938/1000\n",
      "25/25 [==============================] - 8s 335ms/step - loss: 0.1406 - val_loss: 0.1425\n",
      "Epoch 939/1000\n",
      "25/25 [==============================] - 8s 317ms/step - loss: 0.1411 - val_loss: 0.1421\n",
      "Epoch 940/1000\n",
      "25/25 [==============================] - 7s 301ms/step - loss: 0.1414 - val_loss: 0.1423\n",
      "Epoch 941/1000\n",
      "25/25 [==============================] - 8s 312ms/step - loss: 0.1412 - val_loss: 0.1435\n",
      "Epoch 942/1000\n",
      "25/25 [==============================] - 8s 306ms/step - loss: 0.1417 - val_loss: 0.1410\n",
      "Epoch 943/1000\n",
      "25/25 [==============================] - 8s 322ms/step - loss: 0.1399 - val_loss: 0.1408\n",
      "Epoch 944/1000\n",
      "25/25 [==============================] - 9s 353ms/step - loss: 0.1401 - val_loss: 0.1410\n",
      "Epoch 945/1000\n",
      "25/25 [==============================] - 10s 385ms/step - loss: 0.1403 - val_loss: 0.1405\n",
      "Epoch 946/1000\n",
      "25/25 [==============================] - 11s 462ms/step - loss: 0.1407 - val_loss: 0.1411\n",
      "Epoch 947/1000\n",
      "25/25 [==============================] - 13s 540ms/step - loss: 0.1407 - val_loss: 0.1406\n",
      "Epoch 948/1000\n",
      "25/25 [==============================] - 22s 873ms/step - loss: 0.1403 - val_loss: 0.1410\n",
      "Epoch 949/1000\n",
      "25/25 [==============================] - 14s 547ms/step - loss: 0.1401 - val_loss: 0.1406\n",
      "Epoch 950/1000\n",
      "25/25 [==============================] - 10s 387ms/step - loss: 0.1398 - val_loss: 0.1405\n",
      "Epoch 951/1000\n",
      "25/25 [==============================] - 8s 324ms/step - loss: 0.1401 - val_loss: 0.1420\n",
      "Epoch 952/1000\n",
      "25/25 [==============================] - 7s 300ms/step - loss: 0.1408 - val_loss: 0.1405\n",
      "Epoch 953/1000\n",
      "25/25 [==============================] - 7s 297ms/step - loss: 0.1403 - val_loss: 0.1416\n",
      "Epoch 954/1000\n",
      "25/25 [==============================] - 8s 308ms/step - loss: 0.1402 - val_loss: 0.1412\n",
      "Epoch 955/1000\n",
      "25/25 [==============================] - 8s 324ms/step - loss: 0.1408 - val_loss: 0.1408\n",
      "Epoch 956/1000\n",
      "25/25 [==============================] - 9s 345ms/step - loss: 0.1404 - val_loss: 0.1411\n",
      "Epoch 957/1000\n",
      "25/25 [==============================] - 10s 385ms/step - loss: 0.1411 - val_loss: 0.1406\n",
      "Epoch 958/1000\n",
      "25/25 [==============================] - 11s 438ms/step - loss: 0.1400 - val_loss: 0.1405\n",
      "Epoch 959/1000\n",
      "25/25 [==============================] - 13s 516ms/step - loss: 0.1400 - val_loss: 0.1405\n",
      "Epoch 960/1000\n",
      "25/25 [==============================] - 19s 777ms/step - loss: 0.1402 - val_loss: 0.1405\n",
      "Epoch 961/1000\n",
      "25/25 [==============================] - 15s 596ms/step - loss: 0.1403 - val_loss: 0.1408\n",
      "Epoch 962/1000\n",
      "25/25 [==============================] - 10s 394ms/step - loss: 0.1404 - val_loss: 0.1405\n",
      "Epoch 963/1000\n",
      "25/25 [==============================] - 8s 327ms/step - loss: 0.1401 - val_loss: 0.1408\n",
      "Epoch 964/1000\n",
      "25/25 [==============================] - 7s 298ms/step - loss: 0.1408 - val_loss: 0.1406\n",
      "Epoch 965/1000\n",
      "25/25 [==============================] - 8s 317ms/step - loss: 0.1403 - val_loss: 0.1414\n",
      "Epoch 966/1000\n",
      "25/25 [==============================] - 8s 320ms/step - loss: 0.1402 - val_loss: 0.1405\n",
      "Epoch 967/1000\n",
      "25/25 [==============================] - 8s 326ms/step - loss: 0.1401 - val_loss: 0.1406\n",
      "Epoch 968/1000\n",
      "25/25 [==============================] - 8s 340ms/step - loss: 0.1397 - val_loss: 0.1406\n",
      "Epoch 969/1000\n",
      "25/25 [==============================] - 10s 395ms/step - loss: 0.1396 - val_loss: 0.1405\n",
      "Epoch 970/1000\n",
      "25/25 [==============================] - 12s 476ms/step - loss: 0.1406 - val_loss: 0.1406\n",
      "Epoch 971/1000\n",
      "25/25 [==============================] - 15s 618ms/step - loss: 0.1402 - val_loss: 0.1410\n",
      "Epoch 972/1000\n",
      "25/25 [==============================] - 22s 877ms/step - loss: 0.1404 - val_loss: 0.1411\n",
      "Epoch 973/1000\n",
      "25/25 [==============================] - 12s 460ms/step - loss: 0.1401 - val_loss: 0.1404\n",
      "Epoch 974/1000\n",
      "25/25 [==============================] - 9s 343ms/step - loss: 0.1401 - val_loss: 0.1406\n",
      "Epoch 975/1000\n",
      "25/25 [==============================] - 8s 312ms/step - loss: 0.1399 - val_loss: 0.1407\n",
      "Epoch 976/1000\n",
      "25/25 [==============================] - 8s 306ms/step - loss: 0.1401 - val_loss: 0.1405\n",
      "Epoch 977/1000\n",
      "25/25 [==============================] - 8s 310ms/step - loss: 0.1401 - val_loss: 0.1408\n",
      "Epoch 978/1000\n",
      "25/25 [==============================] - 8s 311ms/step - loss: 0.1406 - val_loss: 0.1405\n",
      "Epoch 979/1000\n",
      "25/25 [==============================] - 8s 326ms/step - loss: 0.1399 - val_loss: 0.1405\n",
      "Epoch 980/1000\n",
      "25/25 [==============================] - 9s 354ms/step - loss: 0.1396 - val_loss: 0.1405\n",
      "Epoch 981/1000\n",
      "25/25 [==============================] - 10s 399ms/step - loss: 0.1399 - val_loss: 0.1404\n",
      "Epoch 982/1000\n",
      "25/25 [==============================] - 12s 476ms/step - loss: 0.1415 - val_loss: 0.1404\n",
      "Epoch 983/1000\n",
      "25/25 [==============================] - 16s 624ms/step - loss: 0.1401 - val_loss: 0.1403\n",
      "Epoch 984/1000\n",
      "25/25 [==============================] - 27s 1s/step - loss: 0.1402 - val_loss: 0.1404\n",
      "Epoch 985/1000\n",
      "25/25 [==============================] - 13s 523ms/step - loss: 0.1401 - val_loss: 0.1403\n",
      "Epoch 986/1000\n",
      "25/25 [==============================] - 9s 362ms/step - loss: 0.1392 - val_loss: 0.1403\n",
      "Epoch 987/1000\n",
      "25/25 [==============================] - 8s 331ms/step - loss: 0.1403 - val_loss: 0.1413\n",
      "Epoch 988/1000\n",
      "25/25 [==============================] - 8s 314ms/step - loss: 0.1407 - val_loss: 0.1403\n",
      "Epoch 989/1000\n",
      "25/25 [==============================] - 8s 318ms/step - loss: 0.1400 - val_loss: 0.1404\n",
      "Epoch 990/1000\n",
      "25/25 [==============================] - 9s 341ms/step - loss: 0.1398 - val_loss: 0.1407\n",
      "Epoch 991/1000\n",
      "25/25 [==============================] - 9s 369ms/step - loss: 0.1401 - val_loss: 0.1409\n",
      "Epoch 992/1000\n",
      "25/25 [==============================] - 10s 409ms/step - loss: 0.1405 - val_loss: 0.1407\n",
      "Epoch 993/1000\n",
      "25/25 [==============================] - 12s 463ms/step - loss: 0.1400 - val_loss: 0.1403\n",
      "Epoch 994/1000\n",
      "25/25 [==============================] - 17s 708ms/step - loss: 0.1405 - val_loss: 0.1404\n",
      "Epoch 995/1000\n",
      "25/25 [==============================] - 26s 1s/step - loss: 0.1403 - val_loss: 0.1403\n",
      "Epoch 996/1000\n",
      "25/25 [==============================] - 12s 479ms/step - loss: 0.1403 - val_loss: 0.1404\n",
      "Epoch 997/1000\n",
      "25/25 [==============================] - 9s 375ms/step - loss: 0.1403 - val_loss: 0.1408\n",
      "Epoch 998/1000\n",
      "25/25 [==============================] - 8s 317ms/step - loss: 0.1402 - val_loss: 0.1413\n",
      "Epoch 999/1000\n",
      "25/25 [==============================] - 8s 307ms/step - loss: 0.1401 - val_loss: 0.1403\n",
      "Epoch 1000/1000\n",
      "25/25 [==============================] - 8s 322ms/step - loss: 0.1401 - val_loss: 0.1404\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x23f92b448b0>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#학습\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "model.fit(X_train, X_train, epochs=1000, validation_data=(X_test, X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#테스트 진행할 전체 데이터 정규화\n",
    "X = X.astype('float32') / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1038, 12, 12, 2)\n"
     ]
    }
   ],
   "source": [
    "from keras import backend as K\n",
    "compressed_layer = 8\n",
    "get_4th_layer_output = K.function([model.layers[0].input],[model.layers[compressed_layer].output])\n",
    "\n",
    "compressed = get_4th_layer_output([X])[0]\n",
    "\n",
    "print(compressed.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1038, 288)\n"
     ]
    }
   ],
   "source": [
    "#일렬로 늘리기\n",
    "compressed = compressed.reshape(1038,12*12*2)\n",
    "print(compressed.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Dataset\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.datasets import make_moons\n",
    "\n",
    "\n",
    "# Needed Library!\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 삽입!\n",
    "import Cluster as c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scaled_dataset: \n",
      "[[0.         0.36720175 0.         ... 0.5114288  0.01533747 0.        ]\n",
      " [0.         0.36744404 0.         ... 0.63257676 0.04673958 0.        ]\n",
      " [0.         0.36744404 0.         ... 0.63102466 0.0416379  0.        ]\n",
      " ...\n",
      " [0.         0.36720175 0.00469589 ... 0.         0.0088644  0.        ]\n",
      " [0.         0.36720175 0.         ... 0.         0.0088644  0.        ]\n",
      " [0.         0.36720175 0.00469589 ... 0.         0.0088644  0.        ]]\n"
     ]
    }
   ],
   "source": [
    "result, scaled_x = c.kmeans(compressed, 6, normalization='minmax')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3\n",
      " 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3\n",
      " 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3\n",
      " 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3\n",
      " 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 4 4 4 4 1\n",
      " 4 1 1 1 1 4 1 4 4 4 4 1 1 1 1 1 4 1 4 1 4 1 4 1 1 1 4 1 4 4 1 1 1 1 1 1 1\n",
      " 4 1 1 1 1 1 1 4 4 1 4 1 1 4 4 1 1 4 1 1 1 4 4 4 1 1 4 4 4 4 1 4 1 4 1 4 4\n",
      " 1 4 1 1 1 1 1 4 1 4 1 4 1 4 4 4 4 4 1 4 4 1 1 1 1 4 4 1 4 1 4 4 4 4 4 1 4\n",
      " 1 4 4 1 1 1 1 4 4 4 4 1 4 4 4 1 1 1 1 1 4 4 4 1 1 4 1 4 4 1 4 1 1 1 1 4 4\n",
      " 4 1 1 4 4 1 4 1 4 4 4 1 1 4 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5\n",
      " 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5\n",
      " 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5\n",
      " 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5\n",
      " 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5\n",
      " 5 5]\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import numpy\n",
    "numpy.set_printoptions(threshold=sys.maxsize)\n",
    "\n",
    "#결과보기\n",
    "print(result.labels_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3.\n",
      " 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3.\n",
      " 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3.\n",
      " 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3.\n",
      " 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3.\n",
      " 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3.\n",
      " 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3.\n",
      " 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 2. 2. 2. 2.\n",
      " 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2.\n",
      " 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2.\n",
      " 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2.\n",
      " 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2.\n",
      " 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2.\n",
      " 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2.\n",
      " 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2.\n",
      " 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4.\n",
      " 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4.\n",
      " 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4.\n",
      " 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4.\n",
      " 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4.\n",
      " 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4.\n",
      " 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4.\n",
      " 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4.\n",
      " 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5.\n",
      " 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5.\n",
      " 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5.\n",
      " 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5.\n",
      " 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5.\n",
      " 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5.\n",
      " 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5.\n",
      " 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5.\n",
      " 5. 5. 5. 5. 5. 5. 5. 5. 5. 5.]\n"
     ]
    }
   ],
   "source": [
    "import Cluster as c\n",
    "y = c.getClassLabelFor([3, 0, 2, 0, 1, 4, 5])\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 33, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 4, 4, 4, 4, 1, 4, 1, 1, 1, 1, 4, 1, 4, 4, 4, 4, 1, 1, 1, 1, 1, 4, 1, 4, 1, 4, 1, 4, 1, 1, 1, 4, 1, 4, 4, 1, 1, 1, 1, 1, 1, 1, 4, 1, 1, 1, 1, 1, 1, 4, 4, 1, 4, 1, 1, 4, 4, 1, 1, 4, 1, 1, 1, 4, 4, 4, 1, 1, 4, 4, 4, 4, 1, 4, 1, 4, 1, 4, 4, 1, 4, 1, 1, 1, 1, 1, 4, 1, 4, 1, 4, 1, 4, 4, 4, 4, 4, 1, 4, 4, 1, 1, 1, 1, 4, 4, 1, 4, 1, 4, 4, 4, 4, 4, 1, 4, 1, 4, 4, 1, 1, 1, 1, 4, 4, 4, 4, 1, 4, 4, 4, 1, 1, 1, 1, 1, 4, 4, 4, 1, 1, 4, 1, 4, 4, 1, 4, 1, 1, 1, 1, 4, 4, 4, 1, 1, 4, 4, 1, 4, 1, 4, 4, 4, 1, 1, 4, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]\n"
     ]
    }
   ],
   "source": [
    "pred = \"3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 33 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 4 4 4 4 1 4 1 1 1 1 4 1 4 4 4 4 1 1 1 1 1 4 1 4 1 4 1 4 1 1 1 4 1 4 4 1 1 1 1 1 1 1 4 1 1 1 1 1 1 4 4 1 4 1 1 4 4 1 1 4 1 1 1 4 4 4 1 1 4 4 4 4 1 4 1 4 1 4 4 1 4 1 1 1 1 1 4 1 4 1 4 1 4 4 4 4 4 1 4 4 1 1 1 1 4 4 1 4 1 4 4 4 4 4 1 4 1 4 4 1 1 1 1 4 4 4 4 1 4 4 4 1 1 1 1 1 4 4 4 1 1 4 1 4 4 1 4 1 1 1 1 4 4 4 1 1 4 4 1 4 1 4 4 4 1 1 4 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5\"\n",
    "\n",
    "pred = pred.split(' ')\n",
    "\n",
    "pred_ = []\n",
    "for i in pred:\n",
    "    pred_.append(int(i))\n",
    "print(pred_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'bool' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-35-10023da77c66>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mpred_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpred_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0macc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetAccuracy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpred_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0macc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\Sanhak-Lab\\Cluster.py\u001b[0m in \u001b[0;36mgetAccuracy\u001b[1;34m(data_y, pred_y)\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[0mcount\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m     \u001b[0mbool_array\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mdata_y\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mpred_y\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0mcorrect\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mbool_array\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m         \u001b[1;32mif\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcorrect\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m             \u001b[0mcount\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'bool' object is not iterable"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "pred_ = np.array(pred_)\n",
    "acc = c.getAccuracy(y, pred_)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
